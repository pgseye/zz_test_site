{"title":"Interactions (effect modifiers) are important - don't ignore them","markdown":{"yaml":{"title":"Interactions (effect modifiers) are important - don't ignore them","date":"2023-11-24","categories":["code","analysis","modelling","logistic"],"image":"interact_plot.jpg","description":"Keep an open mind to interactions in your next model."},"headingText":"The Question","containsRefs":false,"markdown":"\n\n```{r}\n#| label: setup\nlibrary(knitr)\nlibrary(quarto)\nlibrary(emmeans)\nlibrary(flextable)\nlibrary(ggplot2)\nsuppressPackageStartupMessages(library(gtsummary))\nopts_chunk$set(echo = T,\n               cache = F,\n               prompt = F,\n               tidy = F,\n               message = F,\n               warning = F)\n```\n\n<br>\n\n\n<details>\n\nRecall that the question this week was to choose between:\n\nA\\) Age is a confounder in the relationship between sex and hospitalisation from car crash.\n\nB\\) Age is an effect modifier in the relationship between sex and hospitalisation from car crash.\n\nusing the data supplied below.\n\n![](images/interact.png)\n\n</details>\n\n## The Answer\n\n-   The answer is **B**. Younger male drivers tend to be more stupid and injure themselves more seriously than their female counterparts. Upon reaching a suitable age of maturity their risk of hospitalisation reduces to about the same (if we assume the 95% CI for the 8% reduction includes 0) as that for females.\n-   When a third variable plays a role in the association between an exposure and an outcome it may act as a confounder **OR** effect modifier (**AND** sometimes both).\n-   A simple confounder (e.g. age) will show the **same** exposure -\\> outcome association across all of its categories (e.g. same risk ratio in \\< 40 yrs and ≥ 40 yrs)\n-   An effect modifier will show **different** magnitudes of association across its categories (e.g. the risk ratio will differ in those \\< 40 yrs and ≥ 40 yrs).\n-   Stratification is the simplest form of exploring and adjusting for confounding/interaction effects (used before we had all this computing power).\n-   Subgroups of data are created for each category of confounder/effect modifier and estimates of interest (mean differences, risk ratios, etc) calculated in each.\n-   These can then be combined in a weighted manner to give an overall (adjusted) estimate if NO effect modification is present.\n-   This is equivalent to including the third variable as a covariate in our regression model (we now use models rather than stratification methods).\n-   Simple inclusion in the regression model (using `+` in `R`) FORCES the exposure -\\> outcome association to be the **same** across all categories of the effect modifier even if in reality it's not.\n-   `+` assumes confounding **ONLY** and **NO** effect modification.\n-   A problem arises, however, when the third variable is more an effect modifier, rather than confounder.\n-   If we suspect effect modification is present, we need to include this third variable in the model as an interaction term (using `*` in `R`)\n-   This will allow the exposure -\\> outcome association to **differ** across categories of the effect modifier.\n-   `*` assumes effect modification is present.\n-   This is a more flexible model specification, than simply 'adjusting' for a variable.\n-   Interpretation is a little more involved (always happy to help with this) but the point is it's important not to blindly assume a third variable can only ever be a confounder.\n-   If effect modification is present, you need to know about it.\n-   It is simple to test for effect modification in `R`, `Stata`, etc. Include the interaction term and then drop it if not clinically/statistically significant at some level.\n-   I have included some `R` output below showing the equivalence of stratification and modelling approaches to interaction effects.\n\nBefore we get to that - a simple set of guidelines for how to think about crude vs stratified associations:\n\n![](images/guidelines.png)\n\nEquivalence of model-derived crude estimate\n\nRecall that the aggregated data that the crude estimate is calculated from is:\n\n```{r}\n#| label: aggregated_data\ndat_agg <- data.frame(sex = c(\"Male\", \"Female\"),\n                      hospitalised = as.numeric(c(1330, 798)), \n                      not_hospitalised = as.numeric(c(7018,6400)))\ndat_agg\n```\n\nTo estimate this model in `R` we essentially run a logistic regression but instead of outputting an odds ratio, we calculate a risk ratio by specifying a `log` rather than the default `logit` link. We will also use the aggregate model specification, as we don't have the individual-level data.\n\nThe model-derived crude risk ratio for `sex = 1.44 (95% CI 1.32, 1.56; p < 0.001)`. This is very close to the estimate that we initially calculated manually from the 2 x 2 table (`1.45`).\n\n```{r}\n#| label: crude model\nmod_crude <- glm(cbind(hospitalised, not_hospitalised) ~ sex, data = dat_agg, family = binomial(link = \"log\"))\ntbl_regression(mod_crude, exp = T)\n```\n\n## Let's introduce age (\\<40 vs ≥ 40) as a third variable\n\n```{r}\n#| label: disaggregated_data\ndat_disagg <- data.frame(sex = c(\"Male\", \"Female\", \"Male\", \"Female\"),\n                         age = c(\"< 40\", \"< 40\", \"≥ 40\", \"≥ 40\"),\n                         hospitalised = as.numeric(c(966, 460, 364, 348)), \n                         not_hospitalised = as.numeric(c(3146, 3000, 3872, 3400)))\ndat_disagg\n```\n\n### Age as a confounder\n\nFor now, let's just assume age is a confounder in the association between sex and hospitalisation risk. The model formulation in `R` is then:\n\n`mod_adj <- glm(cbind(hospitalised, not_hospitalised) ~ sex + age, data = dat_agg, family = binomial(link = \"log\"))`\n\nand the risk ratios we get are:\n\n```{r}\n#| label: adjusted model confounding\nmod_confound <- glm(cbind(hospitalised, not_hospitalised) ~ sex + age, data = dat_disagg, family = binomial(link = \"log\"))\ntbl_regression(mod_confound, exp = T)\n```\n\nSo, what we are seeing here is that the magnitude of association between sex and hospitalisation risk is averaged (in a weighted way) over both categories of age to produce one effect estimate `sex = 1.43 (95% CI 1.32, 1.55; p < 0.001)`. This just so happens to be almost the same as the crude estimate when you ignore age altogether.\n\nThe effect for age in this model is such that whatever your sex, there is about a `53%` reduction in the risk of hospitalisation if you are over 40 vs under 40. Note that in the stratification approach, you aren't able to calculate an effect for age because you are stratifying by it (essentially treating it as a nuisance variable).\n\n### Age as an effect modifier\n\nNow, let's correctly model age as an effect modifier in the association between sex and hospitalisation risk. The model formulation in `R` is then (note the `*` operator):\n\n`mod_adj <- glm(cbind(hospitalised, not_hospitalised) ~ sex * age, data = dat_agg, family = binomial(link = \"log\"))`\n\nand the risk ratios we get are:\n\n```{r}\n#| label: adjusted_model_effect_modification\nmod_interact <- glm(cbind(hospitalised, not_hospitalised) ~ sex * age, data = dat_disagg, family = binomial(link = \"log\"))\ntbl_regression(mod_interact, exp = T)\n```\n\nNote how the p value for the interaction term is very low - this would be a good indicator that the model fits the data better with the interaction term present than without it (i.e. assuming age as a confounder only).\n\nAs I mentioned earlier, the model interpretation with an interaction present does become a little more complicated, but let's break this down (note that I use \"effect\" in a non-causal way):\n\n-   The coefficient for `sex = 1.77 (95% CI 1.60, 1.96; p < 0.001)`. The represents the **\"effect\"** of sex (being male relative to female) on hospitalisation risk at the **reference level** of age, which in this case is the under 40 yrs group. So, for those under 40, there is about a `77%` increased risk for males relative to females.\n\n-   The coefficient for `age = 0.70 (95% CI 0.61, 0.80; p < 0.001)`. This represents the **\"effect\"** of age (being older than 40 yrs relative to younger than 40 yrs) on hospitalisation risk at the **reference level** of sex, which in this case is female. So, for females, there is about a `30%` risk reduction in the need for hospitalisation for older relative to younger drivers.\n\n-   The coefficient for the interaction term: `sex * age = 0.52 (95% CI 0.44, 0.62; p < 0.001)`. This represents the **multiplicative** increase in the magnitude of association for males over 40 yrs.\n\n## Effect modification means more associations to estimate\n\nIn this specific case, when you treat age as a confounder, the model produces two risk ratios - one for `sex` and one for `age`. However, when you treat `age` as an effect modifier, there are now four possible risk ratios to estimate (if you care about age more than it being a \"nuisance\" variable to control for). These are:\n\n1.  The effect of being male in younger individuals.\n2.  The effect of being male in older individuals.\n3.  The effect of being older in females.\n4.  The effect of being older in males.\n\nYou can easily enough work these out manually by multiplying the respective reference coefficients with the interaction coefficient. The risk ratios for each of the above would then be:\n\n1.  `1.77` (we can just read this one straight off the model output)\n2.  `1.77 x 0.52 = 0.92`\n3.  `0.70` (again we can just read this one straight off)\n4.  `0.70 x 0.52 = 0.36`\n\nNote that the effects for 1. and 2. are very similar to what we calculated straight from the 2 x 2 tables (`1.84` and `0.92`, respectively - as previously mentioned, the effects for 3. and 4. aren't able to be calculated for the stratifying variable).\n\n## Emmeans should be your new best friend\n\nPerhaps I am preaching to the converted, but if you don't know what the `emmeans` package and specific function in `R` does, then you should learn about it (the equivalent function in `Stata` is `margins`).\n\n<https://cran.r-project.org/web/packages/emmeans/index.html>\n\n<https://aosmith.rbind.io/2019/03/25/getting-started-with-emmeans/>\n\n`emmeans` does a lot of things, but perhaps its workhorse function is to allow you to take a model and calculate adjusted predictions (either at set values of covariates, or by 'averaging' over them). In this case, we can very easily use `emmeans` to reproduce the manual calculations we just did.\n\n```{r}\n#| label: emmeans\n#| tbl-cap: Predicted Probabilities of Hospitalisation\nemmeans(mod_interact, ~ sex + age, type = \"response\") |> \n  data.frame() |> \n  flextable() |> \n  colformat_double(digits = 3, na_str = \"N/A\") |>\n  set_table_properties(layout = \"autofit\") |> \n  height(height = 1, unit = \"cm\") |> \n  hrule(rule = \"atleast\", part = \"header\") |> \n  align(align = \"center\", part = \"body\") |>\n  bg(bg = \"white\", part = \"all\") |> \n  flextable::font(fontname = \"Consolas\", part = \"all\") |>\n  theme_vanilla()\n```\n\nSpecifying `type = \"response\"` in the `emmeans` call indicates that we want to calculate the outcome on the probability (i.e. risk) scale. It is simple enough to plot these predicted probabilities using the `emmip` function in `emmeans`.\n\n```{r}\n#| label: plot_risk_ratios\nemmip(mod_interact, age ~ sex, type = \"response\") + \n  theme_bw(base_size = 18)\n```\n\nTo get the risk ratios we have been working with until now, we simply add the `pairs(rev = T)` function to the call:\n\n```{r}\n#| label: risk_ratios\n#| tbl-cap: All Pairwise Risk Ratios\nemmeans(mod_interact, ~ sex + age, type = \"response\") |> pairs(rev = T) |> \n  data.frame() |> \n  flextable() |> \n  colformat_double(digits = 3, na_str = \"N/A\") |>\n  set_table_properties(layout = \"autofit\") |> \n  height(height = 1, unit = \"cm\") |> \n  hrule(rule = \"atleast\", part = \"header\") |> \n  align(align = \"center\", part = \"body\") |>\n  bg(bg = \"white\", part = \"all\") |> \n  flextable::font(fontname = \"Consolas\", part = \"all\") |>\n  theme_vanilla()\n```\n\nNote that this gives us two extra comparisons we might not really want (the 3rd and 4th lines of the output) as it estimates every single pairwise comparison. We can get a bit fancier and customise the `emmeans` output to give us only what we want:\n\n```{r}\n#| label: risk_ratios_custom\n#| tbl-cap: Custom Pairwise Risk Ratios\nemm <- emmeans(mod_interact, ~ sex + age, type = \"response\") # save the estimated risks\ncustom <- list(`The effect of being male in younger individuals` = c(-1,1,0,0),\n               `The effect of being male in older individuals` = c(0,0,-1,1),\n               `The effect of being older in females` = c(-1,0,1,0),\n               `The effect of being older in males` = c(0,-1,0,1)) # create custom grid of RR's to estimate\ncontrast(emm, custom) |> \n  summary(infer = T) |> \n  data.frame() |> \n  flextable() |> \n  colformat_double(digits = 3, na_str = \"N/A\") |>\n  set_table_properties(layout = \"autofit\") |> \n  height(height = 1, unit = \"cm\") |> \n  hrule(rule = \"atleast\", part = \"header\") |> \n  align(align = \"center\", part = \"body\") |>\n  bg(bg = \"white\", part = \"all\") |> \n  flextable::font(fontname = \"Consolas\", part = \"all\") |>\n  theme_vanilla()\n```\n\nNote, that these match the manual calculations pretty well.\n\nPlease take some time to learn about `emmeans` (or `margins` in `Stata`). It will make your life so much easier if you plan to have a career in research (and don't always have access to a statistician).\n","srcMarkdownNoYaml":"\n\n```{r}\n#| label: setup\nlibrary(knitr)\nlibrary(quarto)\nlibrary(emmeans)\nlibrary(flextable)\nlibrary(ggplot2)\nsuppressPackageStartupMessages(library(gtsummary))\nopts_chunk$set(echo = T,\n               cache = F,\n               prompt = F,\n               tidy = F,\n               message = F,\n               warning = F)\n```\n\n<br>\n\n## The Question\n\n<details>\n\nRecall that the question this week was to choose between:\n\nA\\) Age is a confounder in the relationship between sex and hospitalisation from car crash.\n\nB\\) Age is an effect modifier in the relationship between sex and hospitalisation from car crash.\n\nusing the data supplied below.\n\n![](images/interact.png)\n\n</details>\n\n## The Answer\n\n-   The answer is **B**. Younger male drivers tend to be more stupid and injure themselves more seriously than their female counterparts. Upon reaching a suitable age of maturity their risk of hospitalisation reduces to about the same (if we assume the 95% CI for the 8% reduction includes 0) as that for females.\n-   When a third variable plays a role in the association between an exposure and an outcome it may act as a confounder **OR** effect modifier (**AND** sometimes both).\n-   A simple confounder (e.g. age) will show the **same** exposure -\\> outcome association across all of its categories (e.g. same risk ratio in \\< 40 yrs and ≥ 40 yrs)\n-   An effect modifier will show **different** magnitudes of association across its categories (e.g. the risk ratio will differ in those \\< 40 yrs and ≥ 40 yrs).\n-   Stratification is the simplest form of exploring and adjusting for confounding/interaction effects (used before we had all this computing power).\n-   Subgroups of data are created for each category of confounder/effect modifier and estimates of interest (mean differences, risk ratios, etc) calculated in each.\n-   These can then be combined in a weighted manner to give an overall (adjusted) estimate if NO effect modification is present.\n-   This is equivalent to including the third variable as a covariate in our regression model (we now use models rather than stratification methods).\n-   Simple inclusion in the regression model (using `+` in `R`) FORCES the exposure -\\> outcome association to be the **same** across all categories of the effect modifier even if in reality it's not.\n-   `+` assumes confounding **ONLY** and **NO** effect modification.\n-   A problem arises, however, when the third variable is more an effect modifier, rather than confounder.\n-   If we suspect effect modification is present, we need to include this third variable in the model as an interaction term (using `*` in `R`)\n-   This will allow the exposure -\\> outcome association to **differ** across categories of the effect modifier.\n-   `*` assumes effect modification is present.\n-   This is a more flexible model specification, than simply 'adjusting' for a variable.\n-   Interpretation is a little more involved (always happy to help with this) but the point is it's important not to blindly assume a third variable can only ever be a confounder.\n-   If effect modification is present, you need to know about it.\n-   It is simple to test for effect modification in `R`, `Stata`, etc. Include the interaction term and then drop it if not clinically/statistically significant at some level.\n-   I have included some `R` output below showing the equivalence of stratification and modelling approaches to interaction effects.\n\nBefore we get to that - a simple set of guidelines for how to think about crude vs stratified associations:\n\n![](images/guidelines.png)\n\nEquivalence of model-derived crude estimate\n\nRecall that the aggregated data that the crude estimate is calculated from is:\n\n```{r}\n#| label: aggregated_data\ndat_agg <- data.frame(sex = c(\"Male\", \"Female\"),\n                      hospitalised = as.numeric(c(1330, 798)), \n                      not_hospitalised = as.numeric(c(7018,6400)))\ndat_agg\n```\n\nTo estimate this model in `R` we essentially run a logistic regression but instead of outputting an odds ratio, we calculate a risk ratio by specifying a `log` rather than the default `logit` link. We will also use the aggregate model specification, as we don't have the individual-level data.\n\nThe model-derived crude risk ratio for `sex = 1.44 (95% CI 1.32, 1.56; p < 0.001)`. This is very close to the estimate that we initially calculated manually from the 2 x 2 table (`1.45`).\n\n```{r}\n#| label: crude model\nmod_crude <- glm(cbind(hospitalised, not_hospitalised) ~ sex, data = dat_agg, family = binomial(link = \"log\"))\ntbl_regression(mod_crude, exp = T)\n```\n\n## Let's introduce age (\\<40 vs ≥ 40) as a third variable\n\n```{r}\n#| label: disaggregated_data\ndat_disagg <- data.frame(sex = c(\"Male\", \"Female\", \"Male\", \"Female\"),\n                         age = c(\"< 40\", \"< 40\", \"≥ 40\", \"≥ 40\"),\n                         hospitalised = as.numeric(c(966, 460, 364, 348)), \n                         not_hospitalised = as.numeric(c(3146, 3000, 3872, 3400)))\ndat_disagg\n```\n\n### Age as a confounder\n\nFor now, let's just assume age is a confounder in the association between sex and hospitalisation risk. The model formulation in `R` is then:\n\n`mod_adj <- glm(cbind(hospitalised, not_hospitalised) ~ sex + age, data = dat_agg, family = binomial(link = \"log\"))`\n\nand the risk ratios we get are:\n\n```{r}\n#| label: adjusted model confounding\nmod_confound <- glm(cbind(hospitalised, not_hospitalised) ~ sex + age, data = dat_disagg, family = binomial(link = \"log\"))\ntbl_regression(mod_confound, exp = T)\n```\n\nSo, what we are seeing here is that the magnitude of association between sex and hospitalisation risk is averaged (in a weighted way) over both categories of age to produce one effect estimate `sex = 1.43 (95% CI 1.32, 1.55; p < 0.001)`. This just so happens to be almost the same as the crude estimate when you ignore age altogether.\n\nThe effect for age in this model is such that whatever your sex, there is about a `53%` reduction in the risk of hospitalisation if you are over 40 vs under 40. Note that in the stratification approach, you aren't able to calculate an effect for age because you are stratifying by it (essentially treating it as a nuisance variable).\n\n### Age as an effect modifier\n\nNow, let's correctly model age as an effect modifier in the association between sex and hospitalisation risk. The model formulation in `R` is then (note the `*` operator):\n\n`mod_adj <- glm(cbind(hospitalised, not_hospitalised) ~ sex * age, data = dat_agg, family = binomial(link = \"log\"))`\n\nand the risk ratios we get are:\n\n```{r}\n#| label: adjusted_model_effect_modification\nmod_interact <- glm(cbind(hospitalised, not_hospitalised) ~ sex * age, data = dat_disagg, family = binomial(link = \"log\"))\ntbl_regression(mod_interact, exp = T)\n```\n\nNote how the p value for the interaction term is very low - this would be a good indicator that the model fits the data better with the interaction term present than without it (i.e. assuming age as a confounder only).\n\nAs I mentioned earlier, the model interpretation with an interaction present does become a little more complicated, but let's break this down (note that I use \"effect\" in a non-causal way):\n\n-   The coefficient for `sex = 1.77 (95% CI 1.60, 1.96; p < 0.001)`. The represents the **\"effect\"** of sex (being male relative to female) on hospitalisation risk at the **reference level** of age, which in this case is the under 40 yrs group. So, for those under 40, there is about a `77%` increased risk for males relative to females.\n\n-   The coefficient for `age = 0.70 (95% CI 0.61, 0.80; p < 0.001)`. This represents the **\"effect\"** of age (being older than 40 yrs relative to younger than 40 yrs) on hospitalisation risk at the **reference level** of sex, which in this case is female. So, for females, there is about a `30%` risk reduction in the need for hospitalisation for older relative to younger drivers.\n\n-   The coefficient for the interaction term: `sex * age = 0.52 (95% CI 0.44, 0.62; p < 0.001)`. This represents the **multiplicative** increase in the magnitude of association for males over 40 yrs.\n\n## Effect modification means more associations to estimate\n\nIn this specific case, when you treat age as a confounder, the model produces two risk ratios - one for `sex` and one for `age`. However, when you treat `age` as an effect modifier, there are now four possible risk ratios to estimate (if you care about age more than it being a \"nuisance\" variable to control for). These are:\n\n1.  The effect of being male in younger individuals.\n2.  The effect of being male in older individuals.\n3.  The effect of being older in females.\n4.  The effect of being older in males.\n\nYou can easily enough work these out manually by multiplying the respective reference coefficients with the interaction coefficient. The risk ratios for each of the above would then be:\n\n1.  `1.77` (we can just read this one straight off the model output)\n2.  `1.77 x 0.52 = 0.92`\n3.  `0.70` (again we can just read this one straight off)\n4.  `0.70 x 0.52 = 0.36`\n\nNote that the effects for 1. and 2. are very similar to what we calculated straight from the 2 x 2 tables (`1.84` and `0.92`, respectively - as previously mentioned, the effects for 3. and 4. aren't able to be calculated for the stratifying variable).\n\n## Emmeans should be your new best friend\n\nPerhaps I am preaching to the converted, but if you don't know what the `emmeans` package and specific function in `R` does, then you should learn about it (the equivalent function in `Stata` is `margins`).\n\n<https://cran.r-project.org/web/packages/emmeans/index.html>\n\n<https://aosmith.rbind.io/2019/03/25/getting-started-with-emmeans/>\n\n`emmeans` does a lot of things, but perhaps its workhorse function is to allow you to take a model and calculate adjusted predictions (either at set values of covariates, or by 'averaging' over them). In this case, we can very easily use `emmeans` to reproduce the manual calculations we just did.\n\n```{r}\n#| label: emmeans\n#| tbl-cap: Predicted Probabilities of Hospitalisation\nemmeans(mod_interact, ~ sex + age, type = \"response\") |> \n  data.frame() |> \n  flextable() |> \n  colformat_double(digits = 3, na_str = \"N/A\") |>\n  set_table_properties(layout = \"autofit\") |> \n  height(height = 1, unit = \"cm\") |> \n  hrule(rule = \"atleast\", part = \"header\") |> \n  align(align = \"center\", part = \"body\") |>\n  bg(bg = \"white\", part = \"all\") |> \n  flextable::font(fontname = \"Consolas\", part = \"all\") |>\n  theme_vanilla()\n```\n\nSpecifying `type = \"response\"` in the `emmeans` call indicates that we want to calculate the outcome on the probability (i.e. risk) scale. It is simple enough to plot these predicted probabilities using the `emmip` function in `emmeans`.\n\n```{r}\n#| label: plot_risk_ratios\nemmip(mod_interact, age ~ sex, type = \"response\") + \n  theme_bw(base_size = 18)\n```\n\nTo get the risk ratios we have been working with until now, we simply add the `pairs(rev = T)` function to the call:\n\n```{r}\n#| label: risk_ratios\n#| tbl-cap: All Pairwise Risk Ratios\nemmeans(mod_interact, ~ sex + age, type = \"response\") |> pairs(rev = T) |> \n  data.frame() |> \n  flextable() |> \n  colformat_double(digits = 3, na_str = \"N/A\") |>\n  set_table_properties(layout = \"autofit\") |> \n  height(height = 1, unit = \"cm\") |> \n  hrule(rule = \"atleast\", part = \"header\") |> \n  align(align = \"center\", part = \"body\") |>\n  bg(bg = \"white\", part = \"all\") |> \n  flextable::font(fontname = \"Consolas\", part = \"all\") |>\n  theme_vanilla()\n```\n\nNote that this gives us two extra comparisons we might not really want (the 3rd and 4th lines of the output) as it estimates every single pairwise comparison. We can get a bit fancier and customise the `emmeans` output to give us only what we want:\n\n```{r}\n#| label: risk_ratios_custom\n#| tbl-cap: Custom Pairwise Risk Ratios\nemm <- emmeans(mod_interact, ~ sex + age, type = \"response\") # save the estimated risks\ncustom <- list(`The effect of being male in younger individuals` = c(-1,1,0,0),\n               `The effect of being male in older individuals` = c(0,0,-1,1),\n               `The effect of being older in females` = c(-1,0,1,0),\n               `The effect of being older in males` = c(0,-1,0,1)) # create custom grid of RR's to estimate\ncontrast(emm, custom) |> \n  summary(infer = T) |> \n  data.frame() |> \n  flextable() |> \n  colformat_double(digits = 3, na_str = \"N/A\") |>\n  set_table_properties(layout = \"autofit\") |> \n  height(height = 1, unit = \"cm\") |> \n  hrule(rule = \"atleast\", part = \"header\") |> \n  align(align = \"center\", part = \"body\") |>\n  bg(bg = \"white\", part = \"all\") |> \n  flextable::font(fontname = \"Consolas\", part = \"all\") |>\n  theme_vanilla()\n```\n\nNote, that these match the manual calculations pretty well.\n\nPlease take some time to learn about `emmeans` (or `margins` in `Stata`). It will make your life so much easier if you plan to have a career in research (and don't always have access to a statistician).\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":12,"fig-height":9,"fig-format":"retina","fig-dpi":96,"df-print":"kable","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":3,"number-sections":true,"highlight-style":"kate","css":["../../styles.css"],"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.433","editor":"visual","page-layout":"article","code-block-bg":"white","code-block-border-left":"#31BAE9","code-copy":true,"fontsize":"1.1em","theme":{"light":"united","dark":"darkly"},"comments":{"giscus":{"repo":"pgseye/Weekly_Stats_Tips"}},"title":"Interactions (effect modifiers) are important - don't ignore them","date":"2023-11-24","categories":["code","analysis","modelling","logistic"],"image":"interact_plot.jpg","description":"Keep an open mind to interactions in your next model."},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}