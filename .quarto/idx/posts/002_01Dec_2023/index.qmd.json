{"title":"It pays to think like a Bayesian","markdown":{"yaml":{"title":"It pays to think like a Bayesian","date":"2023-12-01","categories":["puzzle","probability","Bayesian"],"image":"monty_small.jpg","description":"Bayesian reasoning is more in line with how we process chance in everyday life.","number-sections":false},"headingText":"The Question","containsRefs":false,"markdown":"\n\n\n<details>\n\nRecall that the question this week was to choose between:\n\nA\\) Switch to another door.\n\nB\\) Stay with your original door.\n\nC\\) It doesn't matter if you switch or stay.\n\n![](images/monty.png)\n\n</details>\n\n## The Answer\n\nThe answer is that you should **switch** doors, and in fact if you do switch, you **double** your chances of winning the car - from 33.3% to 66.7%.\n\nThis is known as the **Monty Hall problem** and when it was first posed in a magazine column in 1975 managed to confuse readers to the extent that even mathematicians were writing in to the magazine to claim that answer was in fact wrong and staying with the originally chosen door was the better strategy for success.\n\nThe simplest way that I can explain this is that you start out with a 33.3% chance of winning the car and those probabilities don't change once you lock in your selection and Monty offers you another chance to choose (i.e. the probabilities don't change to 50/50 once Monty reveals what's behind one of the doors).\n\n#### If you stay\n\nIf you choose the correct door to start with (for which there is a 33.3% chance), staying will result in you ending up with the car (winning).\n\nIf you choose the incorrect door to start with (for which there is a 66.7% chance), staying will necessarily result in you ending up with a goat (losing).\n\n#### If you switch\n\nIf you choose the correct door to start with (for which there is a 33.3% chance), switching will result in you ending up with a goat (losing).\n\nIf you choose the incorrect door to start with (for which there is a 66.7% chance), switching will necessarily result in you ending up with the car, because Monty **has** to pick the only other losing door to open (winning).\n\n***Staying is associated with a 33.3% success rate, whereas switching doubles your chance of success to 66.7%.***\n\n<FONT COLOR = red>**Stop here**</FONT> if equations give you the equivalent of the aftermath of eating Mexican food. What I have done below is show how we can arrive at the same answer using an analytical approach when our logic/intuition fails. You may not want to venture that far...\n\nWhat I think is cool about this problem is that while the result might seem counterintuitive to how we naturally process chance, using Bayesian reasoning provides a formulaic way to get at the right answer. This again uses conditional probabilities as I introduced them a few weeks ago. Bayesian thinking is about utilising prior knowledge in conjunction with new data to improve or update our knowledge (whereas the Frequentist approach to statistics doesn't care so much about prior knowledge and instead just uses the data at hand).\n\n::: {.callout-important appearance=\"simple\"}\n\n## Important Concept\n\nBayesian reasoning enables the analysis of data under the light of prior knowledge.\n\n:::\n\nBayes Theorem can be written as:\n\n$$\nPr(\\theta | data) = \\frac{Pr(data | \\theta) Pr(\\theta)}{Pr(data)}\n$$\n\nwhere $\\theta$ could be a particular parameter or hypothesis.\n\nHere:\n\n$Pr(data | \\theta)$ is the likelihood function (the **data**, or what we measure)\n\n$Pr(\\theta)$ is the **prior probability of our hypothesis** (prior knowledge before we the measurement)\n\n$Pr(data)$ is the prior probability of the data\n\n$Pr(\\theta | data)$ is the **posterior probability of our hypothesis** (i.e. \"in light of the data\")\n\nOn the Bayesian/Frequentist topic, note that $Pr(data | \\theta)$ is what null-hypothesis significance testing (NHST) encapsulates and this is a Frequentist concept. Whenever we calculate a p value we are asking:\n\n-   \"What is the probability of this new data (or data even more extreme) occurring by chance **given** the null hypothesis is true?\"\n\nBut really, what we want to know most of the time is the opposite:\n\n-   \"What is the probability of the null hypothesis being true **given** this new data?\"\n\nThat is a Bayesian concept and is answered with $Pr(\\theta | data)$. Maybe we should become more Bayesian in how we handle our research...\n\nAnyway, excuse the digression. We can generalise Bayes Theorem to the Monty Hall problem as:\n\n$$\nPr(\\text{car behind door x} | \\text{Monty opens door y}) = \\frac{Pr(\\text{Monty opens door y} | \\text{car behind door x}) Pr(\\text{car behind door x})}{Pr(\\text{Monty opens door y})}\n$$\n\nFor the sake of the exercise, let *x = door 1 and y = door 3*.\n\nSo we are interested in the probability the car is behind door 1 (that means we picked door 1) when Monty opens door 3 to reveal a goat.\n\nIn calculating the different components of Bayes Theorem, we first need to enumerate the various probabilities.\n\n$Pr(\\text{car behind door 1}) = Pr(\\text{car behind door 2}) = Pr(\\text{car behind door 3}) = 33.3\\%$\n\nThese are the **prior probabilities**.\n\nThen:\n\n$Pr(\\text{Monty opens door 3} | \\text{car behind door 1}) = 50\\%$\n\nMonty can only pick doors 2 or 3, as we picked door 1.\n\n$Pr(\\text{Monty opens door 3} | \\text{car behind door 2}) = 100\\%$\n\nMonty can only pick door 3, as we picked door 1 and he doesn't want to reveal the car behind door 2.\n\n$Pr(\\text{Monty opens door 3} | \\text{car behind door 3}) = 0\\%$\n\nMonty won't reveal the car as part of his playing rules.\n\nThese are the likelihoods or the **data**.\n\nThe $Pr(\\text{Monty opens door 3})$ is a little trickier to calculate. Here we don't need to worry about the car being behind any specific door, only that Monty won't reveal it. Intuitively, this would be $50\\%$ as he only has two doors to choose from. But you can also work this out by summing the product of each of the prior probabilities and the evidence:\n\n$Pr(\\text{Monty opens door 3}) = (0.33 * 0.5) + (0.33 * 1) + (0.33 * 0) = 0.5$\n\nFinally, we can get to working out the **posterior probabilities** of the car being behind each door given Monty opens door 3. We use Bayes Theorem as shown above to do this.\n\n$$\nPr(\\text{car behind door 1} | \\text{Monty opens door 3}) = \\frac{Pr(\\text{Monty opens door 3} | \\text{car behind door 1}) Pr(\\text{car behind door 1})}{Pr(\\text{Monty opens door 3})}\n$$ $$\n = \\frac{0.5 * 0.33}{0.5} = 33.3\\%\n$$ Likewise:\n\n$$\nPr(\\text{car behind door 2} | \\text{Monty opens door 3})  = \\frac{1 * 0.33}{0.5} = 66.7\\%\n$$ and\n\n$$\nPr(\\text{car behind door 3} | \\text{Monty opens door 3})  = \\frac{0 * 0.33}{0.5} = 0\\%\n$$\n\nRemember, we initially chose door 1. So, when Monty opens door 3 (this could have been door 2 - we just needed to pick a door for the exercise), we double our chances of winning by **switching** to door 2. And this is how Bayesian reasoning can come to the rescue when our own intuition fails.\n\nFurther explanation can be found here if you remain unconvinced:\n\n<https://en.wikipedia.org/wiki/Monty_Hall_problem>\n\n<https://statisticsbyjim.com/fun/monty-hall-problem/>\n","srcMarkdownNoYaml":"\n\n## The Question\n\n<details>\n\nRecall that the question this week was to choose between:\n\nA\\) Switch to another door.\n\nB\\) Stay with your original door.\n\nC\\) It doesn't matter if you switch or stay.\n\n![](images/monty.png)\n\n</details>\n\n## The Answer\n\nThe answer is that you should **switch** doors, and in fact if you do switch, you **double** your chances of winning the car - from 33.3% to 66.7%.\n\nThis is known as the **Monty Hall problem** and when it was first posed in a magazine column in 1975 managed to confuse readers to the extent that even mathematicians were writing in to the magazine to claim that answer was in fact wrong and staying with the originally chosen door was the better strategy for success.\n\nThe simplest way that I can explain this is that you start out with a 33.3% chance of winning the car and those probabilities don't change once you lock in your selection and Monty offers you another chance to choose (i.e. the probabilities don't change to 50/50 once Monty reveals what's behind one of the doors).\n\n#### If you stay\n\nIf you choose the correct door to start with (for which there is a 33.3% chance), staying will result in you ending up with the car (winning).\n\nIf you choose the incorrect door to start with (for which there is a 66.7% chance), staying will necessarily result in you ending up with a goat (losing).\n\n#### If you switch\n\nIf you choose the correct door to start with (for which there is a 33.3% chance), switching will result in you ending up with a goat (losing).\n\nIf you choose the incorrect door to start with (for which there is a 66.7% chance), switching will necessarily result in you ending up with the car, because Monty **has** to pick the only other losing door to open (winning).\n\n***Staying is associated with a 33.3% success rate, whereas switching doubles your chance of success to 66.7%.***\n\n<FONT COLOR = red>**Stop here**</FONT> if equations give you the equivalent of the aftermath of eating Mexican food. What I have done below is show how we can arrive at the same answer using an analytical approach when our logic/intuition fails. You may not want to venture that far...\n\nWhat I think is cool about this problem is that while the result might seem counterintuitive to how we naturally process chance, using Bayesian reasoning provides a formulaic way to get at the right answer. This again uses conditional probabilities as I introduced them a few weeks ago. Bayesian thinking is about utilising prior knowledge in conjunction with new data to improve or update our knowledge (whereas the Frequentist approach to statistics doesn't care so much about prior knowledge and instead just uses the data at hand).\n\n::: {.callout-important appearance=\"simple\"}\n\n## Important Concept\n\nBayesian reasoning enables the analysis of data under the light of prior knowledge.\n\n:::\n\nBayes Theorem can be written as:\n\n$$\nPr(\\theta | data) = \\frac{Pr(data | \\theta) Pr(\\theta)}{Pr(data)}\n$$\n\nwhere $\\theta$ could be a particular parameter or hypothesis.\n\nHere:\n\n$Pr(data | \\theta)$ is the likelihood function (the **data**, or what we measure)\n\n$Pr(\\theta)$ is the **prior probability of our hypothesis** (prior knowledge before we the measurement)\n\n$Pr(data)$ is the prior probability of the data\n\n$Pr(\\theta | data)$ is the **posterior probability of our hypothesis** (i.e. \"in light of the data\")\n\nOn the Bayesian/Frequentist topic, note that $Pr(data | \\theta)$ is what null-hypothesis significance testing (NHST) encapsulates and this is a Frequentist concept. Whenever we calculate a p value we are asking:\n\n-   \"What is the probability of this new data (or data even more extreme) occurring by chance **given** the null hypothesis is true?\"\n\nBut really, what we want to know most of the time is the opposite:\n\n-   \"What is the probability of the null hypothesis being true **given** this new data?\"\n\nThat is a Bayesian concept and is answered with $Pr(\\theta | data)$. Maybe we should become more Bayesian in how we handle our research...\n\nAnyway, excuse the digression. We can generalise Bayes Theorem to the Monty Hall problem as:\n\n$$\nPr(\\text{car behind door x} | \\text{Monty opens door y}) = \\frac{Pr(\\text{Monty opens door y} | \\text{car behind door x}) Pr(\\text{car behind door x})}{Pr(\\text{Monty opens door y})}\n$$\n\nFor the sake of the exercise, let *x = door 1 and y = door 3*.\n\nSo we are interested in the probability the car is behind door 1 (that means we picked door 1) when Monty opens door 3 to reveal a goat.\n\nIn calculating the different components of Bayes Theorem, we first need to enumerate the various probabilities.\n\n$Pr(\\text{car behind door 1}) = Pr(\\text{car behind door 2}) = Pr(\\text{car behind door 3}) = 33.3\\%$\n\nThese are the **prior probabilities**.\n\nThen:\n\n$Pr(\\text{Monty opens door 3} | \\text{car behind door 1}) = 50\\%$\n\nMonty can only pick doors 2 or 3, as we picked door 1.\n\n$Pr(\\text{Monty opens door 3} | \\text{car behind door 2}) = 100\\%$\n\nMonty can only pick door 3, as we picked door 1 and he doesn't want to reveal the car behind door 2.\n\n$Pr(\\text{Monty opens door 3} | \\text{car behind door 3}) = 0\\%$\n\nMonty won't reveal the car as part of his playing rules.\n\nThese are the likelihoods or the **data**.\n\nThe $Pr(\\text{Monty opens door 3})$ is a little trickier to calculate. Here we don't need to worry about the car being behind any specific door, only that Monty won't reveal it. Intuitively, this would be $50\\%$ as he only has two doors to choose from. But you can also work this out by summing the product of each of the prior probabilities and the evidence:\n\n$Pr(\\text{Monty opens door 3}) = (0.33 * 0.5) + (0.33 * 1) + (0.33 * 0) = 0.5$\n\nFinally, we can get to working out the **posterior probabilities** of the car being behind each door given Monty opens door 3. We use Bayes Theorem as shown above to do this.\n\n$$\nPr(\\text{car behind door 1} | \\text{Monty opens door 3}) = \\frac{Pr(\\text{Monty opens door 3} | \\text{car behind door 1}) Pr(\\text{car behind door 1})}{Pr(\\text{Monty opens door 3})}\n$$ $$\n = \\frac{0.5 * 0.33}{0.5} = 33.3\\%\n$$ Likewise:\n\n$$\nPr(\\text{car behind door 2} | \\text{Monty opens door 3})  = \\frac{1 * 0.33}{0.5} = 66.7\\%\n$$ and\n\n$$\nPr(\\text{car behind door 3} | \\text{Monty opens door 3})  = \\frac{0 * 0.33}{0.5} = 0\\%\n$$\n\nRemember, we initially chose door 1. So, when Monty opens door 3 (this could have been door 2 - we just needed to pick a door for the exercise), we double our chances of winning by **switching** to door 2. And this is how Bayesian reasoning can come to the rescue when our own intuition fails.\n\nFurther explanation can be found here if you remain unconvinced:\n\n<https://en.wikipedia.org/wiki/Monty_Hall_problem>\n\n<https://statisticsbyjim.com/fun/monty-hall-problem/>\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":12,"fig-height":9,"fig-format":"retina","fig-dpi":96,"df-print":"kable","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":3,"number-sections":false,"highlight-style":"kate","css":["../../styles.css"],"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.433","editor":"visual","page-layout":"article","code-block-bg":"white","code-block-border-left":"#31BAE9","code-copy":true,"fontsize":"1.1em","theme":{"light":"united","dark":"darkly"},"comments":{"giscus":{"repo":"pgseye/Weekly_Stats_Tips"}},"title":"It pays to think like a Bayesian","date":"2023-12-01","categories":["puzzle","probability","Bayesian"],"image":"monty_small.jpg","description":"Bayesian reasoning is more in line with how we process chance in everyday life."},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}