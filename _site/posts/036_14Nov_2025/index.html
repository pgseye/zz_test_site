<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-11-14">
<meta name="description" content="Primer and Intuition for Computational Non-Parametric Resampling">

<title>Test Site 2 - A Gentle Introduction to the Bootstrap</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Test Site 2</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">All Posts</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#the-basis-of-inferential-statistics" id="toc-the-basis-of-inferential-statistics" class="nav-link active" data-scroll-target="#the-basis-of-inferential-statistics"><span class="header-section-number">1</span> The Basis of Inferential Statistics</a></li>
  <li><a href="#the-sampling-distribution" id="toc-the-sampling-distribution" class="nav-link" data-scroll-target="#the-sampling-distribution"><span class="header-section-number">2</span> The Sampling Distribution</a>
  <ul>
  <li><a href="#basic-concepts" id="toc-basic-concepts" class="nav-link" data-scroll-target="#basic-concepts"><span class="header-section-number">2.1</span> Basic concepts</a></li>
  <li><a href="#when-it-works" id="toc-when-it-works" class="nav-link" data-scroll-target="#when-it-works"><span class="header-section-number">2.2</span> When it works</a></li>
  <li><a href="#when-it-doesnt" id="toc-when-it-doesnt" class="nav-link" data-scroll-target="#when-it-doesnt"><span class="header-section-number">2.3</span> When it doesn’t</a></li>
  <li><a href="#why-is-it-called-the-bootstrap" id="toc-why-is-it-called-the-bootstrap" class="nav-link" data-scroll-target="#why-is-it-called-the-bootstrap"><span class="header-section-number">2.4</span> Why is it called the bootstrap?</a></li>
  <li><a href="#an-important-statistical-idea" id="toc-an-important-statistical-idea" class="nav-link" data-scroll-target="#an-important-statistical-idea"><span class="header-section-number">2.5</span> An important statistical idea</a></li>
  </ul></li>
  <li><a href="#the-bootstrap" id="toc-the-bootstrap" class="nav-link" data-scroll-target="#the-bootstrap"><span class="header-section-number">3</span> The Bootstrap</a>
  <ul>
  <li><a href="#what-is-it" id="toc-what-is-it" class="nav-link" data-scroll-target="#what-is-it"><span class="header-section-number">3.1</span> What is it?</a></li>
  <li><a href="#bootstrap-sampling-distribution" id="toc-bootstrap-sampling-distribution" class="nav-link" data-scroll-target="#bootstrap-sampling-distribution"><span class="header-section-number">3.2</span> Bootstrap sampling distribution</a></li>
  <li><a href="#sampling-distributions-reimagined" id="toc-sampling-distributions-reimagined" class="nav-link" data-scroll-target="#sampling-distributions-reimagined"><span class="header-section-number">3.3</span> Sampling distributions reimagined</a></li>
  </ul></li>
  <li><a href="#practical-application" id="toc-practical-application" class="nav-link" data-scroll-target="#practical-application"><span class="header-section-number">4</span> Practical Application</a></li>
  <li><a href="#sample-mean" id="toc-sample-mean" class="nav-link" data-scroll-target="#sample-mean"><span class="header-section-number">5</span> Sample Mean</a>
  <ul>
  <li><a href="#raw-data-distribution" id="toc-raw-data-distribution" class="nav-link" data-scroll-target="#raw-data-distribution"><span class="header-section-number">5.1</span> Raw Data Distribution</a></li>
  <li><a href="#sampling-distribution" id="toc-sampling-distribution" class="nav-link" data-scroll-target="#sampling-distribution"><span class="header-section-number">5.2</span> Sampling Distribution</a></li>
  <li><a href="#comparison-of-95-cis" id="toc-comparison-of-95-cis" class="nav-link" data-scroll-target="#comparison-of-95-cis"><span class="header-section-number">5.3</span> Comparison of 95% CI’s</a></li>
  </ul></li>
  <li><a href="#sample-correlation-coefficient" id="toc-sample-correlation-coefficient" class="nav-link" data-scroll-target="#sample-correlation-coefficient"><span class="header-section-number">6</span> Sample Correlation Coefficient</a>
  <ul>
  <li><a href="#raw-data-distribution-1" id="toc-raw-data-distribution-1" class="nav-link" data-scroll-target="#raw-data-distribution-1"><span class="header-section-number">6.1</span> Raw Data Distribution</a></li>
  <li><a href="#sampling-distribution-1" id="toc-sampling-distribution-1" class="nav-link" data-scroll-target="#sampling-distribution-1"><span class="header-section-number">6.2</span> Sampling Distribution</a></li>
  <li><a href="#comparison-of-95-cis-1" id="toc-comparison-of-95-cis-1" class="nav-link" data-scroll-target="#comparison-of-95-cis-1"><span class="header-section-number">6.3</span> Comparison of 95% CI’s</a></li>
  </ul></li>
  <li><a href="#wrap-up" id="toc-wrap-up" class="nav-link" data-scroll-target="#wrap-up"><span class="header-section-number">7</span> Wrap-Up</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">A Gentle Introduction to the Bootstrap</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
  <div class="quarto-categories">
    <div class="quarto-category">code</div>
    <div class="quarto-category">concept</div>
    <div class="quarto-category">modelling</div>
  </div>
  </div>

<div>
  <div class="description">
    Primer and Intuition for Computational Non-Parametric Resampling
  </div>
</div>


<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">November 14, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p>Today I thought we’d discuss a stats topic that I’m sure you’ve heard about before, but perhaps not really understood, nor yet had a pressing need to use - bootstrap resampling. Now, I have to admit that I haven’t applied this technique much in my own day to day work either, but it’s an important statistical tool to have an understanding of, because there are times when it’s the only approach you can use. And the reason for that is the bootstrap can be considered a swiss army knife of parameter uncertainty estimation when the usual parametric distribution assumptions and resulting formulaic approximations that we base our standard error calculations on, either can’t be trusted or are simply unknown.</p>
<section id="the-basis-of-inferential-statistics" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> The Basis of Inferential Statistics</h1>
<p>OK, before we dive into the main topic, let’s refresh our memories on some basic statistical concepts that are important in helping to understand what the bootstrap is all about. As you know, the application of statistics in our research is ultimately to allow us to make conclusions about some parameter of interest or importance - for example, that could be something as simple as the median survival or the average EDSS in an MS population.</p>
<p>We use data and models to do make those conclusions.</p>
<p>Now, in nearly all cases we want to know something about the population that we are studying, but all we have are data from a sample - because it’s just not practical to measure everyone. So we use statistical inference to infer or draw these conclusions about the population from the available sample. However, a very reasonable question may then be asked, and that is:</p>
<p>“How sure can we be of our conclusions?”</p>
<p>We can’t easily make claims about ‘effects’ when we can’t also quantify the margin of error associated with those claims. That is all the difference between asserting that you have strong evidence or in fact, pretty weak evidence after all. And that is where it’s important to always remember that statistical inference is really a two-side coin - we are not only interested in the estimation of the parameter that we want to know about, but also in the estimation of the uncertainty associated with it.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/pop_samp.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="the-sampling-distribution" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> The Sampling Distribution</h1>
<section id="basic-concepts" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="basic-concepts"><span class="header-section-number">2.1</span> Basic concepts</h2>
<p>And this is where the fundamental idea of the <em>sampling distribution</em> comes into play. In a nutshell, the sampling distribution represents the <strong>theoretical</strong> distribution of a sample statistic that’s derived from repeatedly randomly sampling a population of interest. Now this is a thought exercise only - we don’t do it for obvious reasons in practice - but it allows us to make assumptions about the behaviour of the population parameter that we are trying to estimate. (Note - while I say ‘theoretical’ above, these distributions can now be verified <em>in silico</em> but in the pre-computer era were confirmed empirically by a combination of mathematical derivation and physical simulation - i.e.&nbsp;bootstrapping by hand!)</p>
<p>In this thought exercise we would have a population that we are interested in calculating a parameter for, and we’d draw a sample of observations from this population. We’d then calculate the corresponding sample statistic - let’s say it’s a mean value - and we’d plot that on a frequency histogram. We would then repeat that process many times, plotting each mean value along the way. The resulting plot would show the distribution of all the sample means - and this is what we call the sampling distribution of the sample statistic. It’s important to note that this is NOT the distribution of the data itself, but the distribution of a summary statistic derived from the data.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/samp_dist.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>Now, depending on the sample size, the shape of the underlying raw data distribution and the specific summary statistic we’re interested in, sampling distributions for many statistics often end up looking normal (or close to normal) in shape. And that allows us to leverage fairly simple normal distribution properties such as the mean and standard deviation (SD) to infer the population mean and it’s associated uncertainty. The mean should converge to the actual population parameter and the SD tells us about the uncertainty in the estimation of the parameter - and in fact is directly interpretable from the sampling distribution itself, as the standard error (SE). Once we have the SE it becomes trivial to calculate the 95% confidence interval (CI).</p>
<p>The point in telling you all of this is to highlight to you is that we can use just a single sample to form probabilistic statements about a population parameter, rather than needing to measure the entire population.</p>
</section>
<section id="when-it-works" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="when-it-works"><span class="header-section-number">2.2</span> When it works</h2>
<p>Most of the time the theory of parametric sampling distributions will work just fine for what you want to do. Probability density functions (PDF’s) that define the ‘shape’ of the sampling distribution have been derived for many sample statistics. These equations are sometimes referred to as ‘closed-form solutions’. Some PDF’s are fairly simple, other’s are almost intractably complex and some are simply unknown. But what is important about this, is that when you know the PDF for a sampling distribution, you can calculate <strong>exact</strong> 95% CI’s.</p>
<p>When PDF’s become too difficult or are simply unknown, we can start to leverage approximations. And that probably explains why I haven’t needed to bootstrap much in my own work - the classic central limit theorem (CLT) does its job pretty well. The CLT basically states that you can have whatever shaped raw data distribution you want - flat, skewed, bi-modal - whatever, but when you then construct a sampling distribution from the resulting sample means, that distribution will be normal in shape (if you’ve got a large enough sample).</p>
<p>The thing is, the logic of the central limit theorem translates fairly well to most other sample statistics of interest - for example, medians, proportions, correlations, regression coefficients, and more - through a concept called <strong>large-sample asymptotic normality</strong>. This approximation basically says that if our sample is large enough, the sampling distributions of these other parameters will likewise approach normality in terms of shape. What that means at the end of the day is that we can use fairly simple(-ish) equations for large sample approximations to estimate SE’s and 95% CI’s. The equations for the SE for the mean and proportion are shown below and I’m sure you’ve seen these before.</p>
<p><span class="math display">\[ \bar{x} \pm 1.96^* \frac{s}{\sqrt{n}} \hspace{2cm} \widehat{p} \pm 1.96^* \sqrt{\frac{\widehat{p}(1 - \widehat{p})}{n}} \]</span></p>
</section>
<section id="when-it-doesnt" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="when-it-doesnt"><span class="header-section-number">2.3</span> When it doesn’t</h2>
<p>Clearly, there are situations that can occasionally arise when basic sampling theory might not be adequate for your analytic needs, otherwise we wouldn’t have this post. To my mind there are three main reasons why you might look further afield to a resampling method like the bootstrap to support your analyses.</p>
<ul>
<li><p>The first is sample size. Asymptotic normal theory relies on a ‘large’ sample size to be accurate, and the bootstrap deals with smaller samples much better. However, it is itself not immune to small sample bias (when <code>n</code> becomes quite small - say &lt; <code>15</code>). In such cases not much can save you unless you collect more data, so you might just need to rely on descriptive statistics only.</p></li>
<li><p>The second situation is where equations for the SE are either so complex as to be virtually intractable, or simply don’t exist (as described above). Here you can use the bootstrap to estimate the sampling distribution directly with relative ease.</p></li>
<li><p>Finally, for sampling distributions that depart quite obviously from normality. Here the large-sample approximations just don’t work well, but you can use the bootstrap in these cases to actually capture that non-normal shape and apply it in valid inference.</p></li>
</ul>
</section>
<section id="why-is-it-called-the-bootstrap" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="why-is-it-called-the-bootstrap"><span class="header-section-number">2.4</span> Why is it called the bootstrap?</h2>
<p>Alright - let’s actually talk about The Bootstrap! There is some interesting history in how the bootstrap came to be called what it is, as it’s etymology isn’t from the statistical domain. The <a href="https://en.wikipedia.org/wiki/Bootstrapping">origins</a> of the term are sometimes attributed to an 18th century work of fiction - The Surprising Adventures of Baron Munchausen - in which Baron Munchausen’s plan for getting himself (and his horse) out of a swamp was to pull himself out by his bootstraps. Curiously there appears to be no actual reference to his bootstraps in the story itself, where instead he uses his own hair (pigtails to be specific).</p>
<p>In any case, over time the term evolved to mean many things but with the overarching theme of ‘performing a near impossible task’, or ‘doing more with less’. It is not unheard of today in political discourse as a narrative for self-starting economic mobility - that is, “if you just put in the hard work, you will eventually be successful”.</p>
<p>In statistics specifically, the bootstrap is used to mean that the population parameter we are interested in can be sufficiently defined by the sample of data that we have. In other words, ‘the sample “pulls itself up by its bootstraps”’.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/bootstrapping.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="300"></p>
</figure>
</div>
</section>
<section id="an-important-statistical-idea" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="an-important-statistical-idea"><span class="header-section-number">2.5</span> An important statistical idea</h2>
<p>Before I get to explaining what the bootstrap is in more detail, let me start by introducing a paper that was published in 2020 by two very well-known American statisticians - <a href="https://sites.stat.columbia.edu/gelman/research/unpublished/stat50.pdf">What are the most important statistical ideas of the past 50 years</a>.</p>
<ul>
<li><p>Counterfactual causal inference</p></li>
<li><p><strong>Bootstrapping and simulation-based inference</strong></p></li>
<li><p>Overparameterized models and regularization</p></li>
<li><p>Multilevel models</p></li>
<li><p>Generic computation algorithms</p></li>
<li><p>Adaptive decision analysis</p></li>
<li><p>Robust inference</p></li>
<li><p>Exploratory data analysis</p></li>
</ul>
<p>Each of these ideas has existed in some form prior to the 1970s, both in the theoretical statistics literature and in the practice of various applied ﬁelds. But the authors consider that each has developed enough in the past 50 years to have essentially become something new and in many instances this has been facilitated by the modern computing age, as some of these techniques just weren’t practical to apply before we had fast computers. We have some ideas that you might already be familiar with from traditional statistics - counterfactual inference, multilevel model, robust inference, exploratory data analysis; and perhaps others that might be less so because they fall more into the realm of data science and predictive analytics - overparameterised models, generic algorithms and decision analysis.</p>
<p>Given that bootstrapping is one of these important statistical ideas from the last 50 years, let’s now learn some more about it.</p>
</section>
</section>
<section id="the-bootstrap" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> The Bootstrap</h1>
<section id="what-is-it" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="what-is-it"><span class="header-section-number">3.1</span> What is it?</h2>
<p>The bootstrap method is a resampling technique that estimates the sampling distribution of a statistic by treating the original sample as a proxy for the population. Instead of drawing new samples from an unknown population, which is what we learned about earlier, we simulate this process by repeatedly drawing samples - with replacement - from our single observed sample. And this allows us to approximate the variability and properties of the statistic, based on the assumption that our single, observed sample is a good representation of the underlying population.</p>
<p>In other words, the bootstrap treats the original sample as a miniature, empirical population. Each bootstrap sample is the same size as the original and is created by sampling with replacement. This “with replacement” step is critical because it ensures each bootstrap sample is a unique combination of values from the original data, simulating the variability you’d expect from a new sample.</p>
<p>So we use the same steps here that I outlined earlier in constructing the true sampling distribution - that is, for each bootstrap sample (and we typically specify thousands of them), we calculate our summary statistic and plot these as a frequency histogram. The collection of all these bootstrap sample statistics forms the bootstrap sampling distribution, which then serves as an estimate of the true sampling distribution.</p>
<p>We can then calculate other important measures such as the SE and CI’s by reading the <code>2.5</code> and <code>97.5</code> percentile values directly off the plot. We don’t actually need to invoke any mathematical formulae as we previously did - and that’s because we have an actual distribution now rather than just a theoretical one.</p>
</section>
<section id="bootstrap-sampling-distribution" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="bootstrap-sampling-distribution"><span class="header-section-number">3.2</span> Bootstrap sampling distribution</h2>
<p>Remember what our theoretical sampling distribution looked like? (scroll up if you don’t). Now when we look at our bootstrapped sampling distribution, there isn’t really much that’s changed. The main differences are that we’ve substituted our only sample for our population and we’re now ‘resampling’ from that, rather than sampling from our population. Everything else basically stays the same. Note how we can easily extract the confidence limits ‘empirically’, directly from the plot, by just ordering all the values from lowest to highest and taking the values at the <code>2.5</code> and <code>97.5</code> percentiles. These correspond to the lower and upper confidence limits, giving us <code>95%</code> coverage for the true population parameter. Remember, the beauty of this method is that it doesn’t assume a specific distribution for the data, and that is extremely useful when the classical assumptions aren’t met.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/resamp_dist2.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="sampling-distributions-reimagined" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="sampling-distributions-reimagined"><span class="header-section-number">3.3</span> Sampling distributions reimagined</h2>
<p>These aren’t my <a href="https://ds100.org/course-notes/inference_causality/inference_causality.html">images</a> but I thought I’d show them to you because it’s a tangible visual take on the same two concepts, using the global population, and I think if you’ve been having some trouble following along, this should make things a lot clearer. The top picture shows the true (or theoretical) sampling distribution for a mean. We start off with all <code>7.6</code> billion people in the world and then take multiple samples from the population, calculating the mean in each sample and then plotting the distribution of those sample means.</p>
<p>You can also easily appreciate how the bootstrap sampling distribution differs, below that. We might still start off with our population, but it remains unrealised, and all we actually have is the one sample that we draw from it. Our bootstrap samples are then resamples of that one sample, with replacement. Note how in each bootstrap sample, one individual has been sampled twice - the grey person in the first, the purple in the second and the green in the third. But that’s fine and to be expected. We then calculate the mean in each resample and plot the distribution of those means.</p>
<ul>
<li>Theoretical</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/regular_people.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="596"></p>
</figure>
</div>
<ul>
<li>Bootstrap</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/bootstrap_people.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="696"></p>
</figure>
</div>
</section>
</section>
<section id="practical-application" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Practical Application</h1>
<p>Ok, so we’ve talked a lot about the theory of bootstrapping, but let’s now see how the bootstrap can be applied in a couple of examples. We’ll look both at the sample mean and the sample correlation coefficient. The sampling distribution of the sample mean tends to be normal without much effort, but the correlation coefficient has poorer asymptotic properties, usually requiring much larger samples to become normal in shape. It is common, in fact, for it to have quite a skewed sampling distribution. So, let’s compare the confidence intervals that we get for each statistic using both the bootstrap and assuming approximate normality.</p>
<p>The primary package in R for bootstrapping is the <code>boot</code> package. Calling the corresponding <code>boot</code> function requires that you specify a minimum of <code>3</code> arguments: the first is your data; the second is a function that calculates the summary statistic that you’re interested in - for example, the sample mean; and the third is the number of bootstrap samples that you want to draw. And this is limited only by your computing power but usually at a minimum you want a thousand draws.</p>
<ul>
<li><p><code>bootobject &lt;- boot(data = , statistic = , R =, ...)</code> where:</p>
<ul>
<li><p>data = A vector, matrix or dataframe.</p></li>
<li><p>statistic = A function that produces the k statistics to be bootstrapped.</p></li>
<li><p>R = Number of bootstrap replicates (min = 1000)</p></li>
</ul></li>
</ul>
<p>Once you’ve done that, you can then ask for the bootstrap CI’s, and that is fairly simple to do with the <code>boot.ci()</code> function. This can take up to <code>3</code> arguments where you first specify the returned boot object that you created in the previous step, then you can specify the CI if you want (althoug it defaults to <code>95%</code>), and finally you specify the ‘type’ of confidence interval you want to calculate. Now there are <code>5</code> of these - but it’s probably easier to just specify ‘all’ and you can then compare among them.</p>
<ul>
<li><p><code>boot.ci(bootobject, conf =, type = )</code> where:</p>
<ul>
<li>type = The type of confidence interval returned. Possible values are “norm”, “basic”, “stud”, “perc”, “bca” and “all” (default: type=“all”)</li>
</ul></li>
</ul>
<p>From what I have read, you can really just focus on two which seem to be regarded as the most accurate - the percentile method (which I’ve already described) and the bca method - which stands for bias-corrected. It seems that the bias-corrected method edges out the percentile method as it additionally adjusts for both bias and skewness in the bootstrap distribution. It’s generally regarded as the most accurate of the lot in a general-purpose sense, especially with small to moderate samples or strong skew.</p>
</section>
<section id="sample-mean" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Sample Mean</h1>
<section id="raw-data-distribution" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="raw-data-distribution"><span class="header-section-number">5.1</span> Raw Data Distribution</h2>
<p>To do this in <code>R</code> we’re going to use an inbuilt dataset, and in fact it doesn’t even matter what that is, so I’m not going to describe it here (details are in the code at the end of this post that will allow you to fully reproduce all analyses).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/hist.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>This is the raw data distribution for the variable we’ll be bootstrapping the mean for, and it consists of <code>47</code> observations. You could argue that there’s a normal shape to it, but in all honesty, there probably aren’t enough data points to say that with certainty.</p>
<p>We’ll now take this variable and we’ll bootstrap it <code>1000</code> times - in other words we’ll take <code>1000</code> resamples each of size <code>47</code>, replacing each value in the event that it’s drawn. Then we’ll calculate the mean value in each of those <code>1000</code> resamples.</p>
</section>
<section id="sampling-distribution" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="sampling-distribution"><span class="header-section-number">5.2</span> Sampling Distribution</h2>
<p>When we construct a frequency histogram of those <code>1000</code> mean values, we see the following:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/boot_mean_samp.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>There are a couple of salient things to note:</p>
<ul>
<li><p>The first is that the bootstrap sampling distribution is quite normal in shape, even though the raw data distribution might not have been.</p></li>
<li><p>The second point is that the mean of the original sample and the mean of all the bootstrapped means is virtually identical.</p></li>
</ul>
<p>This is a good thing as it means that the sample mean is an <strong>unbiased</strong> estimator of the population mean. Another way of saying this is that “<em>if I were to repeat this study many times, the sample mean would, on average, hit the true population mean.</em>”</p>
<ul>
<li>The last thing to say about this plot is that if we wanted to obtain the bootstrapped confidence limits we could simply read off the values corresponding to the <code>2.5</code> and <code>97.5</code> percentiles from the plot. Of course, in practice you’d get your stats software to do this for you, but the point is that it’s quite easy to do and doesn’t involve any formulae.</li>
</ul>
</section>
<section id="comparison-of-95-cis" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="comparison-of-95-cis"><span class="header-section-number">5.3</span> Comparison of 95% CI’s</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/boot_mean_cis.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>And these are the <code>95%</code> CI’s from the various methods. The first one is the ‘theoretical’ - assuming normality and the others are derived from the <code>boot.ci</code> function after doing the bootstrapping procedure. Really, there’s not a lot to say about this - you can see that the coverage of all the CI’s is fairly similar, and that’s a good thing as it means you can can have increased confidence in the robustness of your results. (Note - the ‘theoretical’ CI in this case for the mean is based off a t test which enables ‘exact’ CI’s to be calculated as the PDF of the sampling distribution is known. So while I say ‘assuming normality’ in this case it’s really an exact CI).</p>
</section>
</section>
<section id="sample-correlation-coefficient" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Sample Correlation Coefficient</h1>
<section id="raw-data-distribution-1" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="raw-data-distribution-1"><span class="header-section-number">6.1</span> Raw Data Distribution</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/corplot.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>Ok - let’s now consider a different sample statistic that we might be interested in - the correlation coefficient. This is a scatterplot with overlaid density plot of the previous variable (on the x-axis) and a second variable (on the y-axis) from the same dataset. The marginal distribution of the second variable is far from normal as I’m sure you can appreciate, by looking at the density curve on the right side. When we look at the bivariate relationship in terms of the scattterplot itself, it’s not hard to imagine a negative relationship between the two variables.</p>
</section>
<section id="sampling-distribution-1" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="sampling-distribution-1"><span class="header-section-number">6.2</span> Sampling Distribution</h2>
<p>In contrast to the sample mean, the sampling distribution of the correlation coefficient does NOT have the same, simple, normal shape, straight out of the box. This statistic definitely relies on asymptotic normality based on having a large sample - larger than you would require for the sample mean.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/boot_cor_samp.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>This time when we construct a frequency histogram of those <code>1000</code> mean values, we get quite a positively skewed bootstrap sampling distribution, and there is no way we could argue this is normal in shape. The other observation that we can easily make is that the original sample correlation coefficient is different (more negative) to the mean of all the bootstrapped correlation coefficients.</p>
<p>What this reflects is that the sample correlation coefficient is a <strong>biased</strong> estimator of the population correlation coefficient. And another way of saying this is that “<em>if I were to repeat this study many times, the sample correlation would, on average, consistently be closer to zero than the true population correlation.</em>” Now, this bias is worse as the correlation approaches either plus or minus one, and with small sample sizes. The bias reduces as the sample size increases according to our large sample theory for asymptotic normality.</p>
<p>As with the sample mean, if we want to obtain empirical <code>95%</code> CI’s we can just read off the corresponding values at the <code>2.5</code> and <code>97.5</code> percentiles.</p>
</section>
<section id="comparison-of-95-cis-1" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="comparison-of-95-cis-1"><span class="header-section-number">6.3</span> Comparison of 95% CI’s</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/boot_cor_cis.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>Confidence interval coverage with the correlation coefficient is also a little different to what we previously saw with the sample mean. The theoretical and two of the bootstrap intervals - the percentile and the bias-corrected percentile are quite similar, whereas the remaining two bootstrap intervals - the normal and basic are quite different. OK, so what do we believe here? Well, the normal and basic intervals should really only be trusted when we’ve got a large sample size and a well-behaved statistic - and you could make a good argument that we don’t really have either of those two conditions being met here. Therefore it’s either the percentile method or its bias-corrected variant and as I mentioned before the latter is probably the best method, in general, to choose. When we compare the bias-corrected interval to the theoretical interval, we can see that in fact they’re not that different, but the bca is a little more conservative (i.e.&nbsp;the CI is wider) - which is always a good thing, I think, in quantifying uncertainty.</p>
<p>So at the end of the day, for these data, it’s good to be able to report both types of CI’s - theoretical and empirical from the bootstrap. And that’s because we know from the outset that we’re dealing with a sample statistic that might not conform to the theoretical assumptions for CI estimation as well as a ‘better behaved’ statistic like the sample mean.</p>
</section>
</section>
<section id="wrap-up" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> Wrap-Up</h1>
<p>You’ll be glad to know that we have reached the end. Ok, so you might be wondering, what are the main takeaways from today’s post? Well, the first main point is that SE and CI estimation is really important in quantifying the uncertainty associated with a conclusion that we are trying to make from our research.</p>
<p>Most of the time we don’t have to think to deeply about this and just let our hypothesis test and/or model do the heavy lifting for us. That’s fine, but it’s also important to have some idea of what’s happening behind the scenes, and that is for many sample statistics we are leveraging large sample assumptions about asymptotic normality to theoretically derive our Ci’s. It never hurts in these cases to run a bootstrap as well, with the aim of enhancing the robustness of our conclusions if the theoretical and empirical intervals agree, or discussing differences if they don’t.</p>
<p>Furthermore, This is NOT an option for some sample statistics that break these large-sample assumptions, and in these cases, the bootstrap is about all that we have, and therefore all we can use to quanitfy and report uncertainty estimates. For that reason, having a basic understanding of the bootstrap is a good skill to have in your statistics toolbox - you never know when you might need to use it, but you’ve then got it as an option when you do.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="co"># This script runs bootstraps on a sample mean and correlation coefficient and then plots the sampling distributions and CI's from the different methods as well as comparing to theoretical results.</span></span>
<span id="cb1-2"><a href="#cb1-2"></a></span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="fu">library</span>(ggExtra)</span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="fu">library</span>(boot)</span>
<span id="cb1-6"><a href="#cb1-6"></a></span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="fu">data</span>(<span class="st">"swiss"</span>)</span>
<span id="cb1-8"><a href="#cb1-8"></a>swiss</span>
<span id="cb1-9"><a href="#cb1-9"></a></span>
<span id="cb1-10"><a href="#cb1-10"></a><span class="co"># Function to quickly extract all CI's from a boot.ci object</span></span>
<span id="cb1-11"><a href="#cb1-11"></a>extract_boot_ci <span class="ot">&lt;-</span>  <span class="cf">function</span>(boot_ci_obj){</span>
<span id="cb1-12"><a href="#cb1-12"></a>    ci_df <span class="ot">&lt;-</span> <span class="fu">names</span>(boot_ci_obj) <span class="sc">|&gt;</span> </span>
<span id="cb1-13"><a href="#cb1-13"></a>        <span class="co"># We only want the CI types, which are stored as matrices</span></span>
<span id="cb1-14"><a href="#cb1-14"></a>        <span class="fu">keep</span>(<span class="sc">~</span> <span class="fu">is.matrix</span>(boot_ci_obj[[.x]])) <span class="sc">|&gt;</span> </span>
<span id="cb1-15"><a href="#cb1-15"></a>        <span class="fu">map_df</span>(<span class="sc">~</span> {</span>
<span id="cb1-16"><a href="#cb1-16"></a>            ci_matrix <span class="ot">&lt;-</span> boot_ci_obj[[.x]]</span>
<span id="cb1-17"><a href="#cb1-17"></a>            <span class="co"># Extract the lower/upper bounds</span></span>
<span id="cb1-18"><a href="#cb1-18"></a>            lower_bound <span class="ot">&lt;-</span> ci_matrix[<span class="dv">1</span>, <span class="fu">ncol</span>(ci_matrix) <span class="sc">-</span> <span class="dv">1</span>]</span>
<span id="cb1-19"><a href="#cb1-19"></a>            upper_bound <span class="ot">&lt;-</span> ci_matrix[<span class="dv">1</span>, <span class="fu">ncol</span>(ci_matrix)]</span>
<span id="cb1-20"><a href="#cb1-20"></a>            <span class="co"># Return a data frame for this CI type</span></span>
<span id="cb1-21"><a href="#cb1-21"></a>            <span class="fu">tibble</span>(</span>
<span id="cb1-22"><a href="#cb1-22"></a>                <span class="at">type =</span> .x,</span>
<span id="cb1-23"><a href="#cb1-23"></a>                <span class="at">lower_ci =</span> lower_bound,</span>
<span id="cb1-24"><a href="#cb1-24"></a>                <span class="at">upper_ci =</span> upper_bound</span>
<span id="cb1-25"><a href="#cb1-25"></a>            )</span>
<span id="cb1-26"><a href="#cb1-26"></a>        }) <span class="sc">|&gt;</span> </span>
<span id="cb1-27"><a href="#cb1-27"></a>        <span class="co"># Optionally, arrange the data frame for cleaner viewing</span></span>
<span id="cb1-28"><a href="#cb1-28"></a>        <span class="fu">mutate</span>(<span class="at">type =</span> <span class="fu">factor</span>(type, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"normal"</span>, <span class="st">"basic"</span>, <span class="st">"percent"</span>, <span class="st">"bca"</span>, <span class="st">'Theoretical'</span>), <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"Bootstrap - Normal"</span>, <span class="st">"Bootstrap - Basic"</span>, <span class="st">"Bootstrap - Percentile"</span>, <span class="st">"Bootstrap - Bias Corrected"</span>, <span class="st">'Theoretical'</span>))) <span class="sc">|&gt;</span> </span>
<span id="cb1-29"><a href="#cb1-29"></a>        <span class="fu">arrange</span>(type)</span>
<span id="cb1-30"><a href="#cb1-30"></a>    ci_df</span>
<span id="cb1-31"><a href="#cb1-31"></a>}</span>
<span id="cb1-32"><a href="#cb1-32"></a></span>
<span id="cb1-33"><a href="#cb1-33"></a><span class="co">#++++++++++++++++++++++++++++++</span></span>
<span id="cb1-34"><a href="#cb1-34"></a></span>
<span id="cb1-35"><a href="#cb1-35"></a><span class="co"># SAMPLE MEAN ----</span></span>
<span id="cb1-36"><a href="#cb1-36"></a></span>
<span id="cb1-37"><a href="#cb1-37"></a><span class="co"># Plot raw data</span></span>
<span id="cb1-38"><a href="#cb1-38"></a><span class="fu">ggplot</span>(swiss, <span class="fu">aes</span>(<span class="at">x =</span> Fertility)) <span class="sc">+</span></span>
<span id="cb1-39"><a href="#cb1-39"></a>    <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> ..density..), <span class="at">binwidth =</span> <span class="fl">0.5</span>, <span class="at">fill =</span> <span class="st">"lightblue"</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb1-40"><a href="#cb1-40"></a>    <span class="fu">stat_density</span>(<span class="fu">aes</span>(<span class="at">y =</span> ..density..), <span class="at">geom =</span> <span class="st">"point"</span>, <span class="at">position =</span> <span class="st">"identity"</span>, </span>
<span id="cb1-41"><a href="#cb1-41"></a>                 <span class="at">color =</span> <span class="st">"darkblue"</span>, <span class="at">size =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb1-42"><a href="#cb1-42"></a>    <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> abs) <span class="sc">+</span></span>
<span id="cb1-43"><a href="#cb1-43"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Raw Data Distribution"</span>,</span>
<span id="cb1-44"><a href="#cb1-44"></a>         <span class="at">x =</span> <span class="st">"Data Value"</span>, </span>
<span id="cb1-45"><a href="#cb1-45"></a>         <span class="at">y =</span> <span class="st">"Density"</span>) <span class="sc">+</span></span>
<span id="cb1-46"><a href="#cb1-46"></a>    <span class="fu">theme_minimal</span>()</span>
<span id="cb1-47"><a href="#cb1-47"></a></span>
<span id="cb1-48"><a href="#cb1-48"></a><span class="co"># boot function</span></span>
<span id="cb1-49"><a href="#cb1-49"></a>boot_calc_mean <span class="ot">&lt;-</span> <span class="cf">function</span>(data, indices) {</span>
<span id="cb1-50"><a href="#cb1-50"></a>    <span class="co"># Use the indices to resample the data</span></span>
<span id="cb1-51"><a href="#cb1-51"></a>    sample_data <span class="ot">&lt;-</span> data[indices]</span>
<span id="cb1-52"><a href="#cb1-52"></a>    <span class="co"># Return the statistic (mean in this case)</span></span>
<span id="cb1-53"><a href="#cb1-53"></a>    <span class="fu">return</span>(<span class="fu">mean</span>(sample_data))</span>
<span id="cb1-54"><a href="#cb1-54"></a>}</span>
<span id="cb1-55"><a href="#cb1-55"></a></span>
<span id="cb1-56"><a href="#cb1-56"></a><span class="co"># boot</span></span>
<span id="cb1-57"><a href="#cb1-57"></a><span class="fu">set.seed</span>(<span class="dv">20250111</span>)</span>
<span id="cb1-58"><a href="#cb1-58"></a>boot_mean <span class="ot">&lt;-</span> <span class="fu">boot</span>(swiss<span class="sc">$</span>Fertility, boot_calc_mean, <span class="at">R =</span> <span class="dv">1000</span>)</span>
<span id="cb1-59"><a href="#cb1-59"></a>boot_mean_CIs <span class="ot">&lt;-</span> <span class="fu">boot.ci</span>(boot_mean, <span class="at">type =</span> <span class="st">"all"</span>)</span>
<span id="cb1-60"><a href="#cb1-60"></a>boot_mean_CIs</span>
<span id="cb1-61"><a href="#cb1-61"></a></span>
<span id="cb1-62"><a href="#cb1-62"></a><span class="co"># df of bootstrapped estimates</span></span>
<span id="cb1-63"><a href="#cb1-63"></a>bootstrap_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb1-64"><a href="#cb1-64"></a>    <span class="at">bootstrap_means =</span> <span class="fu">as.vector</span>(boot_mean<span class="sc">$</span>t),</span>
<span id="cb1-65"><a href="#cb1-65"></a>    <span class="at">original_mean =</span> boot_mean<span class="sc">$</span>t0</span>
<span id="cb1-66"><a href="#cb1-66"></a>)</span>
<span id="cb1-67"><a href="#cb1-67"></a></span>
<span id="cb1-68"><a href="#cb1-68"></a><span class="co"># Calculate percentiles for confidence interval</span></span>
<span id="cb1-69"><a href="#cb1-69"></a>ci_lower <span class="ot">&lt;-</span> <span class="fu">quantile</span>(boot_mean<span class="sc">$</span>t, <span class="fl">0.025</span>)</span>
<span id="cb1-70"><a href="#cb1-70"></a>ci_upper <span class="ot">&lt;-</span> <span class="fu">quantile</span>(boot_mean<span class="sc">$</span>t, <span class="fl">0.975</span>)</span>
<span id="cb1-71"><a href="#cb1-71"></a></span>
<span id="cb1-72"><a href="#cb1-72"></a><span class="co"># Plot</span></span>
<span id="cb1-73"><a href="#cb1-73"></a><span class="fu">ggplot</span>(bootstrap_df, <span class="fu">aes</span>(<span class="at">x =</span> bootstrap_means)) <span class="sc">+</span></span>
<span id="cb1-74"><a href="#cb1-74"></a>    <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> <span class="fu">after_stat</span>(density)), <span class="at">bins =</span> <span class="dv">30</span>, </span>
<span id="cb1-75"><a href="#cb1-75"></a>                   <span class="at">fill =</span> <span class="st">"lightblue"</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb1-76"><a href="#cb1-76"></a>    <span class="fu">geom_density</span>(<span class="at">color =</span> <span class="st">"blue"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb1-77"><a href="#cb1-77"></a>    <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept =</span> original_mean, <span class="at">color =</span> <span class="st">"Mean of Original Sample"</span>), <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb1-78"><a href="#cb1-78"></a>    <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept =</span> <span class="fu">mean</span>(boot_mean<span class="sc">$</span>t), <span class="at">color =</span> <span class="st">"Mean of Bootstrap Sample Means"</span>), <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb1-79"><a href="#cb1-79"></a>    <span class="co"># Add percentile lines for 95% CI</span></span>
<span id="cb1-80"><a href="#cb1-80"></a>    <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> ci_lower, <span class="at">color =</span> <span class="st">"darkorange3"</span>, <span class="at">linetype =</span> <span class="st">"dotted"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb1-81"><a href="#cb1-81"></a>    <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> ci_upper, <span class="at">color =</span> <span class="st">"darkorange3"</span>, <span class="at">linetype =</span> <span class="st">"dotted"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb1-82"><a href="#cb1-82"></a>    <span class="co"># Add labels for percentile values</span></span>
<span id="cb1-83"><a href="#cb1-83"></a>    <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> ci_lower, <span class="at">y =</span> <span class="fu">max</span>(<span class="fu">density</span>(boot_mean<span class="sc">$</span>t)<span class="sc">$</span>y) <span class="sc">*</span> <span class="fl">0.8</span>, </span>
<span id="cb1-84"><a href="#cb1-84"></a>             <span class="at">label =</span> <span class="fu">paste</span>(<span class="st">"2.5%</span><span class="sc">\n</span><span class="st">"</span>, <span class="fu">round</span>(ci_lower, <span class="dv">2</span>)), </span>
<span id="cb1-85"><a href="#cb1-85"></a>             <span class="at">color =</span> <span class="st">"darkorange3"</span>, <span class="at">hjust =</span> <span class="fl">1.1</span>, <span class="at">size =</span> <span class="fl">3.5</span>) <span class="sc">+</span></span>
<span id="cb1-86"><a href="#cb1-86"></a>    <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> ci_upper, <span class="at">y =</span> <span class="fu">max</span>(<span class="fu">density</span>(boot_mean<span class="sc">$</span>t)<span class="sc">$</span>y) <span class="sc">*</span> <span class="fl">0.8</span>, </span>
<span id="cb1-87"><a href="#cb1-87"></a>             <span class="at">label =</span> <span class="fu">paste</span>(<span class="st">"97.5%</span><span class="sc">\n</span><span class="st">"</span>, <span class="fu">round</span>(ci_upper, <span class="dv">2</span>)), </span>
<span id="cb1-88"><a href="#cb1-88"></a>             <span class="at">color =</span> <span class="st">"darkorange3"</span>, <span class="at">hjust =</span> <span class="sc">-</span><span class="fl">0.1</span>, <span class="at">size =</span> <span class="fl">3.5</span>) <span class="sc">+</span></span>
<span id="cb1-89"><a href="#cb1-89"></a>    <span class="co"># Manual color scale for legend</span></span>
<span id="cb1-90"><a href="#cb1-90"></a>    <span class="fu">scale_color_manual</span>(<span class="at">name =</span> <span class="st">""</span>,</span>
<span id="cb1-91"><a href="#cb1-91"></a>                       <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Mean of Original Sample"</span> <span class="ot">=</span> <span class="st">"red"</span>, <span class="st">"Mean of Bootstrap Sample Means"</span> <span class="ot">=</span> <span class="st">"darkmagenta"</span>)) <span class="sc">+</span></span>
<span id="cb1-92"><a href="#cb1-92"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Bootstrap Distribution with 95% Percentile Confidence Interval"</span>,</span>
<span id="cb1-93"><a href="#cb1-93"></a>         <span class="at">x =</span> <span class="st">"Bootstrap Sample Means"</span>,</span>
<span id="cb1-94"><a href="#cb1-94"></a>         <span class="at">y =</span> <span class="st">"Density"</span>,</span>
<span id="cb1-95"><a href="#cb1-95"></a>         <span class="at">caption =</span> <span class="fu">paste</span>(<span class="st">"95% Percentile CI: ["</span>, <span class="fu">round</span>(ci_lower, <span class="dv">2</span>), <span class="st">", "</span>, <span class="fu">round</span>(ci_upper, <span class="dv">2</span>), <span class="st">"]"</span>)) <span class="sc">+</span></span>
<span id="cb1-96"><a href="#cb1-96"></a>    <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb1-97"><a href="#cb1-97"></a>    <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"top"</span>)</span>
<span id="cb1-98"><a href="#cb1-98"></a></span>
<span id="cb1-99"><a href="#cb1-99"></a><span class="co"># Compare to  (t.test gives exact CI's - not technically large sample)</span></span>
<span id="cb1-100"><a href="#cb1-100"></a>t.test_sample_ci <span class="ot">&lt;-</span>  <span class="fu">t.test</span>(swiss<span class="sc">$</span>Fertility)</span>
<span id="cb1-101"><a href="#cb1-101"></a></span>
<span id="cb1-102"><a href="#cb1-102"></a><span class="co"># Extract CI's into df</span></span>
<span id="cb1-103"><a href="#cb1-103"></a>boot_mean_CIs_df <span class="ot">&lt;-</span>  <span class="fu">extract_boot_ci</span>(boot_mean_CIs)</span>
<span id="cb1-104"><a href="#cb1-104"></a><span class="co"># Add in t.test CI's</span></span>
<span id="cb1-105"><a href="#cb1-105"></a>boot_mean_CIs_df <span class="ot">&lt;-</span>  <span class="fu">rbind</span>(boot_mean_CIs_df, <span class="fu">data.frame</span>(<span class="at">type =</span> <span class="st">"Theoretical"</span>, <span class="at">lower_ci =</span> t.test_sample_ci<span class="sc">$</span>conf.int[<span class="dv">1</span>], <span class="at">upper_ci =</span> t.test_sample_ci<span class="sc">$</span>conf.int[<span class="dv">2</span>]))</span>
<span id="cb1-106"><a href="#cb1-106"></a></span>
<span id="cb1-107"><a href="#cb1-107"></a><span class="co"># Plot all CI's for visualisation</span></span>
<span id="cb1-108"><a href="#cb1-108"></a><span class="fu">ggplot</span>(boot_mean_CIs_df) <span class="sc">+</span></span>
<span id="cb1-109"><a href="#cb1-109"></a>    <span class="fu">aes</span>(<span class="at">xmin =</span> lower_ci, <span class="at">xmax =</span> upper_ci, <span class="at">y =</span> type, <span class="at">color =</span> type) <span class="sc">+</span> </span>
<span id="cb1-110"><a href="#cb1-110"></a>    <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> boot_mean<span class="sc">$</span>t0, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">linewidth =</span> <span class="fl">1.2</span>) <span class="sc">+</span> </span>
<span id="cb1-111"><a href="#cb1-111"></a>    <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">mean</span>(boot_mean<span class="sc">$</span>t), <span class="at">color =</span> <span class="st">"darkmagenta"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">linewidth =</span> <span class="fl">1.2</span>) <span class="sc">+</span> </span>
<span id="cb1-112"><a href="#cb1-112"></a>    <span class="fu">geom_errorbar</span>() <span class="sc">+</span> </span>
<span id="cb1-113"><a href="#cb1-113"></a>    <span class="fu">theme_minimal</span>() <span class="sc">+</span> </span>
<span id="cb1-114"><a href="#cb1-114"></a>    <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>) <span class="sc">+</span> </span>
<span id="cb1-115"><a href="#cb1-115"></a>    <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">""</span>)</span>
<span id="cb1-116"><a href="#cb1-116"></a>    </span>
<span id="cb1-117"><a href="#cb1-117"></a></span>
<span id="cb1-118"><a href="#cb1-118"></a><span class="co">#++++++++++++++++++++++++++++++</span></span>
<span id="cb1-119"><a href="#cb1-119"></a></span>
<span id="cb1-120"><a href="#cb1-120"></a><span class="co"># SAMPLE CORRELATION COEFFICIENT ----</span></span>
<span id="cb1-121"><a href="#cb1-121"></a></span>
<span id="cb1-122"><a href="#cb1-122"></a><span class="co"># Plot bivariate raw data</span></span>
<span id="cb1-123"><a href="#cb1-123"></a>scatterplot <span class="ot">&lt;-</span>  <span class="fu">ggplot</span>(swiss, <span class="fu">aes</span>(<span class="at">x =</span> Fertility, <span class="at">y =</span> Education)) <span class="sc">+</span></span>
<span id="cb1-124"><a href="#cb1-124"></a>    <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"darkblue"</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb1-125"><a href="#cb1-125"></a>    <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb1-126"><a href="#cb1-126"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Bivariate Raw Data Distribution"</span>,</span>
<span id="cb1-127"><a href="#cb1-127"></a>         <span class="at">x =</span> <span class="st">"Data Value 1"</span>,</span>
<span id="cb1-128"><a href="#cb1-128"></a>         <span class="at">y =</span> <span class="st">"Data Value 2"</span>)</span>
<span id="cb1-129"><a href="#cb1-129"></a><span class="co"># Add the marginal density plots using ggMarginal().</span></span>
<span id="cb1-130"><a href="#cb1-130"></a><span class="co"># The 'type' argument specifies the type of marginal plot (e.g., "density", "histogram", "boxplot").</span></span>
<span id="cb1-131"><a href="#cb1-131"></a><span class="co"># The 'fill' argument sets the fill color of the marginal plots.</span></span>
<span id="cb1-132"><a href="#cb1-132"></a><span class="fu">ggMarginal</span>(scatterplot,</span>
<span id="cb1-133"><a href="#cb1-133"></a>           <span class="at">type =</span> <span class="st">"density"</span>,</span>
<span id="cb1-134"><a href="#cb1-134"></a>           <span class="at">fill =</span> <span class="st">"#D55E00"</span>,</span>
<span id="cb1-135"><a href="#cb1-135"></a>           <span class="at">alpha =</span> <span class="fl">0.7</span>)</span>
<span id="cb1-136"><a href="#cb1-136"></a></span>
<span id="cb1-137"><a href="#cb1-137"></a><span class="co"># boot function (note: data should be a data frame or matrix with 2 columns)</span></span>
<span id="cb1-138"><a href="#cb1-138"></a>boot_calc_cor <span class="ot">&lt;-</span> <span class="cf">function</span>(data, indices) {</span>
<span id="cb1-139"><a href="#cb1-139"></a>    <span class="co"># Resample the data using indices (this resamples paired observations)</span></span>
<span id="cb1-140"><a href="#cb1-140"></a>    resampled_data <span class="ot">&lt;-</span> data[indices, ]</span>
<span id="cb1-141"><a href="#cb1-141"></a>    <span class="co"># Calculate correlation between the two variables</span></span>
<span id="cb1-142"><a href="#cb1-142"></a>    <span class="fu">cor</span>(resampled_data[, <span class="dv">1</span>], resampled_data[, <span class="dv">2</span>])</span>
<span id="cb1-143"><a href="#cb1-143"></a>}</span>
<span id="cb1-144"><a href="#cb1-144"></a></span>
<span id="cb1-145"><a href="#cb1-145"></a><span class="co"># boot</span></span>
<span id="cb1-146"><a href="#cb1-146"></a><span class="fu">set.seed</span>(<span class="dv">20250111</span>)</span>
<span id="cb1-147"><a href="#cb1-147"></a>boot_cor <span class="ot">&lt;-</span> <span class="fu">boot</span>(<span class="fu">cbind</span>(swiss<span class="sc">$</span>Fertility, swiss<span class="sc">$</span>Education), boot_calc_cor, <span class="at">R =</span> <span class="dv">1000</span>)</span>
<span id="cb1-148"><a href="#cb1-148"></a>boot_cor_CIs <span class="ot">&lt;-</span> <span class="fu">boot.ci</span>(boot_cor, <span class="at">type =</span> <span class="st">"all"</span>)</span>
<span id="cb1-149"><a href="#cb1-149"></a>boot_cor_CIs</span>
<span id="cb1-150"><a href="#cb1-150"></a></span>
<span id="cb1-151"><a href="#cb1-151"></a><span class="co"># df of bootstrapped estimates</span></span>
<span id="cb1-152"><a href="#cb1-152"></a>bootstrap_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb1-153"><a href="#cb1-153"></a>    <span class="at">bootstrap_cors =</span> <span class="fu">as.vector</span>(boot_cor<span class="sc">$</span>t),</span>
<span id="cb1-154"><a href="#cb1-154"></a>    <span class="at">original_cor =</span> boot_cor<span class="sc">$</span>t0</span>
<span id="cb1-155"><a href="#cb1-155"></a>)</span>
<span id="cb1-156"><a href="#cb1-156"></a></span>
<span id="cb1-157"><a href="#cb1-157"></a><span class="co"># Calculate percentiles for confidence interval</span></span>
<span id="cb1-158"><a href="#cb1-158"></a>ci_lower <span class="ot">&lt;-</span> <span class="fu">quantile</span>(boot_cor<span class="sc">$</span>t, <span class="fl">0.025</span>)</span>
<span id="cb1-159"><a href="#cb1-159"></a>ci_upper <span class="ot">&lt;-</span> <span class="fu">quantile</span>(boot_cor<span class="sc">$</span>t, <span class="fl">0.975</span>)</span>
<span id="cb1-160"><a href="#cb1-160"></a></span>
<span id="cb1-161"><a href="#cb1-161"></a><span class="co"># Plot</span></span>
<span id="cb1-162"><a href="#cb1-162"></a><span class="fu">ggplot</span>(bootstrap_df, <span class="fu">aes</span>(<span class="at">x =</span> bootstrap_cors)) <span class="sc">+</span></span>
<span id="cb1-163"><a href="#cb1-163"></a>    <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> <span class="fu">after_stat</span>(density)), <span class="at">bins =</span> <span class="dv">30</span>, </span>
<span id="cb1-164"><a href="#cb1-164"></a>                   <span class="at">fill =</span> <span class="st">"lightblue"</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb1-165"><a href="#cb1-165"></a>    <span class="fu">geom_density</span>(<span class="at">color =</span> <span class="st">"blue"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb1-166"><a href="#cb1-166"></a>    <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept =</span> original_cor, <span class="at">color =</span> <span class="st">"Correlation of Original Sample"</span>), <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb1-167"><a href="#cb1-167"></a>    <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept =</span> <span class="fu">mean</span>(boot_cor<span class="sc">$</span>t), <span class="at">color =</span> <span class="st">"Mean of Bootstrap Sample Correlations"</span>), <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb1-168"><a href="#cb1-168"></a>    <span class="co"># Add percentile lines for 95% CI</span></span>
<span id="cb1-169"><a href="#cb1-169"></a>    <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> ci_lower, <span class="at">color =</span> <span class="st">"darkorange3"</span>, <span class="at">linetype =</span> <span class="st">"dotted"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb1-170"><a href="#cb1-170"></a>    <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> ci_upper, <span class="at">color =</span> <span class="st">"darkorange3"</span>, <span class="at">linetype =</span> <span class="st">"dotted"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb1-171"><a href="#cb1-171"></a>    <span class="co"># Add labels for percentile values</span></span>
<span id="cb1-172"><a href="#cb1-172"></a>    <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> ci_lower, <span class="at">y =</span> <span class="fu">max</span>(<span class="fu">density</span>(boot_mean<span class="sc">$</span>t)<span class="sc">$</span>y) <span class="sc">*</span> <span class="fl">0.8</span>, </span>
<span id="cb1-173"><a href="#cb1-173"></a>             <span class="at">label =</span> <span class="fu">paste</span>(<span class="st">"2.5%</span><span class="sc">\n</span><span class="st">"</span>, <span class="fu">round</span>(ci_lower, <span class="dv">2</span>)), </span>
<span id="cb1-174"><a href="#cb1-174"></a>             <span class="at">color =</span> <span class="st">"darkorange3"</span>, <span class="at">hjust =</span> <span class="fl">1.1</span>, <span class="at">vjust =</span> <span class="sc">-</span><span class="dv">7</span>, <span class="at">size =</span> <span class="fl">3.5</span>) <span class="sc">+</span></span>
<span id="cb1-175"><a href="#cb1-175"></a>    <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> ci_upper, <span class="at">y =</span> <span class="fu">max</span>(<span class="fu">density</span>(boot_mean<span class="sc">$</span>t)<span class="sc">$</span>y) <span class="sc">*</span> <span class="fl">0.8</span>, </span>
<span id="cb1-176"><a href="#cb1-176"></a>             <span class="at">label =</span> <span class="fu">paste</span>(<span class="st">"97.5%</span><span class="sc">\n</span><span class="st">"</span>, <span class="fu">round</span>(ci_upper, <span class="dv">2</span>)), </span>
<span id="cb1-177"><a href="#cb1-177"></a>             <span class="at">color =</span> <span class="st">"darkorange3"</span>, <span class="at">hjust =</span> <span class="sc">-</span><span class="fl">0.1</span>, <span class="at">vjust =</span> <span class="sc">-</span><span class="dv">7</span>, <span class="at">size =</span> <span class="fl">3.5</span>) <span class="sc">+</span></span>
<span id="cb1-178"><a href="#cb1-178"></a>    <span class="co"># Manual color scale for legend</span></span>
<span id="cb1-179"><a href="#cb1-179"></a>    <span class="fu">scale_color_manual</span>(<span class="at">name =</span> <span class="st">""</span>,</span>
<span id="cb1-180"><a href="#cb1-180"></a>                       <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Correlation of Original Sample"</span> <span class="ot">=</span> <span class="st">"red"</span>, <span class="st">"Mean of Bootstrap Sample Correlations"</span> <span class="ot">=</span> <span class="st">"darkmagenta"</span>)) <span class="sc">+</span></span>
<span id="cb1-181"><a href="#cb1-181"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Bootstrap Distribution with 95% Percentile Confidence Interval"</span>,</span>
<span id="cb1-182"><a href="#cb1-182"></a>         <span class="at">x =</span> <span class="st">"Bootstrap Sample Correlations"</span>,</span>
<span id="cb1-183"><a href="#cb1-183"></a>         <span class="at">y =</span> <span class="st">"Density"</span>,</span>
<span id="cb1-184"><a href="#cb1-184"></a>         <span class="at">caption =</span> <span class="fu">paste</span>(<span class="st">"95% Percentile CI: ["</span>, <span class="fu">round</span>(ci_lower, <span class="dv">2</span>), <span class="st">", "</span>, <span class="fu">round</span>(ci_upper, <span class="dv">2</span>), <span class="st">"]"</span>)) <span class="sc">+</span></span>
<span id="cb1-185"><a href="#cb1-185"></a>    <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb1-186"><a href="#cb1-186"></a>    <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"top"</span>)</span>
<span id="cb1-187"><a href="#cb1-187"></a></span>
<span id="cb1-188"><a href="#cb1-188"></a><span class="co"># Compare to (cor.test gives large sample approximation)</span></span>
<span id="cb1-189"><a href="#cb1-189"></a>cor.test_sample_ci <span class="ot">&lt;-</span>  <span class="fu">cor.test</span>(swiss<span class="sc">$</span>Fertility, swiss<span class="sc">$</span>Education)</span>
<span id="cb1-190"><a href="#cb1-190"></a></span>
<span id="cb1-191"><a href="#cb1-191"></a><span class="co"># Extract CI's into df</span></span>
<span id="cb1-192"><a href="#cb1-192"></a>boot_cor_CIs_df <span class="ot">&lt;-</span>  <span class="fu">extract_boot_ci</span>(boot_cor_CIs)</span>
<span id="cb1-193"><a href="#cb1-193"></a><span class="co"># Add in t.test CI's</span></span>
<span id="cb1-194"><a href="#cb1-194"></a>boot_cor_CIs_df <span class="ot">&lt;-</span>  <span class="fu">rbind</span>(boot_cor_CIs_df, <span class="fu">data.frame</span>(<span class="at">type =</span> <span class="st">"Theoretical"</span>, <span class="at">lower_ci =</span> cor.test_sample_ci<span class="sc">$</span>conf.int[<span class="dv">1</span>], <span class="at">upper_ci =</span> cor.test_sample_ci<span class="sc">$</span>conf.int[<span class="dv">2</span>]))</span>
<span id="cb1-195"><a href="#cb1-195"></a></span>
<span id="cb1-196"><a href="#cb1-196"></a><span class="co"># Plot all CI's for visualisation</span></span>
<span id="cb1-197"><a href="#cb1-197"></a><span class="fu">ggplot</span>(boot_cor_CIs_df) <span class="sc">+</span></span>
<span id="cb1-198"><a href="#cb1-198"></a>    <span class="fu">aes</span>(<span class="at">xmin =</span> lower_ci, <span class="at">xmax =</span> upper_ci, <span class="at">y =</span> type, <span class="at">color =</span> type) <span class="sc">+</span> </span>
<span id="cb1-199"><a href="#cb1-199"></a>    <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> boot_cor<span class="sc">$</span>t0, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">linewidth =</span> <span class="fl">1.2</span>) <span class="sc">+</span> </span>
<span id="cb1-200"><a href="#cb1-200"></a>    <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">mean</span>(boot_cor<span class="sc">$</span>t), <span class="at">color =</span> <span class="st">"darkmagenta"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">linewidth =</span> <span class="fl">1.2</span>) <span class="sc">+</span> </span>
<span id="cb1-201"><a href="#cb1-201"></a>    <span class="fu">geom_errorbar</span>() <span class="sc">+</span> </span>
<span id="cb1-202"><a href="#cb1-202"></a>    <span class="fu">theme_minimal</span>() <span class="sc">+</span> </span>
<span id="cb1-203"><a href="#cb1-203"></a>    <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>) <span class="sc">+</span> </span>
<span id="cb1-204"><a href="#cb1-204"></a>    <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">""</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="pgseye/Weekly_Stats_Tips" data-repo-id="R_kgDOKvfOfQ" data-category="General" data-category-id="DIC_kwDOKvfOfc4CbFWq" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark"><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb2" data-shortcodes="false"><pre class="sourceCode numberSource markdown number-lines code-with-copy"><code class="sourceCode markdown"><span id="cb2-1"><a href="#cb2-1"></a><span class="co">---</span></span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="an">title:</span><span class="co"> "A Gentle Introduction to the Bootstrap"</span></span>
<span id="cb2-3"><a href="#cb2-3"></a><span class="an">date:</span><span class="co"> 2025-11-14</span></span>
<span id="cb2-4"><a href="#cb2-4"></a><span class="an">categories:</span><span class="co"> [code, concept, modelling]</span></span>
<span id="cb2-5"><a href="#cb2-5"></a><span class="an">image:</span><span class="co"> "images/bootstrapping.png"</span></span>
<span id="cb2-6"><a href="#cb2-6"></a><span class="an">description:</span><span class="co"> "Primer and Intuition for Computational Non-Parametric Resampling"</span></span>
<span id="cb2-7"><a href="#cb2-7"></a><span class="co">---</span></span>
<span id="cb2-8"><a href="#cb2-8"></a></span>
<span id="cb2-9"><a href="#cb2-9"></a>Today I thought we'd discuss a stats topic that I'm sure you've heard about before, but perhaps not really understood, nor yet had a pressing need to use - bootstrap resampling. Now, I have to admit that I haven't applied this technique much in my own day to day work either, but it's an important statistical tool to have an understanding of, because there are times when it's the only approach you can use. And the reason for that is the bootstrap can be considered a swiss army knife of parameter uncertainty estimation when the usual parametric distribution assumptions and resulting formulaic approximations that we base our standard error calculations on, either can't be trusted or are simply unknown.</span>
<span id="cb2-10"><a href="#cb2-10"></a></span>
<span id="cb2-11"><a href="#cb2-11"></a><span class="fu"># The Basis of Inferential Statistics</span></span>
<span id="cb2-12"><a href="#cb2-12"></a></span>
<span id="cb2-13"><a href="#cb2-13"></a>OK, before we dive into the main topic, let's refresh our memories on some basic statistical concepts that are important in helping to understand what the bootstrap is all about. As you know, the application of statistics in our research is ultimately to allow us to make conclusions about some parameter of interest or importance - for example, that could be something as simple as the median survival or the average EDSS in an MS population.</span>
<span id="cb2-14"><a href="#cb2-14"></a></span>
<span id="cb2-15"><a href="#cb2-15"></a>We use data and models to do make those conclusions.</span>
<span id="cb2-16"><a href="#cb2-16"></a></span>
<span id="cb2-17"><a href="#cb2-17"></a>Now, in nearly all cases we want to know something about the population that we are studying, but all we have are data from a sample - because it's just not practical to measure everyone. So we use statistical inference to infer or draw these conclusions about the population from the available sample. However, a very reasonable question may then be asked, and that is:</span>
<span id="cb2-18"><a href="#cb2-18"></a></span>
<span id="cb2-19"><a href="#cb2-19"></a>"How sure can we be of our conclusions?"</span>
<span id="cb2-20"><a href="#cb2-20"></a></span>
<span id="cb2-21"><a href="#cb2-21"></a>We can't easily make claims about 'effects' when we can't also quantify the margin of error associated with those claims. That is all the difference between asserting that you have strong evidence or in fact, pretty weak evidence after all. And that is where it's important to always remember that statistical inference is really a two-side coin - we are not only interested in the estimation of the parameter that we want to know about, but also in the estimation of the uncertainty associated with it.</span>
<span id="cb2-22"><a href="#cb2-22"></a></span>
<span id="cb2-23"><a href="#cb2-23"></a><span class="al">![](images/pop_samp.png)</span>{fig-align="center"}</span>
<span id="cb2-24"><a href="#cb2-24"></a></span>
<span id="cb2-25"><a href="#cb2-25"></a><span class="fu"># The Sampling Distribution</span></span>
<span id="cb2-26"><a href="#cb2-26"></a></span>
<span id="cb2-27"><a href="#cb2-27"></a><span class="fu">## Basic concepts</span></span>
<span id="cb2-28"><a href="#cb2-28"></a></span>
<span id="cb2-29"><a href="#cb2-29"></a>And this is where the fundamental idea of the *sampling distribution* comes into play. In a nutshell, the sampling distribution represents the **theoretical** distribution of a sample statistic that's derived from repeatedly randomly sampling a population of interest. Now this is a thought exercise only - we don't do it for obvious reasons in practice - but it allows us to make assumptions about the behaviour of the population parameter that we are trying to estimate. (Note - while I say 'theoretical' above, these distributions can now be verified *in silico* but in the pre-computer era were confirmed empirically by a combination of mathematical derivation and physical simulation - i.e. bootstrapping by hand!)</span>
<span id="cb2-30"><a href="#cb2-30"></a></span>
<span id="cb2-31"><a href="#cb2-31"></a>In this thought exercise we would have a population that we are interested in calculating a parameter for, and we'd draw a sample of observations from this population. We'd then calculate the corresponding sample statistic - let's say it's a mean value - and we'd plot that on a frequency histogram. We would then repeat that process many times, plotting each mean value along the way. The resulting plot would show the distribution of all the sample means - and this is what we call the sampling distribution of the sample statistic. It's important to note that this is NOT the distribution of the data itself, but the distribution of a summary statistic derived from the data.</span>
<span id="cb2-32"><a href="#cb2-32"></a></span>
<span id="cb2-33"><a href="#cb2-33"></a><span class="al">![](images/samp_dist.png)</span>{fig-align="center"}</span>
<span id="cb2-34"><a href="#cb2-34"></a></span>
<span id="cb2-35"><a href="#cb2-35"></a>Now, depending on the sample size, the shape of the underlying raw data distribution and the specific summary statistic we're interested in, sampling distributions for many statistics often end up looking normal (or close to normal) in shape. And that allows us to leverage fairly simple normal distribution properties such as the mean and standard deviation (SD) to infer the population mean and it's associated uncertainty. The mean should converge to the actual population parameter and the SD tells us about the uncertainty in the estimation of the parameter - and in fact is directly interpretable from the sampling distribution itself, as the standard error (SE). Once we have the SE it becomes trivial to calculate the 95% confidence interval (CI).</span>
<span id="cb2-36"><a href="#cb2-36"></a></span>
<span id="cb2-37"><a href="#cb2-37"></a>The point in telling you all of this is to highlight to you is that we can use just a single sample to form probabilistic statements about a population parameter, rather than needing to measure the entire population.</span>
<span id="cb2-38"><a href="#cb2-38"></a></span>
<span id="cb2-39"><a href="#cb2-39"></a><span class="fu">## When it works</span></span>
<span id="cb2-40"><a href="#cb2-40"></a></span>
<span id="cb2-41"><a href="#cb2-41"></a>Most of the time the theory of parametric sampling distributions will work just fine for what you want to do. Probability density functions (PDF's) that define the 'shape' of the sampling distribution have been derived for many sample statistics. These equations are sometimes referred to as 'closed-form solutions'. Some PDF's are fairly simple, other's are almost intractably complex and some are simply unknown. But what is important about this, is that when you know the PDF for a sampling distribution, you can calculate **exact** 95% CI's.</span>
<span id="cb2-42"><a href="#cb2-42"></a></span>
<span id="cb2-43"><a href="#cb2-43"></a>When PDF's become too difficult or are simply unknown, we can start to leverage approximations. And that probably explains why I haven't needed to bootstrap much in my own work - the classic central limit theorem (CLT) does its job pretty well. The CLT basically states that you can have whatever shaped raw data distribution you want - flat, skewed, bi-modal - whatever, but when you then construct a sampling distribution from the resulting sample means, that distribution will be normal in shape (if you've got a large enough sample).</span>
<span id="cb2-44"><a href="#cb2-44"></a></span>
<span id="cb2-45"><a href="#cb2-45"></a>The thing is, the logic of the central limit theorem translates fairly well to most other sample statistics of interest - for example, medians, proportions, correlations, regression coefficients, and more - through a concept called **large-sample asymptotic normality**. This approximation basically says that if our sample is large enough, the sampling distributions of these other parameters will likewise approach normality in terms of shape. What that means at the end of the day is that we can use fairly simple(-ish) equations for large sample approximations to estimate SE's and 95% CI's. The equations for the SE for the mean and proportion are shown below and I'm sure you've seen these before.</span>
<span id="cb2-46"><a href="#cb2-46"></a></span>
<span id="cb2-47"><a href="#cb2-47"></a>$$ \bar{x} \pm 1.96^* \frac{s}{\sqrt{n}} \hspace{2cm} \widehat{p} \pm 1.96^* \sqrt{\frac{\widehat{p}(1 - \widehat{p})}{n}} $$</span>
<span id="cb2-48"><a href="#cb2-48"></a></span>
<span id="cb2-49"><a href="#cb2-49"></a><span class="fu">## When it doesn't</span></span>
<span id="cb2-50"><a href="#cb2-50"></a></span>
<span id="cb2-51"><a href="#cb2-51"></a>Clearly, there are situations that can occasionally arise when basic sampling theory might not be adequate for your analytic needs, otherwise we wouldn't have this post. To my mind there are three main reasons why you might look further afield to a resampling method like the bootstrap to support your analyses.</span>
<span id="cb2-52"><a href="#cb2-52"></a></span>
<span id="cb2-53"><a href="#cb2-53"></a><span class="ss">-   </span>The first is sample size. Asymptotic normal theory relies on a 'large' sample size to be accurate, and the bootstrap deals with smaller samples much better. However, it is itself not immune to small sample bias (when <span class="in">`n`</span> becomes quite small - say <span class="sc">\&lt;</span> <span class="in">`15`</span>). In such cases not much can save you unless you collect more data, so you might just need to rely on descriptive statistics only.</span>
<span id="cb2-54"><a href="#cb2-54"></a></span>
<span id="cb2-55"><a href="#cb2-55"></a><span class="ss">-   </span>The second situation is where equations for the SE are either so complex as to be virtually intractable, or simply don't exist (as described above). Here you can use the bootstrap to estimate the sampling distribution directly with relative ease.</span>
<span id="cb2-56"><a href="#cb2-56"></a></span>
<span id="cb2-57"><a href="#cb2-57"></a><span class="ss">-   </span>Finally, for sampling distributions that depart quite obviously from normality. Here the large-sample approximations just don't work well, but you can use the bootstrap in these cases to actually capture that non-normal shape and apply it in valid inference.</span>
<span id="cb2-58"><a href="#cb2-58"></a></span>
<span id="cb2-59"><a href="#cb2-59"></a><span class="fu">## Why is it called the bootstrap?</span></span>
<span id="cb2-60"><a href="#cb2-60"></a></span>
<span id="cb2-61"><a href="#cb2-61"></a>Alright - let's actually talk about The Bootstrap! There is some interesting history in how the bootstrap came to be called what it is, as it's etymology isn't from the statistical domain. The <span class="co">[</span><span class="ot">origins</span><span class="co">](https://en.wikipedia.org/wiki/Bootstrapping)</span> of the term are sometimes attributed to an 18th century work of fiction - The Surprising Adventures of Baron Munchausen - in which Baron Munchausen's plan for getting himself (and his horse) out of a swamp was to pull himself out by his bootstraps. Curiously there appears to be no actual reference to his bootstraps in the story itself, where instead he uses his own hair (pigtails to be specific).</span>
<span id="cb2-62"><a href="#cb2-62"></a></span>
<span id="cb2-63"><a href="#cb2-63"></a>In any case, over time the term evolved to mean many things but with the overarching theme of 'performing a near impossible task', or 'doing more with less'. It is not unheard of today in political discourse as a narrative for self-starting economic mobility - that is, "if you just put in the hard work, you will eventually be successful".</span>
<span id="cb2-64"><a href="#cb2-64"></a></span>
<span id="cb2-65"><a href="#cb2-65"></a>In statistics specifically, the bootstrap is used to mean that the population parameter we are interested in can be sufficiently defined by the sample of data that we have. In other words, 'the sample "pulls itself up by its bootstraps"'.</span>
<span id="cb2-66"><a href="#cb2-66"></a></span>
<span id="cb2-67"><a href="#cb2-67"></a><span class="al">![](images/bootstrapping.png)</span>{fig-align="center" width="300"}</span>
<span id="cb2-68"><a href="#cb2-68"></a></span>
<span id="cb2-69"><a href="#cb2-69"></a><span class="fu">## An important statistical idea</span></span>
<span id="cb2-70"><a href="#cb2-70"></a></span>
<span id="cb2-71"><a href="#cb2-71"></a>Before I get to explaining what the bootstrap is in more detail, let me start by introducing a paper that was published in 2020 by two very well-known American statisticians - <span class="co">[</span><span class="ot">What are the most important statistical ideas of the past 50 years</span><span class="co">](https://sites.stat.columbia.edu/gelman/research/unpublished/stat50.pdf)</span>.</span>
<span id="cb2-72"><a href="#cb2-72"></a></span>
<span id="cb2-73"><a href="#cb2-73"></a><span class="ss">-   </span>Counterfactual causal inference</span>
<span id="cb2-74"><a href="#cb2-74"></a></span>
<span id="cb2-75"><a href="#cb2-75"></a><span class="ss">-   </span>**Bootstrapping and simulation-based inference**</span>
<span id="cb2-76"><a href="#cb2-76"></a></span>
<span id="cb2-77"><a href="#cb2-77"></a><span class="ss">-   </span>Overparameterized models and regularization</span>
<span id="cb2-78"><a href="#cb2-78"></a></span>
<span id="cb2-79"><a href="#cb2-79"></a><span class="ss">-   </span>Multilevel models</span>
<span id="cb2-80"><a href="#cb2-80"></a></span>
<span id="cb2-81"><a href="#cb2-81"></a><span class="ss">-   </span>Generic computation algorithms</span>
<span id="cb2-82"><a href="#cb2-82"></a></span>
<span id="cb2-83"><a href="#cb2-83"></a><span class="ss">-   </span>Adaptive decision analysis</span>
<span id="cb2-84"><a href="#cb2-84"></a></span>
<span id="cb2-85"><a href="#cb2-85"></a><span class="ss">-   </span>Robust inference</span>
<span id="cb2-86"><a href="#cb2-86"></a></span>
<span id="cb2-87"><a href="#cb2-87"></a><span class="ss">-   </span>Exploratory data analysis</span>
<span id="cb2-88"><a href="#cb2-88"></a></span>
<span id="cb2-89"><a href="#cb2-89"></a>Each of these ideas has existed in some form prior to the 1970s, both in the theoretical statistics literature and in the practice of various applied ﬁelds. But the authors consider that each has developed enough in the past 50 years to have essentially become something new and in many instances this has been facilitated by the modern computing age, as some of these techniques just weren't practical to apply before we had fast computers. We have some ideas that you might already be familiar with from traditional statistics - counterfactual inference, multilevel model, robust inference, exploratory data analysis; and perhaps others that might be less so because they fall more into the realm of data science and predictive analytics - overparameterised models, generic algorithms and decision analysis.</span>
<span id="cb2-90"><a href="#cb2-90"></a></span>
<span id="cb2-91"><a href="#cb2-91"></a>Given that bootstrapping is one of these important statistical ideas from the last 50 years, let's now learn some more about it.</span>
<span id="cb2-92"><a href="#cb2-92"></a></span>
<span id="cb2-93"><a href="#cb2-93"></a><span class="fu"># The Bootstrap</span></span>
<span id="cb2-94"><a href="#cb2-94"></a></span>
<span id="cb2-95"><a href="#cb2-95"></a><span class="fu">## What is it?</span></span>
<span id="cb2-96"><a href="#cb2-96"></a></span>
<span id="cb2-97"><a href="#cb2-97"></a>The bootstrap method is a resampling technique that estimates the sampling distribution of a statistic by treating the original sample as a proxy for the population. Instead of drawing new samples from an unknown population, which is what we learned about earlier, we simulate this process by repeatedly drawing samples - with replacement - from our single observed sample. And this allows us to approximate the variability and properties of the statistic, based on the assumption that our single, observed sample is a good representation of the underlying population.</span>
<span id="cb2-98"><a href="#cb2-98"></a></span>
<span id="cb2-99"><a href="#cb2-99"></a>In other words, the bootstrap treats the original sample as a miniature, empirical population. Each bootstrap sample is the same size as the original and is created by sampling with replacement. This "with replacement" step is critical because it ensures each bootstrap sample is a unique combination of values from the original data, simulating the variability you'd expect from a new sample.</span>
<span id="cb2-100"><a href="#cb2-100"></a></span>
<span id="cb2-101"><a href="#cb2-101"></a>So we use the same steps here that I outlined earlier in constructing the true sampling distribution - that is, for each bootstrap sample (and we typically specify thousands of them), we calculate our summary statistic and plot these as a frequency histogram. The collection of all these bootstrap sample statistics forms the bootstrap sampling distribution, which then serves as an estimate of the true sampling distribution.</span>
<span id="cb2-102"><a href="#cb2-102"></a></span>
<span id="cb2-103"><a href="#cb2-103"></a>We can then calculate other important measures such as the SE and CI's by reading the <span class="in">`2.5`</span> and <span class="in">`97.5`</span> percentile values directly off the plot. We don't actually need to invoke any mathematical formulae as we previously did - and that's because we have an actual distribution now rather than just a theoretical one.</span>
<span id="cb2-104"><a href="#cb2-104"></a></span>
<span id="cb2-105"><a href="#cb2-105"></a><span class="fu">## Bootstrap sampling distribution</span></span>
<span id="cb2-106"><a href="#cb2-106"></a></span>
<span id="cb2-107"><a href="#cb2-107"></a>Remember what our theoretical sampling distribution looked like? (scroll up if you don't). Now when we look at our bootstrapped sampling distribution, there isn't really much that's changed. The main differences are that we've substituted our only sample for our population and we're now 'resampling' from that, rather than sampling from our population. Everything else basically stays the same. Note how we can easily extract the confidence limits 'empirically', directly from the plot, by just ordering all the values from lowest to highest and taking the values at the <span class="in">`2.5`</span> and <span class="in">`97.5`</span> percentiles. These correspond to the lower and upper confidence limits, giving us <span class="in">`95%`</span> coverage for the true population parameter. Remember, the beauty of this method is that it doesn't assume a specific distribution for the data, and that is extremely useful when the classical assumptions aren't met.</span>
<span id="cb2-108"><a href="#cb2-108"></a></span>
<span id="cb2-109"><a href="#cb2-109"></a><span class="al">![](images/resamp_dist2.png)</span>{fig-align="center"}</span>
<span id="cb2-110"><a href="#cb2-110"></a></span>
<span id="cb2-111"><a href="#cb2-111"></a><span class="fu">## Sampling distributions reimagined</span></span>
<span id="cb2-112"><a href="#cb2-112"></a></span>
<span id="cb2-113"><a href="#cb2-113"></a>These aren't my <span class="co">[</span><span class="ot">images</span><span class="co">](https://ds100.org/course-notes/inference_causality/inference_causality.html)</span> but I thought I'd show them to you because it's a tangible visual take on the same two concepts, using the global population, and I think if you've been having some trouble following along, this should make things a lot clearer. The top picture shows the true (or theoretical) sampling distribution for a mean. We start off with all <span class="in">`7.6`</span> billion people in the world and then take multiple samples from the population, calculating the mean in each sample and then plotting the distribution of those sample means.</span>
<span id="cb2-114"><a href="#cb2-114"></a></span>
<span id="cb2-115"><a href="#cb2-115"></a>You can also easily appreciate how the bootstrap sampling distribution differs, below that. We might still start off with our population, but it remains unrealised, and all we actually have is the one sample that we draw from it. Our bootstrap samples are then resamples of that one sample, with replacement. Note how in each bootstrap sample, one individual has been sampled twice - the grey person in the first, the purple in the second and the green in the third. But that's fine and to be expected. We then calculate the mean in each resample and plot the distribution of those means.</span>
<span id="cb2-116"><a href="#cb2-116"></a></span>
<span id="cb2-117"><a href="#cb2-117"></a><span class="ss">-   </span>Theoretical</span>
<span id="cb2-118"><a href="#cb2-118"></a></span>
<span id="cb2-119"><a href="#cb2-119"></a><span class="al">![](images/regular_people.png)</span>{fig-align="center" width="596"}</span>
<span id="cb2-120"><a href="#cb2-120"></a></span>
<span id="cb2-121"><a href="#cb2-121"></a><span class="ss">-   </span>Bootstrap</span>
<span id="cb2-122"><a href="#cb2-122"></a></span>
<span id="cb2-123"><a href="#cb2-123"></a><span class="al">![](images/bootstrap_people.png)</span>{fig-align="center" width="696"}</span>
<span id="cb2-124"><a href="#cb2-124"></a></span>
<span id="cb2-125"><a href="#cb2-125"></a><span class="fu"># Practical Application</span></span>
<span id="cb2-126"><a href="#cb2-126"></a></span>
<span id="cb2-127"><a href="#cb2-127"></a>Ok, so we've talked a lot about the theory of bootstrapping, but let's now see how the bootstrap can be applied in a couple of examples. We'll look both at the sample mean and the sample correlation coefficient. The sampling distribution of the sample mean tends to be normal without much effort, but the correlation coefficient has poorer asymptotic properties, usually requiring much larger samples to become normal in shape. It is common, in fact, for it to have quite a skewed sampling distribution. So, let's compare the confidence intervals that we get for each statistic using both the bootstrap and assuming approximate normality.</span>
<span id="cb2-128"><a href="#cb2-128"></a></span>
<span id="cb2-129"><a href="#cb2-129"></a>The primary package in R for bootstrapping is the <span class="in">`boot`</span> package. Calling the corresponding <span class="in">`boot`</span> function requires that you specify a minimum of <span class="in">`3`</span> arguments: the first is your data; the second is a function that calculates the summary statistic that you're interested in - for example, the sample mean; and the third is the number of bootstrap samples that you want to draw. And this is limited only by your computing power but usually at a minimum you want a thousand draws.</span>
<span id="cb2-130"><a href="#cb2-130"></a></span>
<span id="cb2-131"><a href="#cb2-131"></a><span class="ss">-   </span><span class="in">`bootobject &lt;- boot(data = , statistic = , R =, ...)`</span> where:</span>
<span id="cb2-132"><a href="#cb2-132"></a></span>
<span id="cb2-133"><a href="#cb2-133"></a><span class="ss">    -   </span>data = A vector, matrix or dataframe.</span>
<span id="cb2-134"><a href="#cb2-134"></a></span>
<span id="cb2-135"><a href="#cb2-135"></a><span class="ss">    -   </span>statistic = A function that produces the k statistics to be bootstrapped.</span>
<span id="cb2-136"><a href="#cb2-136"></a></span>
<span id="cb2-137"><a href="#cb2-137"></a><span class="ss">    -   </span>R = Number of bootstrap replicates (min = 1000)</span>
<span id="cb2-138"><a href="#cb2-138"></a></span>
<span id="cb2-139"><a href="#cb2-139"></a>Once you've done that, you can then ask for the bootstrap CI's, and that is fairly simple to do with the <span class="in">`boot.ci()`</span> function. This can take up to <span class="in">`3`</span> arguments where you first specify the returned boot object that you created in the previous step, then you can specify the CI if you want (althoug it defaults to <span class="in">`95%`</span>), and finally you specify the 'type' of confidence interval you want to calculate. Now there are <span class="in">`5`</span> of these - but it's probably easier to just specify 'all' and you can then compare among them.</span>
<span id="cb2-140"><a href="#cb2-140"></a></span>
<span id="cb2-141"><a href="#cb2-141"></a><span class="ss">-   </span><span class="in">`boot.ci(bootobject, conf =, type = )`</span> where:</span>
<span id="cb2-142"><a href="#cb2-142"></a></span>
<span id="cb2-143"><a href="#cb2-143"></a><span class="ss">    -   </span>type = The type of confidence interval returned. Possible values are "norm", "basic", "stud", "perc", "bca" and "all" (default: type="all")</span>
<span id="cb2-144"><a href="#cb2-144"></a></span>
<span id="cb2-145"><a href="#cb2-145"></a>From what I have read, you can really just focus on two which seem to be regarded as the most accurate - the percentile method (which I've already described) and the bca method - which stands for bias-corrected. It seems that the bias-corrected method edges out the percentile method as it additionally adjusts for both bias and skewness in the bootstrap distribution. It's generally regarded as the most accurate of the lot in a general-purpose sense, especially with small to moderate samples or strong skew.</span>
<span id="cb2-146"><a href="#cb2-146"></a></span>
<span id="cb2-147"><a href="#cb2-147"></a><span class="fu"># Sample Mean</span></span>
<span id="cb2-148"><a href="#cb2-148"></a></span>
<span id="cb2-149"><a href="#cb2-149"></a><span class="fu">## Raw Data Distribution</span></span>
<span id="cb2-150"><a href="#cb2-150"></a></span>
<span id="cb2-151"><a href="#cb2-151"></a>To do this in <span class="in">`R`</span> we're going to use an inbuilt dataset, and in fact it doesn't even matter what that is, so I'm not going to describe it here (details are in the code at the end of this post that will allow you to fully reproduce all analyses).</span>
<span id="cb2-152"><a href="#cb2-152"></a></span>
<span id="cb2-153"><a href="#cb2-153"></a><span class="al">![](images/hist.png)</span>{fig-align="center"}</span>
<span id="cb2-154"><a href="#cb2-154"></a></span>
<span id="cb2-155"><a href="#cb2-155"></a>This is the raw data distribution for the variable we'll be bootstrapping the mean for, and it consists of <span class="in">`47`</span> observations. You could argue that there's a normal shape to it, but in all honesty, there probably aren't enough data points to say that with certainty.</span>
<span id="cb2-156"><a href="#cb2-156"></a></span>
<span id="cb2-157"><a href="#cb2-157"></a>We'll now take this variable and we'll bootstrap it <span class="in">`1000`</span> times - in other words we'll take <span class="in">`1000`</span> resamples each of size <span class="in">`47`</span>, replacing each value in the event that it's drawn. Then we'll calculate the mean value in each of those <span class="in">`1000`</span> resamples.</span>
<span id="cb2-158"><a href="#cb2-158"></a></span>
<span id="cb2-159"><a href="#cb2-159"></a><span class="fu">## Sampling Distribution</span></span>
<span id="cb2-160"><a href="#cb2-160"></a></span>
<span id="cb2-161"><a href="#cb2-161"></a>When we construct a frequency histogram of those <span class="in">`1000`</span> mean values, we see the following:</span>
<span id="cb2-162"><a href="#cb2-162"></a></span>
<span id="cb2-163"><a href="#cb2-163"></a><span class="al">![](images/boot_mean_samp.png)</span>{fig-align="center"}</span>
<span id="cb2-164"><a href="#cb2-164"></a></span>
<span id="cb2-165"><a href="#cb2-165"></a>There are a couple of salient things to note:</span>
<span id="cb2-166"><a href="#cb2-166"></a></span>
<span id="cb2-167"><a href="#cb2-167"></a><span class="ss">-   </span>The first is that the bootstrap sampling distribution is quite normal in shape, even though the raw data distribution might not have been.</span>
<span id="cb2-168"><a href="#cb2-168"></a></span>
<span id="cb2-169"><a href="#cb2-169"></a><span class="ss">-   </span>The second point is that the mean of the original sample and the mean of all the bootstrapped means is virtually identical.</span>
<span id="cb2-170"><a href="#cb2-170"></a></span>
<span id="cb2-171"><a href="#cb2-171"></a>This is a good thing as it means that the sample mean is an **unbiased** estimator of the population mean. Another way of saying this is that "*if I were to repeat this study many times, the sample mean would, on average, hit the true population mean.*"</span>
<span id="cb2-172"><a href="#cb2-172"></a></span>
<span id="cb2-173"><a href="#cb2-173"></a><span class="ss">-   </span>The last thing to say about this plot is that if we wanted to obtain the bootstrapped confidence limits we could simply read off the values corresponding to the <span class="in">`2.5`</span> and <span class="in">`97.5`</span> percentiles from the plot. Of course, in practice you'd get your stats software to do this for you, but the point is that it's quite easy to do and doesn't involve any formulae.</span>
<span id="cb2-174"><a href="#cb2-174"></a></span>
<span id="cb2-175"><a href="#cb2-175"></a><span class="fu">## Comparison of 95% CI's</span></span>
<span id="cb2-176"><a href="#cb2-176"></a></span>
<span id="cb2-177"><a href="#cb2-177"></a><span class="al">![](images/boot_mean_cis.png)</span>{fig-align="center"}</span>
<span id="cb2-178"><a href="#cb2-178"></a></span>
<span id="cb2-179"><a href="#cb2-179"></a>And these are the <span class="in">`95%`</span> CI's from the various methods. The first one is the 'theoretical' - assuming normality and the others are derived from the <span class="in">`boot.ci`</span> function after doing the bootstrapping procedure. Really, there's not a lot to say about this - you can see that the coverage of all the CI's is fairly similar, and that's a good thing as it means you can can have increased confidence in the robustness of your results. (Note - the 'theoretical' CI in this case for the mean is based off a t test which enables 'exact' CI's to be calculated as the PDF of the sampling distribution is known. So while I say 'assuming normality' in this case it's really an exact CI).</span>
<span id="cb2-180"><a href="#cb2-180"></a></span>
<span id="cb2-181"><a href="#cb2-181"></a><span class="fu"># Sample Correlation Coefficient</span></span>
<span id="cb2-182"><a href="#cb2-182"></a></span>
<span id="cb2-183"><a href="#cb2-183"></a><span class="fu">## Raw Data Distribution</span></span>
<span id="cb2-184"><a href="#cb2-184"></a></span>
<span id="cb2-185"><a href="#cb2-185"></a><span class="al">![](images/corplot.png)</span>{fig-align="center"}</span>
<span id="cb2-186"><a href="#cb2-186"></a></span>
<span id="cb2-187"><a href="#cb2-187"></a>Ok - let's now consider a different sample statistic that we might be interested in - the correlation coefficient. This is a scatterplot with overlaid density plot of the previous variable (on the x-axis) and a second variable (on the y-axis) from the same dataset. The marginal distribution of the second variable is far from normal as I'm sure you can appreciate, by looking at the density curve on the right side. When we look at the bivariate relationship in terms of the scattterplot itself, it's not hard to imagine a negative relationship between the two variables.</span>
<span id="cb2-188"><a href="#cb2-188"></a></span>
<span id="cb2-189"><a href="#cb2-189"></a><span class="fu">## Sampling Distribution</span></span>
<span id="cb2-190"><a href="#cb2-190"></a></span>
<span id="cb2-191"><a href="#cb2-191"></a>In contrast to the sample mean, the sampling distribution of the correlation coefficient does NOT have the same, simple, normal shape, straight out of the box. This statistic definitely relies on asymptotic normality based on having a large sample - larger than you would require for the sample mean.</span>
<span id="cb2-192"><a href="#cb2-192"></a></span>
<span id="cb2-193"><a href="#cb2-193"></a><span class="al">![](images/boot_cor_samp.png)</span>{fig-align="center"}</span>
<span id="cb2-194"><a href="#cb2-194"></a></span>
<span id="cb2-195"><a href="#cb2-195"></a>This time when we construct a frequency histogram of those <span class="in">`1000`</span> mean values, we get quite a positively skewed bootstrap sampling distribution, and there is no way we could argue this is normal in shape. The other observation that we can easily make is that the original sample correlation coefficient is different (more negative) to the mean of all the bootstrapped correlation coefficients.</span>
<span id="cb2-196"><a href="#cb2-196"></a></span>
<span id="cb2-197"><a href="#cb2-197"></a>What this reflects is that the sample correlation coefficient is a **biased** estimator of the population correlation coefficient. And another way of saying this is that "*if I were to repeat this study many times, the sample correlation would, on average, consistently be closer to zero than the true population correlation.*" Now, this bias is worse as the correlation approaches either plus or minus one, and with small sample sizes. The bias reduces as the sample size increases according to our large sample theory for asymptotic normality.</span>
<span id="cb2-198"><a href="#cb2-198"></a></span>
<span id="cb2-199"><a href="#cb2-199"></a>As with the sample mean, if we want to obtain empirical <span class="in">`95%`</span> CI's we can just read off the corresponding values at the <span class="in">`2.5`</span> and <span class="in">`97.5`</span> percentiles.</span>
<span id="cb2-200"><a href="#cb2-200"></a></span>
<span id="cb2-201"><a href="#cb2-201"></a><span class="fu">## Comparison of 95% CI's</span></span>
<span id="cb2-202"><a href="#cb2-202"></a></span>
<span id="cb2-203"><a href="#cb2-203"></a><span class="al">![](images/boot_cor_cis.png)</span>{fig-align="center"}</span>
<span id="cb2-204"><a href="#cb2-204"></a></span>
<span id="cb2-205"><a href="#cb2-205"></a>Confidence interval coverage with the correlation coefficient is also a little different to what we previously saw with the sample mean. The theoretical and two of the bootstrap intervals - the percentile and the bias-corrected percentile are quite similar, whereas the remaining two bootstrap intervals - the normal and basic are quite different. OK, so what do we believe here? Well, the normal and basic intervals should really only be trusted when we've got a large sample size and a well-behaved statistic - and you could make a good argument that we don't really have either of those two conditions being met here. Therefore it's either the percentile method or its bias-corrected variant and as I mentioned before the latter is probably the best method, in general, to choose. When we compare the bias-corrected interval to the theoretical interval, we can see that in fact they're not that different, but the bca is a little more conservative (i.e. the CI is wider) - which is always a good thing, I think, in quantifying uncertainty.</span>
<span id="cb2-206"><a href="#cb2-206"></a></span>
<span id="cb2-207"><a href="#cb2-207"></a>So at the end of the day, for these data, it's good to be able to report both types of CI's - theoretical and empirical from the bootstrap. And that's because we know from the outset that we're dealing with a sample statistic that might not conform to the theoretical assumptions for CI estimation as well as a 'better behaved' statistic like the sample mean.</span>
<span id="cb2-208"><a href="#cb2-208"></a></span>
<span id="cb2-209"><a href="#cb2-209"></a><span class="fu"># Wrap-Up</span></span>
<span id="cb2-210"><a href="#cb2-210"></a></span>
<span id="cb2-211"><a href="#cb2-211"></a>You'll be glad to know that we have reached the end. Ok, so you might be wondering, what are the main takeaways from today's post? Well, the first main point is that SE and CI estimation is really important in quantifying the uncertainty associated with a conclusion that we are trying to make from our research.</span>
<span id="cb2-212"><a href="#cb2-212"></a></span>
<span id="cb2-213"><a href="#cb2-213"></a>Most of the time we don't have to think to deeply about this and just let our hypothesis test and/or model do the heavy lifting for us. That's fine, but it's also important to have some idea of what's happening behind the scenes, and that is for many sample statistics we are leveraging large sample assumptions about asymptotic normality to theoretically derive our Ci's. It never hurts in these cases to run a bootstrap as well, with the aim of enhancing the robustness of our conclusions if the theoretical and empirical intervals agree, or discussing differences if they don't.</span>
<span id="cb2-214"><a href="#cb2-214"></a></span>
<span id="cb2-215"><a href="#cb2-215"></a>Furthermore, This is NOT an option for some sample statistics that break these large-sample assumptions, and in these cases, the bootstrap is about all that we have, and therefore all we can use to quanitfy and report uncertainty estimates. For that reason, having a basic understanding of the bootstrap is a good skill to have in your statistics toolbox - you never know when you might need to use it, but you've then got it as an option when you do.</span>
<span id="cb2-216"><a href="#cb2-216"></a></span>
<span id="cb2-219"><a href="#cb2-219"></a><span class="in">```{r}</span></span>
<span id="cb2-220"><a href="#cb2-220"></a><span class="co">#| eval: false</span></span>
<span id="cb2-221"><a href="#cb2-221"></a><span class="co"># This script runs bootstraps on a sample mean and correlation coefficient and then plots the sampling distributions and CI's from the different methods as well as comparing to theoretical results.</span></span>
<span id="cb2-222"><a href="#cb2-222"></a></span>
<span id="cb2-223"><a href="#cb2-223"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb2-224"><a href="#cb2-224"></a><span class="fu">library</span>(ggExtra)</span>
<span id="cb2-225"><a href="#cb2-225"></a><span class="fu">library</span>(boot)</span>
<span id="cb2-226"><a href="#cb2-226"></a></span>
<span id="cb2-227"><a href="#cb2-227"></a><span class="fu">data</span>(<span class="st">"swiss"</span>)</span>
<span id="cb2-228"><a href="#cb2-228"></a>swiss</span>
<span id="cb2-229"><a href="#cb2-229"></a></span>
<span id="cb2-230"><a href="#cb2-230"></a><span class="co"># Function to quickly extract all CI's from a boot.ci object</span></span>
<span id="cb2-231"><a href="#cb2-231"></a>extract_boot_ci <span class="ot">&lt;-</span>  <span class="cf">function</span>(boot_ci_obj){</span>
<span id="cb2-232"><a href="#cb2-232"></a>    ci_df <span class="ot">&lt;-</span> <span class="fu">names</span>(boot_ci_obj) <span class="sc">|&gt;</span> </span>
<span id="cb2-233"><a href="#cb2-233"></a>        <span class="co"># We only want the CI types, which are stored as matrices</span></span>
<span id="cb2-234"><a href="#cb2-234"></a>        <span class="fu">keep</span>(<span class="sc">~</span> <span class="fu">is.matrix</span>(boot_ci_obj[[.x]])) <span class="sc">|&gt;</span> </span>
<span id="cb2-235"><a href="#cb2-235"></a>        <span class="fu">map_df</span>(<span class="sc">~</span> {</span>
<span id="cb2-236"><a href="#cb2-236"></a>            ci_matrix <span class="ot">&lt;-</span> boot_ci_obj[[.x]]</span>
<span id="cb2-237"><a href="#cb2-237"></a>            <span class="co"># Extract the lower/upper bounds</span></span>
<span id="cb2-238"><a href="#cb2-238"></a>            lower_bound <span class="ot">&lt;-</span> ci_matrix[<span class="dv">1</span>, <span class="fu">ncol</span>(ci_matrix) <span class="sc">-</span> <span class="dv">1</span>]</span>
<span id="cb2-239"><a href="#cb2-239"></a>            upper_bound <span class="ot">&lt;-</span> ci_matrix[<span class="dv">1</span>, <span class="fu">ncol</span>(ci_matrix)]</span>
<span id="cb2-240"><a href="#cb2-240"></a>            <span class="co"># Return a data frame for this CI type</span></span>
<span id="cb2-241"><a href="#cb2-241"></a>            <span class="fu">tibble</span>(</span>
<span id="cb2-242"><a href="#cb2-242"></a>                <span class="at">type =</span> .x,</span>
<span id="cb2-243"><a href="#cb2-243"></a>                <span class="at">lower_ci =</span> lower_bound,</span>
<span id="cb2-244"><a href="#cb2-244"></a>                <span class="at">upper_ci =</span> upper_bound</span>
<span id="cb2-245"><a href="#cb2-245"></a>            )</span>
<span id="cb2-246"><a href="#cb2-246"></a>        }) <span class="sc">|&gt;</span> </span>
<span id="cb2-247"><a href="#cb2-247"></a>        <span class="co"># Optionally, arrange the data frame for cleaner viewing</span></span>
<span id="cb2-248"><a href="#cb2-248"></a>        <span class="fu">mutate</span>(<span class="at">type =</span> <span class="fu">factor</span>(type, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"normal"</span>, <span class="st">"basic"</span>, <span class="st">"percent"</span>, <span class="st">"bca"</span>, <span class="st">'Theoretical'</span>), <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"Bootstrap - Normal"</span>, <span class="st">"Bootstrap - Basic"</span>, <span class="st">"Bootstrap - Percentile"</span>, <span class="st">"Bootstrap - Bias Corrected"</span>, <span class="st">'Theoretical'</span>))) <span class="sc">|&gt;</span> </span>
<span id="cb2-249"><a href="#cb2-249"></a>        <span class="fu">arrange</span>(type)</span>
<span id="cb2-250"><a href="#cb2-250"></a>    ci_df</span>
<span id="cb2-251"><a href="#cb2-251"></a>}</span>
<span id="cb2-252"><a href="#cb2-252"></a></span>
<span id="cb2-253"><a href="#cb2-253"></a><span class="co">#++++++++++++++++++++++++++++++</span></span>
<span id="cb2-254"><a href="#cb2-254"></a></span>
<span id="cb2-255"><a href="#cb2-255"></a><span class="co"># SAMPLE MEAN ----</span></span>
<span id="cb2-256"><a href="#cb2-256"></a></span>
<span id="cb2-257"><a href="#cb2-257"></a><span class="co"># Plot raw data</span></span>
<span id="cb2-258"><a href="#cb2-258"></a><span class="fu">ggplot</span>(swiss, <span class="fu">aes</span>(<span class="at">x =</span> Fertility)) <span class="sc">+</span></span>
<span id="cb2-259"><a href="#cb2-259"></a>    <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> ..density..), <span class="at">binwidth =</span> <span class="fl">0.5</span>, <span class="at">fill =</span> <span class="st">"lightblue"</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb2-260"><a href="#cb2-260"></a>    <span class="fu">stat_density</span>(<span class="fu">aes</span>(<span class="at">y =</span> ..density..), <span class="at">geom =</span> <span class="st">"point"</span>, <span class="at">position =</span> <span class="st">"identity"</span>, </span>
<span id="cb2-261"><a href="#cb2-261"></a>                 <span class="at">color =</span> <span class="st">"darkblue"</span>, <span class="at">size =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb2-262"><a href="#cb2-262"></a>    <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> abs) <span class="sc">+</span></span>
<span id="cb2-263"><a href="#cb2-263"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Raw Data Distribution"</span>,</span>
<span id="cb2-264"><a href="#cb2-264"></a>         <span class="at">x =</span> <span class="st">"Data Value"</span>, </span>
<span id="cb2-265"><a href="#cb2-265"></a>         <span class="at">y =</span> <span class="st">"Density"</span>) <span class="sc">+</span></span>
<span id="cb2-266"><a href="#cb2-266"></a>    <span class="fu">theme_minimal</span>()</span>
<span id="cb2-267"><a href="#cb2-267"></a></span>
<span id="cb2-268"><a href="#cb2-268"></a><span class="co"># boot function</span></span>
<span id="cb2-269"><a href="#cb2-269"></a>boot_calc_mean <span class="ot">&lt;-</span> <span class="cf">function</span>(data, indices) {</span>
<span id="cb2-270"><a href="#cb2-270"></a>    <span class="co"># Use the indices to resample the data</span></span>
<span id="cb2-271"><a href="#cb2-271"></a>    sample_data <span class="ot">&lt;-</span> data[indices]</span>
<span id="cb2-272"><a href="#cb2-272"></a>    <span class="co"># Return the statistic (mean in this case)</span></span>
<span id="cb2-273"><a href="#cb2-273"></a>    <span class="fu">return</span>(<span class="fu">mean</span>(sample_data))</span>
<span id="cb2-274"><a href="#cb2-274"></a>}</span>
<span id="cb2-275"><a href="#cb2-275"></a></span>
<span id="cb2-276"><a href="#cb2-276"></a><span class="co"># boot</span></span>
<span id="cb2-277"><a href="#cb2-277"></a><span class="fu">set.seed</span>(<span class="dv">20250111</span>)</span>
<span id="cb2-278"><a href="#cb2-278"></a>boot_mean <span class="ot">&lt;-</span> <span class="fu">boot</span>(swiss<span class="sc">$</span>Fertility, boot_calc_mean, <span class="at">R =</span> <span class="dv">1000</span>)</span>
<span id="cb2-279"><a href="#cb2-279"></a>boot_mean_CIs <span class="ot">&lt;-</span> <span class="fu">boot.ci</span>(boot_mean, <span class="at">type =</span> <span class="st">"all"</span>)</span>
<span id="cb2-280"><a href="#cb2-280"></a>boot_mean_CIs</span>
<span id="cb2-281"><a href="#cb2-281"></a></span>
<span id="cb2-282"><a href="#cb2-282"></a><span class="co"># df of bootstrapped estimates</span></span>
<span id="cb2-283"><a href="#cb2-283"></a>bootstrap_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb2-284"><a href="#cb2-284"></a>    <span class="at">bootstrap_means =</span> <span class="fu">as.vector</span>(boot_mean<span class="sc">$</span>t),</span>
<span id="cb2-285"><a href="#cb2-285"></a>    <span class="at">original_mean =</span> boot_mean<span class="sc">$</span>t0</span>
<span id="cb2-286"><a href="#cb2-286"></a>)</span>
<span id="cb2-287"><a href="#cb2-287"></a></span>
<span id="cb2-288"><a href="#cb2-288"></a><span class="co"># Calculate percentiles for confidence interval</span></span>
<span id="cb2-289"><a href="#cb2-289"></a>ci_lower <span class="ot">&lt;-</span> <span class="fu">quantile</span>(boot_mean<span class="sc">$</span>t, <span class="fl">0.025</span>)</span>
<span id="cb2-290"><a href="#cb2-290"></a>ci_upper <span class="ot">&lt;-</span> <span class="fu">quantile</span>(boot_mean<span class="sc">$</span>t, <span class="fl">0.975</span>)</span>
<span id="cb2-291"><a href="#cb2-291"></a></span>
<span id="cb2-292"><a href="#cb2-292"></a><span class="co"># Plot</span></span>
<span id="cb2-293"><a href="#cb2-293"></a><span class="fu">ggplot</span>(bootstrap_df, <span class="fu">aes</span>(<span class="at">x =</span> bootstrap_means)) <span class="sc">+</span></span>
<span id="cb2-294"><a href="#cb2-294"></a>    <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> <span class="fu">after_stat</span>(density)), <span class="at">bins =</span> <span class="dv">30</span>, </span>
<span id="cb2-295"><a href="#cb2-295"></a>                   <span class="at">fill =</span> <span class="st">"lightblue"</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb2-296"><a href="#cb2-296"></a>    <span class="fu">geom_density</span>(<span class="at">color =</span> <span class="st">"blue"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb2-297"><a href="#cb2-297"></a>    <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept =</span> original_mean, <span class="at">color =</span> <span class="st">"Mean of Original Sample"</span>), <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb2-298"><a href="#cb2-298"></a>    <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept =</span> <span class="fu">mean</span>(boot_mean<span class="sc">$</span>t), <span class="at">color =</span> <span class="st">"Mean of Bootstrap Sample Means"</span>), <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb2-299"><a href="#cb2-299"></a>    <span class="co"># Add percentile lines for 95% CI</span></span>
<span id="cb2-300"><a href="#cb2-300"></a>    <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> ci_lower, <span class="at">color =</span> <span class="st">"darkorange3"</span>, <span class="at">linetype =</span> <span class="st">"dotted"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb2-301"><a href="#cb2-301"></a>    <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> ci_upper, <span class="at">color =</span> <span class="st">"darkorange3"</span>, <span class="at">linetype =</span> <span class="st">"dotted"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb2-302"><a href="#cb2-302"></a>    <span class="co"># Add labels for percentile values</span></span>
<span id="cb2-303"><a href="#cb2-303"></a>    <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> ci_lower, <span class="at">y =</span> <span class="fu">max</span>(<span class="fu">density</span>(boot_mean<span class="sc">$</span>t)<span class="sc">$</span>y) <span class="sc">*</span> <span class="fl">0.8</span>, </span>
<span id="cb2-304"><a href="#cb2-304"></a>             <span class="at">label =</span> <span class="fu">paste</span>(<span class="st">"2.5%</span><span class="sc">\n</span><span class="st">"</span>, <span class="fu">round</span>(ci_lower, <span class="dv">2</span>)), </span>
<span id="cb2-305"><a href="#cb2-305"></a>             <span class="at">color =</span> <span class="st">"darkorange3"</span>, <span class="at">hjust =</span> <span class="fl">1.1</span>, <span class="at">size =</span> <span class="fl">3.5</span>) <span class="sc">+</span></span>
<span id="cb2-306"><a href="#cb2-306"></a>    <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> ci_upper, <span class="at">y =</span> <span class="fu">max</span>(<span class="fu">density</span>(boot_mean<span class="sc">$</span>t)<span class="sc">$</span>y) <span class="sc">*</span> <span class="fl">0.8</span>, </span>
<span id="cb2-307"><a href="#cb2-307"></a>             <span class="at">label =</span> <span class="fu">paste</span>(<span class="st">"97.5%</span><span class="sc">\n</span><span class="st">"</span>, <span class="fu">round</span>(ci_upper, <span class="dv">2</span>)), </span>
<span id="cb2-308"><a href="#cb2-308"></a>             <span class="at">color =</span> <span class="st">"darkorange3"</span>, <span class="at">hjust =</span> <span class="sc">-</span><span class="fl">0.1</span>, <span class="at">size =</span> <span class="fl">3.5</span>) <span class="sc">+</span></span>
<span id="cb2-309"><a href="#cb2-309"></a>    <span class="co"># Manual color scale for legend</span></span>
<span id="cb2-310"><a href="#cb2-310"></a>    <span class="fu">scale_color_manual</span>(<span class="at">name =</span> <span class="st">""</span>,</span>
<span id="cb2-311"><a href="#cb2-311"></a>                       <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Mean of Original Sample"</span> <span class="ot">=</span> <span class="st">"red"</span>, <span class="st">"Mean of Bootstrap Sample Means"</span> <span class="ot">=</span> <span class="st">"darkmagenta"</span>)) <span class="sc">+</span></span>
<span id="cb2-312"><a href="#cb2-312"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Bootstrap Distribution with 95% Percentile Confidence Interval"</span>,</span>
<span id="cb2-313"><a href="#cb2-313"></a>         <span class="at">x =</span> <span class="st">"Bootstrap Sample Means"</span>,</span>
<span id="cb2-314"><a href="#cb2-314"></a>         <span class="at">y =</span> <span class="st">"Density"</span>,</span>
<span id="cb2-315"><a href="#cb2-315"></a>         <span class="at">caption =</span> <span class="fu">paste</span>(<span class="st">"95% Percentile CI: ["</span>, <span class="fu">round</span>(ci_lower, <span class="dv">2</span>), <span class="st">", "</span>, <span class="fu">round</span>(ci_upper, <span class="dv">2</span>), <span class="st">"]"</span>)) <span class="sc">+</span></span>
<span id="cb2-316"><a href="#cb2-316"></a>    <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb2-317"><a href="#cb2-317"></a>    <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"top"</span>)</span>
<span id="cb2-318"><a href="#cb2-318"></a></span>
<span id="cb2-319"><a href="#cb2-319"></a><span class="co"># Compare to  (t.test gives exact CI's - not technically large sample)</span></span>
<span id="cb2-320"><a href="#cb2-320"></a>t.test_sample_ci <span class="ot">&lt;-</span>  <span class="fu">t.test</span>(swiss<span class="sc">$</span>Fertility)</span>
<span id="cb2-321"><a href="#cb2-321"></a></span>
<span id="cb2-322"><a href="#cb2-322"></a><span class="co"># Extract CI's into df</span></span>
<span id="cb2-323"><a href="#cb2-323"></a>boot_mean_CIs_df <span class="ot">&lt;-</span>  <span class="fu">extract_boot_ci</span>(boot_mean_CIs)</span>
<span id="cb2-324"><a href="#cb2-324"></a><span class="co"># Add in t.test CI's</span></span>
<span id="cb2-325"><a href="#cb2-325"></a>boot_mean_CIs_df <span class="ot">&lt;-</span>  <span class="fu">rbind</span>(boot_mean_CIs_df, <span class="fu">data.frame</span>(<span class="at">type =</span> <span class="st">"Theoretical"</span>, <span class="at">lower_ci =</span> t.test_sample_ci<span class="sc">$</span>conf.int[<span class="dv">1</span>], <span class="at">upper_ci =</span> t.test_sample_ci<span class="sc">$</span>conf.int[<span class="dv">2</span>]))</span>
<span id="cb2-326"><a href="#cb2-326"></a></span>
<span id="cb2-327"><a href="#cb2-327"></a><span class="co"># Plot all CI's for visualisation</span></span>
<span id="cb2-328"><a href="#cb2-328"></a><span class="fu">ggplot</span>(boot_mean_CIs_df) <span class="sc">+</span></span>
<span id="cb2-329"><a href="#cb2-329"></a>    <span class="fu">aes</span>(<span class="at">xmin =</span> lower_ci, <span class="at">xmax =</span> upper_ci, <span class="at">y =</span> type, <span class="at">color =</span> type) <span class="sc">+</span> </span>
<span id="cb2-330"><a href="#cb2-330"></a>    <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> boot_mean<span class="sc">$</span>t0, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">linewidth =</span> <span class="fl">1.2</span>) <span class="sc">+</span> </span>
<span id="cb2-331"><a href="#cb2-331"></a>    <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">mean</span>(boot_mean<span class="sc">$</span>t), <span class="at">color =</span> <span class="st">"darkmagenta"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">linewidth =</span> <span class="fl">1.2</span>) <span class="sc">+</span> </span>
<span id="cb2-332"><a href="#cb2-332"></a>    <span class="fu">geom_errorbar</span>() <span class="sc">+</span> </span>
<span id="cb2-333"><a href="#cb2-333"></a>    <span class="fu">theme_minimal</span>() <span class="sc">+</span> </span>
<span id="cb2-334"><a href="#cb2-334"></a>    <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>) <span class="sc">+</span> </span>
<span id="cb2-335"><a href="#cb2-335"></a>    <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">""</span>)</span>
<span id="cb2-336"><a href="#cb2-336"></a>    </span>
<span id="cb2-337"><a href="#cb2-337"></a></span>
<span id="cb2-338"><a href="#cb2-338"></a><span class="co">#++++++++++++++++++++++++++++++</span></span>
<span id="cb2-339"><a href="#cb2-339"></a></span>
<span id="cb2-340"><a href="#cb2-340"></a><span class="co"># SAMPLE CORRELATION COEFFICIENT ----</span></span>
<span id="cb2-341"><a href="#cb2-341"></a></span>
<span id="cb2-342"><a href="#cb2-342"></a><span class="co"># Plot bivariate raw data</span></span>
<span id="cb2-343"><a href="#cb2-343"></a>scatterplot <span class="ot">&lt;-</span>  <span class="fu">ggplot</span>(swiss, <span class="fu">aes</span>(<span class="at">x =</span> Fertility, <span class="at">y =</span> Education)) <span class="sc">+</span></span>
<span id="cb2-344"><a href="#cb2-344"></a>    <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"darkblue"</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb2-345"><a href="#cb2-345"></a>    <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb2-346"><a href="#cb2-346"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Bivariate Raw Data Distribution"</span>,</span>
<span id="cb2-347"><a href="#cb2-347"></a>         <span class="at">x =</span> <span class="st">"Data Value 1"</span>,</span>
<span id="cb2-348"><a href="#cb2-348"></a>         <span class="at">y =</span> <span class="st">"Data Value 2"</span>)</span>
<span id="cb2-349"><a href="#cb2-349"></a><span class="co"># Add the marginal density plots using ggMarginal().</span></span>
<span id="cb2-350"><a href="#cb2-350"></a><span class="co"># The 'type' argument specifies the type of marginal plot (e.g., "density", "histogram", "boxplot").</span></span>
<span id="cb2-351"><a href="#cb2-351"></a><span class="co"># The 'fill' argument sets the fill color of the marginal plots.</span></span>
<span id="cb2-352"><a href="#cb2-352"></a><span class="fu">ggMarginal</span>(scatterplot,</span>
<span id="cb2-353"><a href="#cb2-353"></a>           <span class="at">type =</span> <span class="st">"density"</span>,</span>
<span id="cb2-354"><a href="#cb2-354"></a>           <span class="at">fill =</span> <span class="st">"#D55E00"</span>,</span>
<span id="cb2-355"><a href="#cb2-355"></a>           <span class="at">alpha =</span> <span class="fl">0.7</span>)</span>
<span id="cb2-356"><a href="#cb2-356"></a></span>
<span id="cb2-357"><a href="#cb2-357"></a><span class="co"># boot function (note: data should be a data frame or matrix with 2 columns)</span></span>
<span id="cb2-358"><a href="#cb2-358"></a>boot_calc_cor <span class="ot">&lt;-</span> <span class="cf">function</span>(data, indices) {</span>
<span id="cb2-359"><a href="#cb2-359"></a>    <span class="co"># Resample the data using indices (this resamples paired observations)</span></span>
<span id="cb2-360"><a href="#cb2-360"></a>    resampled_data <span class="ot">&lt;-</span> data[indices, ]</span>
<span id="cb2-361"><a href="#cb2-361"></a>    <span class="co"># Calculate correlation between the two variables</span></span>
<span id="cb2-362"><a href="#cb2-362"></a>    <span class="fu">cor</span>(resampled_data[, <span class="dv">1</span>], resampled_data[, <span class="dv">2</span>])</span>
<span id="cb2-363"><a href="#cb2-363"></a>}</span>
<span id="cb2-364"><a href="#cb2-364"></a></span>
<span id="cb2-365"><a href="#cb2-365"></a><span class="co"># boot</span></span>
<span id="cb2-366"><a href="#cb2-366"></a><span class="fu">set.seed</span>(<span class="dv">20250111</span>)</span>
<span id="cb2-367"><a href="#cb2-367"></a>boot_cor <span class="ot">&lt;-</span> <span class="fu">boot</span>(<span class="fu">cbind</span>(swiss<span class="sc">$</span>Fertility, swiss<span class="sc">$</span>Education), boot_calc_cor, <span class="at">R =</span> <span class="dv">1000</span>)</span>
<span id="cb2-368"><a href="#cb2-368"></a>boot_cor_CIs <span class="ot">&lt;-</span> <span class="fu">boot.ci</span>(boot_cor, <span class="at">type =</span> <span class="st">"all"</span>)</span>
<span id="cb2-369"><a href="#cb2-369"></a>boot_cor_CIs</span>
<span id="cb2-370"><a href="#cb2-370"></a></span>
<span id="cb2-371"><a href="#cb2-371"></a><span class="co"># df of bootstrapped estimates</span></span>
<span id="cb2-372"><a href="#cb2-372"></a>bootstrap_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb2-373"><a href="#cb2-373"></a>    <span class="at">bootstrap_cors =</span> <span class="fu">as.vector</span>(boot_cor<span class="sc">$</span>t),</span>
<span id="cb2-374"><a href="#cb2-374"></a>    <span class="at">original_cor =</span> boot_cor<span class="sc">$</span>t0</span>
<span id="cb2-375"><a href="#cb2-375"></a>)</span>
<span id="cb2-376"><a href="#cb2-376"></a></span>
<span id="cb2-377"><a href="#cb2-377"></a><span class="co"># Calculate percentiles for confidence interval</span></span>
<span id="cb2-378"><a href="#cb2-378"></a>ci_lower <span class="ot">&lt;-</span> <span class="fu">quantile</span>(boot_cor<span class="sc">$</span>t, <span class="fl">0.025</span>)</span>
<span id="cb2-379"><a href="#cb2-379"></a>ci_upper <span class="ot">&lt;-</span> <span class="fu">quantile</span>(boot_cor<span class="sc">$</span>t, <span class="fl">0.975</span>)</span>
<span id="cb2-380"><a href="#cb2-380"></a></span>
<span id="cb2-381"><a href="#cb2-381"></a><span class="co"># Plot</span></span>
<span id="cb2-382"><a href="#cb2-382"></a><span class="fu">ggplot</span>(bootstrap_df, <span class="fu">aes</span>(<span class="at">x =</span> bootstrap_cors)) <span class="sc">+</span></span>
<span id="cb2-383"><a href="#cb2-383"></a>    <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> <span class="fu">after_stat</span>(density)), <span class="at">bins =</span> <span class="dv">30</span>, </span>
<span id="cb2-384"><a href="#cb2-384"></a>                   <span class="at">fill =</span> <span class="st">"lightblue"</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb2-385"><a href="#cb2-385"></a>    <span class="fu">geom_density</span>(<span class="at">color =</span> <span class="st">"blue"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb2-386"><a href="#cb2-386"></a>    <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept =</span> original_cor, <span class="at">color =</span> <span class="st">"Correlation of Original Sample"</span>), <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb2-387"><a href="#cb2-387"></a>    <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept =</span> <span class="fu">mean</span>(boot_cor<span class="sc">$</span>t), <span class="at">color =</span> <span class="st">"Mean of Bootstrap Sample Correlations"</span>), <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb2-388"><a href="#cb2-388"></a>    <span class="co"># Add percentile lines for 95% CI</span></span>
<span id="cb2-389"><a href="#cb2-389"></a>    <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> ci_lower, <span class="at">color =</span> <span class="st">"darkorange3"</span>, <span class="at">linetype =</span> <span class="st">"dotted"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb2-390"><a href="#cb2-390"></a>    <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> ci_upper, <span class="at">color =</span> <span class="st">"darkorange3"</span>, <span class="at">linetype =</span> <span class="st">"dotted"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb2-391"><a href="#cb2-391"></a>    <span class="co"># Add labels for percentile values</span></span>
<span id="cb2-392"><a href="#cb2-392"></a>    <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> ci_lower, <span class="at">y =</span> <span class="fu">max</span>(<span class="fu">density</span>(boot_mean<span class="sc">$</span>t)<span class="sc">$</span>y) <span class="sc">*</span> <span class="fl">0.8</span>, </span>
<span id="cb2-393"><a href="#cb2-393"></a>             <span class="at">label =</span> <span class="fu">paste</span>(<span class="st">"2.5%</span><span class="sc">\n</span><span class="st">"</span>, <span class="fu">round</span>(ci_lower, <span class="dv">2</span>)), </span>
<span id="cb2-394"><a href="#cb2-394"></a>             <span class="at">color =</span> <span class="st">"darkorange3"</span>, <span class="at">hjust =</span> <span class="fl">1.1</span>, <span class="at">vjust =</span> <span class="sc">-</span><span class="dv">7</span>, <span class="at">size =</span> <span class="fl">3.5</span>) <span class="sc">+</span></span>
<span id="cb2-395"><a href="#cb2-395"></a>    <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> ci_upper, <span class="at">y =</span> <span class="fu">max</span>(<span class="fu">density</span>(boot_mean<span class="sc">$</span>t)<span class="sc">$</span>y) <span class="sc">*</span> <span class="fl">0.8</span>, </span>
<span id="cb2-396"><a href="#cb2-396"></a>             <span class="at">label =</span> <span class="fu">paste</span>(<span class="st">"97.5%</span><span class="sc">\n</span><span class="st">"</span>, <span class="fu">round</span>(ci_upper, <span class="dv">2</span>)), </span>
<span id="cb2-397"><a href="#cb2-397"></a>             <span class="at">color =</span> <span class="st">"darkorange3"</span>, <span class="at">hjust =</span> <span class="sc">-</span><span class="fl">0.1</span>, <span class="at">vjust =</span> <span class="sc">-</span><span class="dv">7</span>, <span class="at">size =</span> <span class="fl">3.5</span>) <span class="sc">+</span></span>
<span id="cb2-398"><a href="#cb2-398"></a>    <span class="co"># Manual color scale for legend</span></span>
<span id="cb2-399"><a href="#cb2-399"></a>    <span class="fu">scale_color_manual</span>(<span class="at">name =</span> <span class="st">""</span>,</span>
<span id="cb2-400"><a href="#cb2-400"></a>                       <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Correlation of Original Sample"</span> <span class="ot">=</span> <span class="st">"red"</span>, <span class="st">"Mean of Bootstrap Sample Correlations"</span> <span class="ot">=</span> <span class="st">"darkmagenta"</span>)) <span class="sc">+</span></span>
<span id="cb2-401"><a href="#cb2-401"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Bootstrap Distribution with 95% Percentile Confidence Interval"</span>,</span>
<span id="cb2-402"><a href="#cb2-402"></a>         <span class="at">x =</span> <span class="st">"Bootstrap Sample Correlations"</span>,</span>
<span id="cb2-403"><a href="#cb2-403"></a>         <span class="at">y =</span> <span class="st">"Density"</span>,</span>
<span id="cb2-404"><a href="#cb2-404"></a>         <span class="at">caption =</span> <span class="fu">paste</span>(<span class="st">"95% Percentile CI: ["</span>, <span class="fu">round</span>(ci_lower, <span class="dv">2</span>), <span class="st">", "</span>, <span class="fu">round</span>(ci_upper, <span class="dv">2</span>), <span class="st">"]"</span>)) <span class="sc">+</span></span>
<span id="cb2-405"><a href="#cb2-405"></a>    <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb2-406"><a href="#cb2-406"></a>    <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"top"</span>)</span>
<span id="cb2-407"><a href="#cb2-407"></a></span>
<span id="cb2-408"><a href="#cb2-408"></a><span class="co"># Compare to (cor.test gives large sample approximation)</span></span>
<span id="cb2-409"><a href="#cb2-409"></a>cor.test_sample_ci <span class="ot">&lt;-</span>  <span class="fu">cor.test</span>(swiss<span class="sc">$</span>Fertility, swiss<span class="sc">$</span>Education)</span>
<span id="cb2-410"><a href="#cb2-410"></a></span>
<span id="cb2-411"><a href="#cb2-411"></a><span class="co"># Extract CI's into df</span></span>
<span id="cb2-412"><a href="#cb2-412"></a>boot_cor_CIs_df <span class="ot">&lt;-</span>  <span class="fu">extract_boot_ci</span>(boot_cor_CIs)</span>
<span id="cb2-413"><a href="#cb2-413"></a><span class="co"># Add in t.test CI's</span></span>
<span id="cb2-414"><a href="#cb2-414"></a>boot_cor_CIs_df <span class="ot">&lt;-</span>  <span class="fu">rbind</span>(boot_cor_CIs_df, <span class="fu">data.frame</span>(<span class="at">type =</span> <span class="st">"Theoretical"</span>, <span class="at">lower_ci =</span> cor.test_sample_ci<span class="sc">$</span>conf.int[<span class="dv">1</span>], <span class="at">upper_ci =</span> cor.test_sample_ci<span class="sc">$</span>conf.int[<span class="dv">2</span>]))</span>
<span id="cb2-415"><a href="#cb2-415"></a></span>
<span id="cb2-416"><a href="#cb2-416"></a><span class="co"># Plot all CI's for visualisation</span></span>
<span id="cb2-417"><a href="#cb2-417"></a><span class="fu">ggplot</span>(boot_cor_CIs_df) <span class="sc">+</span></span>
<span id="cb2-418"><a href="#cb2-418"></a>    <span class="fu">aes</span>(<span class="at">xmin =</span> lower_ci, <span class="at">xmax =</span> upper_ci, <span class="at">y =</span> type, <span class="at">color =</span> type) <span class="sc">+</span> </span>
<span id="cb2-419"><a href="#cb2-419"></a>    <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> boot_cor<span class="sc">$</span>t0, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">linewidth =</span> <span class="fl">1.2</span>) <span class="sc">+</span> </span>
<span id="cb2-420"><a href="#cb2-420"></a>    <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">mean</span>(boot_cor<span class="sc">$</span>t), <span class="at">color =</span> <span class="st">"darkmagenta"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">linewidth =</span> <span class="fl">1.2</span>) <span class="sc">+</span> </span>
<span id="cb2-421"><a href="#cb2-421"></a>    <span class="fu">geom_errorbar</span>() <span class="sc">+</span> </span>
<span id="cb2-422"><a href="#cb2-422"></a>    <span class="fu">theme_minimal</span>() <span class="sc">+</span> </span>
<span id="cb2-423"><a href="#cb2-423"></a>    <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>) <span class="sc">+</span> </span>
<span id="cb2-424"><a href="#cb2-424"></a>    <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">""</span>)</span>
<span id="cb2-425"><a href="#cb2-425"></a><span class="in">```</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>