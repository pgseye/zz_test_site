[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Test Site",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nLogistic regression under the hood\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\nmodelling\n\n\nvisualisation\n\n\nprobability\n\n\n\nSee how log-odds, odds and probability are all simply versions of each other - and fundamental to logistic regression.\n\n\n\n\n\nMay 31, 2024\n\n\n8 min\n\n\n\n\n\n\n\n\n\n\n\n\nProp Odds\n\n\n\n\n\n\nanalysis\n\n\nconcept\n\n\ncode\n\n\nmodelling\n\n\n\n\n\n\n\n\n\nMay 17, 2024\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\ngtsummary - Your New Go-To for Tables\n\n\n\n\n\n\ncode\n\n\npresentation\n\n\n\nCreate summary and regression tables in a flash.\n\n\n\n\n\nMay 3, 2024\n\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\n\nEverything is a Linear Model\n\n\n\n\n\n\nanalysis\n\n\nconcept\n\n\ncode\n\n\nmodelling\n\n\n\nThe t-test and linear model with one grouping variable are two sides of the same coin.\n\n\n\n\n\nApr 19, 2024\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nDon‚Äôt be Scared of Splines\n\n\n\n\n\n\nanalysis\n\n\nconcept\n\n\ncode\n\n\nmodelling\n\n\nvisualisation\n\n\n\nRestricted cubic splines give you the ultimate flexiblity in modelling continuous predictors.\n\n\n\n\n\nApr 5, 2024\n\n\n20 min\n\n\n\n\n\n\n\n\n\n\n\n\nEasily view your data by a grouping variable\n\n\n\n\n\n\ncode\n\n\n\nUse by() to view your data by a grouping variable.\n\n\n\n\n\nMar 22, 2024\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nSimpson‚Äôs Paradox - Contextualised for Research Students\n\n\n\n\n\n\nconcept\n\n\ncode\n\n\nvisualisation\n\n\n\nSimpson‚Äôs Paradox is essentially an extreme form of confounding, characterised by a reversal of the effect estimate sign.\n\n\n\n\n\nMar 8, 2024\n\n\n7 min\n\n\n\n\n\n\n\n\n\n\n\n\nImmortal time bias - ‚ÄúThe fallacy that never dies‚Äù (Part 2)\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\nmodelling\n\n\nsurvival\n\n\nvisualisation\n\n\n\nLet‚Äôs investigate immortal time bias with a coded example.\n\n\n\n\n\nFeb 23, 2024\n\n\n8 min\n\n\n\n\n\n\n\n\n\n\n\n\nImmortal time bias - ‚ÄúThe fallacy that never dies‚Äù (Part 1)\n\n\n\n\n\n\nconcept\n\n\nsurvival\n\n\n\nLearn why this misclassification of time in a survival analysis can seriously bias your results.\n\n\n\n\n\nFeb 16, 2024\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nPut your ggplot on steroids\n\n\n\n\n\n\nvisualisation\n\n\ncode\n\n\n\nPlotly adds some interactivity and can help clarify your data.\n\n\n\n\n\nFeb 2, 2024\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nA Very Merry Christmas\n\n\n\n\n\n\nfun\n\n\ncode\n\n\nvisualisation\n\n\n\nHo, Ho, Ho\n\n\n\n\n\nDec 8, 2023\n\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\n\nIt pays to think like a Bayesian\n\n\n\n\n\n\npuzzle\n\n\nprobability\n\n\nBayesian\n\n\n\nBayesian reasoning is more in line with how we process chance in everyday life.\n\n\n\n\n\nDec 1, 2023\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\nInteractions (effect modifiers) are important - don‚Äôt ignore them\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\nmodelling\n\n\nlogistic\n\n\n\nKeep an open mind to interactions in your next model.\n\n\n\n\n\nNov 24, 2023\n\n\n12 min\n\n\n\n\n\n\n\n\n\n\n\n\nStats Tips - Welcome\n\n\n\n\n\n\nnews\n\n\n\nWelcome to what I hope can become a useful stats resource.\n\n\n\n\n\nNov 22, 2023\n\n\n2 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/007_08Mar_2024/index.html",
    "href": "posts/007_08Mar_2024/index.html",
    "title": "Simpson‚Äôs Paradox - Contextualised for Research Students",
    "section": "",
    "text": "A thought exercise this week in possible ways to interpret the following plot. This comes from hypothetical (simulated) data that purports to assess research students productivity (measured by how quickly they can type) as a function of the number of standard cups of coffee they drink in a day.\n\n\n\n\n\n\nNote\n\n\n\nI am no way suggesting that these findings apply to MSNI research students who no doubt remain highly productive throughout their research careers.\n\n\n\n\nCode\nlibrary(bayestestR)\nlibrary(ggplot2)\nlibrary(dplyr)\n# Simulate some Simpson's paradox style data \nset.seed(253445)\ndat &lt;- simulate_simpson(\n  n = 50,\n  r = 0.5,\n  groups = 3,\n  difference = 2,\n  group_prefix = \"G_\"\n)\n# A couple of variable manipulations to get the variables to look the way I want\ndat$V2 &lt;- (dat$V2*10)+90\ndat$V1 &lt;- (dat$V1+1)/2\n# Rename groups\ndat &lt;- dat |&gt; \n  mutate(Group = case_when(Group == \"G_1\" ~ \"Honours\",\n                           Group == \"G_2\" ~ \"Masters\",\n                           Group == \"G_3\" ~ \"PhD\")) |&gt; \n  rename(`Student Type` = Group)\n# Plot aggregated data\nggplot(dat, aes(x = V1, y = V2)) + \n  geom_point(size = 3) + \n  geom_smooth(method = \"lm\", se = F) +\n  ggtitle(\"Research students - Typing speed as a function of coffee consumption\") +\n  xlab(\"Number of (standard) cups of coffee\") + ylab(\"Words Per Minute (WPM)\") +\n  scale_y_continuous(limits = c(0, 100), breaks = seq(0, 100, by = 20)) +\n  scale_x_continuous(limits = c(0, 5), breaks = seq(0, 5, by = 1)) +\n  theme_bw(base_size = 18)\n\n\n\n\n\n\n\n\n\nIf they define typing speed as total words/total time elapsed then the time spent buying/making coffee, holding cups and drinking would inflate the denominator without the numerator increasing and make it appear that typing speed has decreased as more time is spent not typing. Would be very hard to get the speed back up just by typing faster in that scenario. So clearly the workplace should be providing each worker with a pre-made, heated camelbak filled with coffee each day to improve productivity. Hands free coffee drinking! (Robb - former Research Student)\nThe best response of the week has to go to Robb for this very well considered and justified attempt to have the bosses supply one of these (I‚Äôm assuming this is what you really meant Robb):\n\n\n\nNew MSNI Coffee Facilities?\n\n\nSo what is this scatterplot showing? Well there appears to be a relationship between coffee drinking and typing speed - drinking more cups of coffee seems to be associated with reduced typing speed (note that I am not suggesting that drinking more coffee causes reduced typing speed, merely that there is a correlation). Fitting a regression model to these data produces a best-fitting line with a negative slope or coefficient. It is interesting though - is this direction of ‚Äòeffect‚Äô what one might reasonably expect? Perhaps, but my intuition would be that drinking more coffee might naturally correlate with a faster typing ability (don‚Äôt forget I‚Äôve made up the data to suit the story I‚Äôm telling - I can only guess as to whether these associations are real or not).\nSo what else could be going on to produce the pattern that you see? Well, you might then naturally think that there is some other ‚Äòlurking‚Äô variable (i.e.¬†a confounder) that is distorting or masking the true relationship between coffee consumption and typing speed leading to the association that we actually observe. And, you‚Äôd be right‚Ä¶\nIt just so turns out that the program that the research student is enrolled in (Honours, Masters, PhD) is an important factor in teasing apart the coffee -&gt; typing speed association. If we now condition on or control for Student Type we see a completely different picture regarding that association. As before, we can similarly fit regression lines to these three subgroups. For each Student Type drinking more coffee is now associated with a faster typing speed (the slope/coefficient of those lines are now positive), but we can also observe some other interesting findings. On average, Honours students drink the fewest cups of coffee and have the fastest typing speed - they are fresh and motivated. In contrast, PhD students drink the most coffee and have the slowest typing speed. My take on this (and again I‚Äôm sure this doesn‚Äôt apply to MSNI students), is that by the time you‚Äôve become a PhD student, you have more caffeine coursing through your system than actual blood, but in fact this does little to help your productivity which is more impaired by your sheer exhaustion, increasing cynicism towards academic life and typing-related repetitive strain injury (maybe this is just a realisation of my own PhD experience ü§î).\n\n\nCode\nggplot(dat, aes(x = V1, y = V2, color = `Student Type`)) + \n  geom_point(size = 3) + \n  geom_smooth(method = \"lm\", se = F) +\n  ggtitle(\"Research students - Typing speed as a function of coffee consumption\") +\n  xlab(\"Number of (standard) cups of coffee\") + ylab(\"Words Per Minute (WPM)\") +\n  scale_y_continuous(limits = c(0, 100), breaks = seq(0, 100, by = 20)) +\n  scale_x_continuous(limits = c(0, 5), breaks = seq(0, 5, by = 1)) + \n  theme_bw(base_size = 18) +\n  theme(legend.position = c(1,1), legend.justification = c(1.1,1.1))\n\n\n\n\n\n\n\n\n\nYou might have come across Simpson‚Äôs Paradox in your statistical reading - it‚Äôs a fairly common epidemiological bias but it can have important implications for the interpretation of evidence from observational studies, including yours. And so to that end it‚Äôs not purely an exercise for academic interest. Simpson‚Äôs Paradox is a version of Lord‚Äôs Paradox (differentiated by whether exposure and outcome variables are categorical, or continuous, or a combination of both) but at the end of the day they are both a type of Reversal Paradox. Regardless of the variable type, a common characteristic is shared in the Reversal Paradox: the association between two variables can be reversed, diminished, or enhanced when another variable (confounder) is statistically controlled for.\n\n\n\n\n\n\nImportant\n\n\n\nObserved associations at the aggregated level - when important underlying group structures aren‚Äôt realised - or worse still, ignored - can potentially reverse when the data are disaggregated and those underlying group structures are considered in the analysis. In other words, the observed association across all groups can be quite different to that within each group. This is Simpson‚Äôs Paradox in a nutshell.\n\n\nA canonical example of Simpson‚Äôs Paradox is the relationship between body mass and longevity across different species of animals. In general, across all animal species, larger animals (elephants, whales, etc) tend to live longer than smaller animals (rodents, birds, etc). There are of course exceptions to that rule - I‚Äôm looking at you Mr Tortoise. But when you look within species, an inverse correlation typically exists - being heavier tends to be associated with a shorter life.\nThese examples highlight the importance of understanding your data and the research questions you are asking. Prior knowledge of potential variable relationships (measured and unmeasured) and underlying causal theory should be the primary considerations guiding you in the modelling of your data. Simply following variable selection techniques based on statistical criteria can still lead to models that are consistent and replicable, but also very easily lead to erroneous conclusions because you haven‚Äôt considered a pesky ‚Äòlurking‚Äô factor that can leave you with the equivalent of statistical and scientific egg on your face."
  },
  {
    "objectID": "posts/100__2024/index.html",
    "href": "posts/100__2024/index.html",
    "title": "Logistic regression under the hood",
    "section": "",
    "text": "Code\n# Recreate data from Ophthalmic statistics note 11: logistic regression.\n# Original source: A comparison of several methods of macular hole measurement using optical coherence tomography, and their value in predicting anatomical and visual outcomes.\n\nlibrary(tidyverse)\nlibrary(ggpubr)\nlibrary(ggmagnify)\nlibrary(emmeans)\n\n# Simulate data ----\nn &lt;- 1000                    # don't change this unless necessary (plots might be fragile)\nset.seed(1234)\nx  &lt;-  rnorm(n, 486, 142)    # generate macular hole inner opening data with mean 486 and sd = 152\nz  &lt;-  10.89 - 0.016 * x     # generate variable that is linear combination of intercept = 10.89 and coefficient for macular hole -0.016 (logit scale)\npr  &lt;-  1/(1 + exp(-z))      # generate probabilities from this\ny  &lt;-  rbinom(n, 1, pr)      # generate outcome variable as a function of those probabilities\n\n# Create dataframe from these:\ndf &lt;-  data.frame(y = y, x = x, z = z, pr = pr)\ndf &lt;- df |&gt; \n  filter(x &gt; 100) # only include those with thickness &gt; 100\n\n# Logistic regression model ----\n# Rescale x to 1 unit = 100 microns instead of 1 micron\nsummary(mod_logistic &lt;- glm(y ~ I(x/100), data = df, family = \"binomial\"))\n\n\n\nCall:\nglm(formula = y ~ I(x/100), family = \"binomial\", data = df)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  10.3501     0.7456   13.88   &lt;2e-16 ***\nI(x/100)     -1.5045     0.1212  -12.42   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 773.74  on 989  degrees of freedom\nResidual deviance: 494.67  on 988  degrees of freedom\nAIC: 498.67\n\nNumber of Fisher Scoring iterations: 6\n\n\nCode\n# Emmeans of logodds at 600 and 700 microns\nemmeans_df &lt;- data.frame(emmeans(mod_logistic, ~ x, at = list(x = c(600, 700))))\n# Create df of emmeans and corresponding odds and probs, for plotting\nemmeans_df &lt;- emmeans_df |&gt; \n  select(x, emmean) |&gt; \n  rename(logodds = emmean) |&gt; \n  mutate(odds = round(exp(logodds), 3),\n         probs = round(plogis(logodds), 2),\n         logodds = round(logodds, 3))\n\n# Predictions ----\n# Create new df to predict on new values of x\nnew_dat &lt;- data.frame(x = seq(from = 0, to = 1200, length.out = 100))\n# Predict new fitted values and SE's on logodds scale\npred_logodds &lt;- predict(mod_logistic, newdata = new_dat, type = \"link\", se = TRUE)\nnew_dat &lt;- cbind(new_dat, pred_logodds)\n# Create new df of predictions\npredictions &lt;- new_dat |&gt; \n  rename(pred_logodds_est = fit) |&gt; \n  mutate(pred_logodds_LL = pred_logodds_est - (1.96 * se.fit),\n         pred_logodds_UL = pred_logodds_est + (1.96 * se.fit)) |&gt; \n  select(-c(se.fit, residual.scale))\n# Predict new fitted values and SE's on odds scale\npredictions &lt;- predictions |&gt; \n  mutate(pred_odds_est = exp(pred_logodds_est),\n         pred_odds_LL = exp(pred_logodds_LL),\n         pred_odds_UL = exp(pred_logodds_UL))\n# Predict new fitted values and SE's on probability scale\npred_probs &lt;- predict(mod_logistic, newdata = new_dat, type = \"response\", se = TRUE)\nnew_dat &lt;- cbind(new_dat[1], pred_probs)\nnew_dat &lt;- new_dat |&gt; \n  mutate(pred_probs_LL = fit - (1.96 * se.fit),\n         pred_probs_UL = fit + (1.96 * se.fit))\n# Add predicted probs and CIs to predictions df\npredictions &lt;- cbind(predictions, \n                     pred_probs_est = new_dat$fit, \n                     pred_probs_LL = new_dat$pred_probs_LL,\n                     pred_probs_UL = new_dat$pred_probs_UL)\n\n# Reformat plots slightly for ggarrange ----\np3a &lt;- ggplot(predictions, aes(x = x, y = pred_logodds_est)) + \n  geom_ribbon(aes(ymin = pred_logodds_LL, ymax = pred_logodds_UL), alpha = 0.2) + \n  geom_line(color = \"cornflowerblue\", linewidth = 1) +\n  geom_point(data = df, aes(x = x, y = y), size = 2, alpha = 0.1) +\n  annotate(\"text\", x = 1150, y = 6, label = \"log-odds\", size = 10) +\n  scale_x_continuous(limits = c(0, 1200), breaks = seq(0, 1200, by = 100)) +\n  scale_y_continuous(limits = c(-100, 100), breaks = seq(-100, 100, by = 2)) +\n  coord_cartesian(xlim = c(0, 1200), ylim = c(-8, 8)) +\n  geom_vline(xintercept = 600, color = \"red\", linetype = \"dotted\", linewidth = 0.6) +\n  geom_vline(xintercept = 700, color = \"red\", linetype = \"dotted\", linewidth = 0.6) +\n  ggrepel::geom_label_repel(data = emmeans_df, aes(x, logodds),\n                            label = emmeans_df$logodds, \n                            nudge_x = c(-50, 50), nudge_y = c(4, -4),\n                            color = \"red\", segment.size = 0.2, size = 5) +\n  theme_bw(base_size = 25) +\n  ylab(\"\") +\n  theme(axis.title.x = element_blank(), axis.text.x = element_blank())\n\np4a &lt;- ggplot(predictions, aes(x = x, y = pred_odds_est)) + \n  geom_ribbon(aes(ymin = pred_odds_LL, ymax = pred_odds_UL), alpha = 0.2) + \n  geom_line(color = \"cornflowerblue\", linewidth = 1) +\n  geom_point(data = df, aes(x = x, y = y), size = 2, alpha = 0.1) +\n  annotate(\"text\", x = 1150, y = 6000, label = \"odds\", size = 10) +\n  scale_x_continuous(limits = c(0, 1200), breaks = seq(0, 1200, by = 100)) +\n  scale_y_continuous(limits = c(-20, 1000000), breaks = c(seq(0, 1000000, by = 1000))) +\n  coord_cartesian(xlim = c(0, 1200), ylim = c(0, 7000)) +\n  geom_vline(xintercept = 600, color = \"red\", linetype = \"dotted\", linewidth = 0.6) +\n  geom_vline(xintercept = 700, color = \"red\", linetype = \"dotted\", linewidth = 0.6) +\n  ylab(\"\") +\n  theme_bw(base_size = 25) +\n  theme(axis.title.x = element_blank(), axis.text.x = element_blank())\np4a_inset &lt;- p4a +\n  scale_y_continuous(limits = c(-20, 1000000), breaks = c(1,2,3,4,5, seq(0, 1000000, by = 1000))) +\n  geom_vline(xintercept = 600, color = \"red\", linetype = \"dotted\", linewidth = 0.6) +\n  geom_vline(xintercept = 700, color = \"red\", linetype = \"dotted\", linewidth = 0.6) +\n  ggrepel::geom_label_repel(data = emmeans_df, aes(x, odds),\n                            label = emmeans_df$odds, \n                            nudge_x = c(-50, 50), nudge_y = c(-1, 2),\n                            color = \"red\", segment.size = 0.2, size = 5)\np4a &lt;- p4a + geom_magnify(from = c(xmin = 500, xmax = 1000, ymin = 0, ymax = 5), \n                          to = c(xmin = 465, xmax = 1010, ymin = 1000, ymax = 5000), \n                          shadow = T, axes = \"y\", plot = p4a_inset)\n\np5a &lt;- ggplot(predictions, aes(x = x, y = pred_probs_est)) + \n  geom_ribbon(aes(ymin = pred_probs_LL, ymax = pred_probs_UL), alpha = 0.2) + \n  geom_line(color = \"cornflowerblue\", linewidth = 1) +\n  geom_point(data = df, aes(x = x, y = y), size = 2, alpha = 0.1) +\n  annotate(\"text\", x = 1150, y = 0.8, label = \"probability\", size = 10) +\n  scale_x_continuous(limits = c(0, 1200), breaks = seq(0, 1200, by = 100)) +\n  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.2)) +\n  geom_vline(xintercept = 600, color = \"red\", linetype = \"dotted\", linewidth = 0.6) +\n  geom_vline(xintercept = 700, color = \"red\", linetype = \"dotted\", linewidth = 0.6) +\n  ggrepel::geom_label_repel(data = emmeans_df, aes(x, probs),\n                            label = emmeans_df$probs, \n                            nudge_x = c(-50, 50), nudge_y = c(-0.1, 0.1),\n                            color = \"red\", segment.size = 0.2, size = 5) +\n  ylab(\"\") + xlab(\"Macular hole thickness\") +\n  theme_bw(base_size = 25)\nggarrange(p3a, p4a, p5a, align = \"v\", ncol = 1, heights = c(1,1,1.2))"
  },
  {
    "objectID": "posts/008_22Mar_2024/index.html",
    "href": "posts/008_22Mar_2024/index.html",
    "title": "Easily view your data by a grouping variable",
    "section": "",
    "text": "It is easy enough to view a dataframe in RStudio by opening the dataframe in the viewer or printing the dataframe (or part of it) to the console. However, this can be messy if you want to quickly identify data by a grouping variable (usually the patient id). The by() function can help you to do this. Let‚Äôs illustrate its utility with the sleepstudy dataset from the lme4 package. To start with I‚Äôll print the data for the first 3 subjects as one might.\nsleepstudy |&gt; as_tibble() |&gt; print(n = 30)\n\n\nCode\nlibrary(lme4)\nlibrary(dplyr)\n# Load data\ndata(\"sleepstudy\")\nsleepstudy |&gt; as_tibble() |&gt; print(n = 30)\n\n\n# A tibble: 180 √ó 3\n   Reaction  Days Subject\n      &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;  \n 1     250.     0 308    \n 2     259.     1 308    \n 3     251.     2 308    \n 4     321.     3 308    \n 5     357.     4 308    \n 6     415.     5 308    \n 7     382.     6 308    \n 8     290.     7 308    \n 9     431.     8 308    \n10     466.     9 308    \n11     223.     0 309    \n12     205.     1 309    \n13     203.     2 309    \n14     205.     3 309    \n15     208.     4 309    \n16     216.     5 309    \n17     214.     6 309    \n18     218.     7 309    \n19     224.     8 309    \n20     237.     9 309    \n21     199.     0 310    \n22     194.     1 310    \n23     234.     2 310    \n24     233.     3 310    \n25     229.     4 310    \n26     220.     5 310    \n27     235.     6 310    \n28     256.     7 310    \n29     261.     8 310    \n30     248.     9 310    \n# ‚Ñπ 150 more rows\n\n\nBut we can do this better with:\nby(sleepstudy, sleepstudy$PATIENT_ID, identity)[1:3]\nNote that the [1:3] indicates the range of group indices that you want to view.\n\n\nCode\nby(sleepstudy, sleepstudy$Subject, identity)[1:3]\n\n\n$`308`\n   Reaction Days Subject\n1  249.5600    0     308\n2  258.7047    1     308\n3  250.8006    2     308\n4  321.4398    3     308\n5  356.8519    4     308\n6  414.6901    5     308\n7  382.2038    6     308\n8  290.1486    7     308\n9  430.5853    8     308\n10 466.3535    9     308\n\n$`309`\n   Reaction Days Subject\n11 222.7339    0     309\n12 205.2658    1     309\n13 202.9778    2     309\n14 204.7070    3     309\n15 207.7161    4     309\n16 215.9618    5     309\n17 213.6303    6     309\n18 217.7272    7     309\n19 224.2957    8     309\n20 237.3142    9     309\n\n$`310`\n   Reaction Days Subject\n21 199.0539    0     310\n22 194.3322    1     310\n23 234.3200    2     310\n24 232.8416    3     310\n25 229.3074    4     310\n26 220.4579    5     310\n27 235.4208    6     310\n28 255.7511    7     310\n29 261.0125    8     310\n30 247.5153    9     310\n\n\nIf you want to take this a step further, you can generalise this with a function that will allow you to quickly view the data in any range that you want, without having to continually copy and paste that line of code. Just call the function with your dataframe and group id names and the range of group indices that you want to view (interestingly while writing this function I worked out you don‚Äôt even need the by() function to achieve the same result).\nprint_groups(sleepstudy, Subject, 1, 3)\n\n\nCode\n# Create function\nprint_groups &lt;- function(df, id, index1, index2) {\n  df &lt;- data.frame(df)\n  ids_all &lt;-  unique(eval(substitute(id), df))\n  ids_range &lt;- ids_all[index1:index2]\n  if (index1 &lt;= length(ids_all) & index2 &lt;= length(ids_all)) {\n    for (id2 in ids_range) {\n      cat(paste0(\"id = \", id2, \"\\n\"))\n      print(df[eval(substitute(id), df) %in% id2,])\n      cat(\"----------------------------\\n\\n\")\n    }\n  } else {\n    print(\"There aren't that many groups in your dataset\")\n  }\n}\n\n# Use function\nprint_groups(sleepstudy, Subject, 1, 3)\n\n\nid = 308\n   Reaction Days Subject\n1  249.5600    0     308\n2  258.7047    1     308\n3  250.8006    2     308\n4  321.4398    3     308\n5  356.8519    4     308\n6  414.6901    5     308\n7  382.2038    6     308\n8  290.1486    7     308\n9  430.5853    8     308\n10 466.3535    9     308\n----------------------------\n\nid = 309\n   Reaction Days Subject\n11 222.7339    0     309\n12 205.2658    1     309\n13 202.9778    2     309\n14 204.7070    3     309\n15 207.7161    4     309\n16 215.9618    5     309\n17 213.6303    6     309\n18 217.7272    7     309\n19 224.2957    8     309\n20 237.3142    9     309\n----------------------------\n\nid = 310\n   Reaction Days Subject\n21 199.0539    0     310\n22 194.3322    1     310\n23 234.3200    2     310\n24 232.8416    3     310\n25 229.3074    4     310\n26 220.4579    5     310\n27 235.4208    6     310\n28 255.7511    7     310\n29 261.0125    8     310\n30 247.5153    9     310\n----------------------------\n\n\nAnd there you have it!"
  },
  {
    "objectID": "posts/001_24Nov2023/index.html",
    "href": "posts/001_24Nov2023/index.html",
    "title": "Interactions (effect modifiers) are important - don‚Äôt ignore them",
    "section": "",
    "text": "Code\nlibrary(knitr)\nlibrary(quarto)\nlibrary(emmeans)\nlibrary(flextable)\nlibrary(ggplot2)\nsuppressPackageStartupMessages(library(gtsummary))\nopts_chunk$set(echo = T,\n               cache = F,\n               prompt = F,\n               tidy = F,\n               message = F,\n               warning = F)"
  },
  {
    "objectID": "posts/001_24Nov2023/index.html#the-question",
    "href": "posts/001_24Nov2023/index.html#the-question",
    "title": "Interactions (effect modifiers) are important - don‚Äôt ignore them",
    "section": "1 The Question",
    "text": "1 The Question\n\nRecall that the question this week was to choose between:\nA) Age is a confounder in the relationship between sex and hospitalisation from car crash.\nB) Age is an effect modifier in the relationship between sex and hospitalisation from car crash.\nusing the data supplied below."
  },
  {
    "objectID": "posts/001_24Nov2023/index.html#the-answer",
    "href": "posts/001_24Nov2023/index.html#the-answer",
    "title": "Interactions (effect modifiers) are important - don‚Äôt ignore them",
    "section": "2 The Answer",
    "text": "2 The Answer\n\nThe answer is B. Younger male drivers tend to be more stupid and injure themselves more seriously than their female counterparts. Upon reaching a suitable age of maturity their risk of hospitalisation reduces to about the same (if we assume the 95% CI for the 8% reduction includes 0) as that for females.\nWhen a third variable plays a role in the association between an exposure and an outcome it may act as a confounder OR effect modifier (AND sometimes both).\nA simple confounder (e.g.¬†age) will show the same exposure -&gt; outcome association across all of its categories (e.g.¬†same risk ratio in &lt; 40 yrs and ‚â• 40 yrs)\nAn effect modifier will show different magnitudes of association across its categories (e.g.¬†the risk ratio will differ in those &lt; 40 yrs and ‚â• 40 yrs).\nStratification is the simplest form of exploring and adjusting for confounding/interaction effects (used before we had all this computing power).\nSubgroups of data are created for each category of confounder/effect modifier and estimates of interest (mean differences, risk ratios, etc) calculated in each.\nThese can then be combined in a weighted manner to give an overall (adjusted) estimate if NO effect modification is present.\nThis is equivalent to including the third variable as a covariate in our regression model (we now use models rather than stratification methods).\nSimple inclusion in the regression model (using + in R) FORCES the exposure -&gt; outcome association to be the same across all categories of the effect modifier even if in reality it‚Äôs not.\n+ assumes confounding ONLY and NO effect modification.\nA problem arises, however, when the third variable is more an effect modifier, rather than confounder.\nIf we suspect effect modification is present, we need to include this third variable in the model as an interaction term (using * in R)\nThis will allow the exposure -&gt; outcome association to differ across categories of the effect modifier.\n* assumes effect modification is present.\nThis is a more flexible model specification, than simply ‚Äòadjusting‚Äô for a variable.\nInterpretation is a little more involved (always happy to help with this) but the point is it‚Äôs important not to blindly assume a third variable can only ever be a confounder.\nIf effect modification is present, you need to know about it.\nIt is simple to test for effect modification in R, Stata, etc. Include the interaction term and then drop it if not clinically/statistically significant at some level.\nI have included some R output below showing the equivalence of stratification and modelling approaches to interaction effects.\n\nBefore we get to that - a simple set of guidelines for how to think about crude vs stratified associations:\n\nEquivalence of model-derived crude estimate\nRecall that the aggregated data that the crude estimate is calculated from is:\n\n\nCode\ndat_agg &lt;- data.frame(sex = c(\"Male\", \"Female\"),\n                      hospitalised = as.numeric(c(1330, 798)), \n                      not_hospitalised = as.numeric(c(7018,6400)))\ndat_agg\n\n\n\n\n\n\nsex\nhospitalised\nnot_hospitalised\n\n\n\n\nMale\n1330\n7018\n\n\nFemale\n798\n6400\n\n\n\n\n\n\nTo estimate this model in R we essentially run a logistic regression but instead of outputting an odds ratio, we calculate a risk ratio by specifying a log rather than the default logit link. We will also use the aggregate model specification, as we don‚Äôt have the individual-level data.\nThe model-derived crude risk ratio for sex = 1.44 (95% CI 1.32, 1.56; p &lt; 0.001). This is very close to the estimate that we initially calculated manually from the 2 x 2 table (1.45).\n\n\nCode\nmod_crude &lt;- glm(cbind(hospitalised, not_hospitalised) ~ sex, data = dat_agg, family = binomial(link = \"log\"))\ntbl_regression(mod_crude, exp = T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nRR1\n95% CI1\np-value\n\n\n\n\nsex\n\n\n\n\n\n\n\n\n¬†¬†¬†¬†Female\n‚Äî\n‚Äî\n\n\n\n\n¬†¬†¬†¬†Male\n1.44\n1.32, 1.56\n&lt;0.001\n\n\n\n1 RR = Relative Risk, CI = Confidence Interval"
  },
  {
    "objectID": "posts/001_24Nov2023/index.html#lets-introduce-age-40-vs-40-as-a-third-variable",
    "href": "posts/001_24Nov2023/index.html#lets-introduce-age-40-vs-40-as-a-third-variable",
    "title": "Interactions (effect modifiers) are important - don‚Äôt ignore them",
    "section": "3 Let‚Äôs introduce age (<40 vs ‚â• 40) as a third variable",
    "text": "3 Let‚Äôs introduce age (&lt;40 vs ‚â• 40) as a third variable\n\n\nCode\ndat_disagg &lt;- data.frame(sex = c(\"Male\", \"Female\", \"Male\", \"Female\"),\n                         age = c(\"&lt; 40\", \"&lt; 40\", \"‚â• 40\", \"‚â• 40\"),\n                         hospitalised = as.numeric(c(966, 460, 364, 348)), \n                         not_hospitalised = as.numeric(c(3146, 3000, 3872, 3400)))\ndat_disagg\n\n\n\n\n\n\nsex\nage\nhospitalised\nnot_hospitalised\n\n\n\n\nMale\n&lt; 40\n966\n3146\n\n\nFemale\n&lt; 40\n460\n3000\n\n\nMale\n‚â• 40\n364\n3872\n\n\nFemale\n‚â• 40\n348\n3400\n\n\n\n\n\n\n\n3.1 Age as a confounder\nFor now, let‚Äôs just assume age is a confounder in the association between sex and hospitalisation risk. The model formulation in R is then:\nmod_adj &lt;- glm(cbind(hospitalised, not_hospitalised) ~ sex + age, data = dat_agg, family = binomial(link = \"log\"))\nand the risk ratios we get are:\n\n\nCode\nmod_confound &lt;- glm(cbind(hospitalised, not_hospitalised) ~ sex + age, data = dat_disagg, family = binomial(link = \"log\"))\ntbl_regression(mod_confound, exp = T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nRR1\n95% CI1\np-value\n\n\n\n\nsex\n\n\n\n\n\n\n\n\n¬†¬†¬†¬†Female\n‚Äî\n‚Äî\n\n\n\n\n¬†¬†¬†¬†Male\n1.43\n1.32, 1.55\n&lt;0.001\n\n\nage\n\n\n\n\n\n\n\n\n¬†¬†¬†¬†&lt; 40\n‚Äî\n‚Äî\n\n\n\n\n¬†¬†¬†¬†‚â• 40\n0.47\n0.43, 0.51\n&lt;0.001\n\n\n\n1 RR = Relative Risk, CI = Confidence Interval\n\n\n\n\n\n\n\n\nSo, what we are seeing here is that the magnitude of association between sex and hospitalisation risk is averaged (in a weighted way) over both categories of age to produce one effect estimate sex = 1.43 (95% CI 1.32, 1.55; p &lt; 0.001). This just so happens to be almost the same as the crude estimate when you ignore age altogether.\nThe effect for age in this model is such that whatever your sex, there is about a 53% reduction in the risk of hospitalisation if you are over 40 vs under 40. Note that in the stratification approach, you aren‚Äôt able to calculate an effect for age because you are stratifying by it (essentially treating it as a nuisance variable).\n\n\n3.2 Age as an effect modifier\nNow, let‚Äôs correctly model age as an effect modifier in the association between sex and hospitalisation risk. The model formulation in R is then (note the * operator):\nmod_adj &lt;- glm(cbind(hospitalised, not_hospitalised) ~ sex * age, data = dat_agg, family = binomial(link = \"log\"))\nand the risk ratios we get are:\n\n\nCode\nmod_interact &lt;- glm(cbind(hospitalised, not_hospitalised) ~ sex * age, data = dat_disagg, family = binomial(link = \"log\"))\ntbl_regression(mod_interact, exp = T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nRR1\n95% CI1\np-value\n\n\n\n\nsex\n\n\n\n\n\n\n\n\n¬†¬†¬†¬†Female\n‚Äî\n‚Äî\n\n\n\n\n¬†¬†¬†¬†Male\n1.77\n1.60, 1.96\n&lt;0.001\n\n\nage\n\n\n\n\n\n\n\n\n¬†¬†¬†¬†&lt; 40\n‚Äî\n‚Äî\n\n\n\n\n¬†¬†¬†¬†‚â• 40\n0.70\n0.61, 0.80\n&lt;0.001\n\n\nsex * age\n\n\n\n\n\n\n\n\n¬†¬†¬†¬†Male * ‚â• 40\n0.52\n0.44, 0.62\n&lt;0.001\n\n\n\n1 RR = Relative Risk, CI = Confidence Interval\n\n\n\n\n\n\n\n\nNote how the p value for the interaction term is very low - this would be a good indicator that the model fits the data better with the interaction term present than without it (i.e.¬†assuming age as a confounder only).\nAs I mentioned earlier, the model interpretation with an interaction present does become a little more complicated, but let‚Äôs break this down (note that I use ‚Äúeffect‚Äù in a non-causal way):\n\nThe coefficient for sex = 1.77 (95% CI 1.60, 1.96; p &lt; 0.001). The represents the ‚Äúeffect‚Äù of sex (being male relative to female) on hospitalisation risk at the reference level of age, which in this case is the under 40 yrs group. So, for those under 40, there is about a 77% increased risk for males relative to females.\nThe coefficient for age = 0.70 (95% CI 0.61, 0.80; p &lt; 0.001). This represents the ‚Äúeffect‚Äù of age (being older than 40 yrs relative to younger than 40 yrs) on hospitalisation risk at the reference level of sex, which in this case is female. So, for females, there is about a 30% risk reduction in the need for hospitalisation for older relative to younger drivers.\nThe coefficient for the interaction term: sex * age = 0.52 (95% CI 0.44, 0.62; p &lt; 0.001). This represents the multiplicative increase in the magnitude of association for males over 40 yrs."
  },
  {
    "objectID": "posts/001_24Nov2023/index.html#effect-modification-means-more-associations-to-estimate",
    "href": "posts/001_24Nov2023/index.html#effect-modification-means-more-associations-to-estimate",
    "title": "Interactions (effect modifiers) are important - don‚Äôt ignore them",
    "section": "4 Effect modification means more associations to estimate",
    "text": "4 Effect modification means more associations to estimate\nIn this specific case, when you treat age as a confounder, the model produces two risk ratios - one for sex and one for age. However, when you treat age as an effect modifier, there are now four possible risk ratios to estimate (if you care about age more than it being a ‚Äúnuisance‚Äù variable to control for). These are:\n\nThe effect of being male in younger individuals.\nThe effect of being male in older individuals.\nThe effect of being older in females.\nThe effect of being older in males.\n\nYou can easily enough work these out manually by multiplying the respective reference coefficients with the interaction coefficient. The risk ratios for each of the above would then be:\n\n1.77 (we can just read this one straight off the model output)\n1.77 x 0.52 = 0.92\n0.70 (again we can just read this one straight off)\n0.70 x 0.52 = 0.36\n\nNote that the effects for 1. and 2. are very similar to what we calculated straight from the 2 x 2 tables (1.84 and 0.92, respectively - as previously mentioned, the effects for 3. and 4. aren‚Äôt able to be calculated for the stratifying variable)."
  },
  {
    "objectID": "posts/001_24Nov2023/index.html#emmeans-should-be-your-new-best-friend",
    "href": "posts/001_24Nov2023/index.html#emmeans-should-be-your-new-best-friend",
    "title": "Interactions (effect modifiers) are important - don‚Äôt ignore them",
    "section": "5 Emmeans should be your new best friend",
    "text": "5 Emmeans should be your new best friend\nPerhaps I am preaching to the converted, but if you don‚Äôt know what the emmeans package and specific function in R does, then you should learn about it (the equivalent function in Stata is margins).\nhttps://cran.r-project.org/web/packages/emmeans/index.html\nhttps://aosmith.rbind.io/2019/03/25/getting-started-with-emmeans/\nemmeans does a lot of things, but perhaps its workhorse function is to allow you to take a model and calculate adjusted predictions (either at set values of covariates, or by ‚Äòaveraging‚Äô over them). In this case, we can very easily use emmeans to reproduce the manual calculations we just did.\n\n\nCode\nemmeans(mod_interact, ~ sex + age, type = \"response\") |&gt; \n  data.frame() |&gt; \n  flextable() |&gt; \n  colformat_double(digits = 3, na_str = \"N/A\") |&gt;\n  set_table_properties(layout = \"autofit\") |&gt; \n  height(height = 1, unit = \"cm\") |&gt; \n  hrule(rule = \"atleast\", part = \"header\") |&gt; \n  align(align = \"center\", part = \"body\") |&gt;\n  bg(bg = \"white\", part = \"all\") |&gt; \n  flextable::font(fontname = \"Consolas\", part = \"all\") |&gt;\n  theme_vanilla()\n\n\nPredicted Probabilities of HospitalisationsexageprobSEdfasymp.LCLasymp.UCLFemale&lt; 400.1330.006 Inf0.1220.145Male&lt; 400.2350.007 Inf0.2220.248Female‚â• 400.0930.005 Inf0.0840.103Male‚â• 400.0860.004 Inf0.0780.095\n\n\nSpecifying type = \"response\" in the emmeans call indicates that we want to calculate the outcome on the probability (i.e.¬†risk) scale. It is simple enough to plot these predicted probabilities using the emmip function in emmeans.\n\n\nCode\nemmip(mod_interact, age ~ sex, type = \"response\") + \n  theme_bw(base_size = 18)\n\n\n\n\n\n\n\n\n\nTo get the risk ratios we have been working with until now, we simply add the pairs(rev = T) function to the call:\n\n\nCode\nemmeans(mod_interact, ~ sex + age, type = \"response\") |&gt; pairs(rev = T) |&gt; \n  data.frame() |&gt; \n  flextable() |&gt; \n  colformat_double(digits = 3, na_str = \"N/A\") |&gt;\n  set_table_properties(layout = \"autofit\") |&gt; \n  height(height = 1, unit = \"cm\") |&gt; \n  hrule(rule = \"atleast\", part = \"header\") |&gt; \n  align(align = \"center\", part = \"body\") |&gt;\n  bg(bg = \"white\", part = \"all\") |&gt; \n  flextable::font(fontname = \"Consolas\", part = \"all\") |&gt;\n  theme_vanilla()\n\n\nAll Pairwise Risk RatioscontrastratioSEdfnullz.ratiop.valueMale &lt; 40 / Female &lt; 401.7670.091 Inf1.00011.0030.000Female ‚â• 40 / Female &lt; 400.6980.047 Inf1.000-5.3560.000Female ‚â• 40 / Male &lt; 400.3950.023 Inf1.000-15.9230.000Male ‚â• 40 / Female &lt; 400.6460.043 Inf1.000-6.5820.000Male ‚â• 40 / Male &lt; 400.3660.021 Inf1.000-17.4990.000Male ‚â• 40 / Female ‚â• 400.9250.066 Inf1.000-1.0830.700\n\n\nNote that this gives us two extra comparisons we might not really want (the 3rd and 4th lines of the output) as it estimates every single pairwise comparison. We can get a bit fancier and customise the emmeans output to give us only what we want:\n\n\nCode\nemm &lt;- emmeans(mod_interact, ~ sex + age, type = \"response\") # save the estimated risks\ncustom &lt;- list(`The effect of being male in younger individuals` = c(-1,1,0,0),\n               `The effect of being male in older individuals` = c(0,0,-1,1),\n               `The effect of being older in females` = c(-1,0,1,0),\n               `The effect of being older in males` = c(0,-1,0,1)) # create custom grid of RR's to estimate\ncontrast(emm, custom) |&gt; \n  summary(infer = T) |&gt; \n  data.frame() |&gt; \n  flextable() |&gt; \n  colformat_double(digits = 3, na_str = \"N/A\") |&gt;\n  set_table_properties(layout = \"autofit\") |&gt; \n  height(height = 1, unit = \"cm\") |&gt; \n  hrule(rule = \"atleast\", part = \"header\") |&gt; \n  align(align = \"center\", part = \"body\") |&gt;\n  bg(bg = \"white\", part = \"all\") |&gt; \n  flextable::font(fontname = \"Consolas\", part = \"all\") |&gt;\n  theme_vanilla()\n\n\nCustom Pairwise Risk RatioscontrastratioSEdfasymp.LCLasymp.UCLnullz.ratiop.valueThe effect of being male in younger individuals1.7670.091 Inf1.5971.9561.00011.0030.000The effect of being male in older individuals0.9250.066 Inf0.8041.0651.000-1.0830.279The effect of being older in females0.6980.047 Inf0.6120.7961.000-5.3560.000The effect of being older in males0.3660.021 Inf0.3270.4091.000-17.4990.000\n\n\nNote, that these match the manual calculations pretty well.\nPlease take some time to learn about emmeans (or margins in Stata). It will make your life so much easier if you plan to have a career in research (and don‚Äôt always have access to a statistician)."
  },
  {
    "objectID": "posts/009_05Apr_2024/index.html",
    "href": "posts/009_05Apr_2024/index.html",
    "title": "Don‚Äôt be Scared of Splines",
    "section": "",
    "text": "Have you heard the term restricted cubic spline (RCS) and thought ‚Äòthat‚Äôs just seems too hard but I should learn about it one day‚Äô and then stuck to modelling your continuous predictor as you always do, assuming it has a linear relationship with the outcome? Well I hope that by the end of this post you have a better basic understanding of what RCS‚Äôs actually are, how they give you so much more flexibility in your modelling toolkit, and above all else, how they are really not that hard to use.\nWhen you want to explore the association between a continuous predictor variable and an outcome (of any form really - binary, count, continuous) you have choices to make about how you parameterise that predictor. In fact, one could consider a hierarchy of such choices that range from downright egregious through to ‚Äòwe‚Äôll just do it how it‚Äôs always done‚Äô through to what is becoming thought more of these days as ‚Äòbest-practice‚Äô in statistical modelling. These approaches include:\n\nCategorising the predictor - Egregious.\nAssuming the predictor has a linear relationship with the outcome (or its link function if the outcome is not continuous) - ‚ÄòWe‚Äôll just do it how it‚Äôs always done‚Äô.\nAssuming the predictor has a non-linear relationship with the outcome and using a piece-wise model (segmented regression) to model smaller segments of the data where linearity does in fact hold - A better alternative than assuming linearity.\nAssuming the predictor has a non-linear relationship with the outcome and using polynomial (e.g.¬†quadratic/cubic/etc) regression - Again, a better alternative than assuming linearity.\nAssuming the predictor has a non-linear relationship with the outcome and using RCS‚Äôs - arguably ‚Äòbest practice‚Äô.\n\n\n\n\n\n\n\nImportant\n\n\n\nDon‚Äôt forget it‚Äôs always a good idea to plot your data first to visualise the relationship (using a lowess smoother helps). There is no need to worry about non-linearity if in fact the relationship between your predictor and outcome isn‚Äôt - just model it as linear and you‚Äôre done.\n\n\nNow, having made that point, let me follow by saying that this is relatively easy when you have a continuous predictor and a continuous outcome. But what do you do with other outcome types - for example, in the case of a binary outcome (successes/failures) your outcome just consists of a bunch of 0's and 1's. This is more challenging to visualise but it is possible. Here, a good way to visualise your observed data is to ‚Äòbin‚Äô the predictor into discrete categories (arbitrarily decided by you), counting the number of successes out of the total in each bin - this will give the proportion of successes - i.e.¬†the observed probability of success in each bin. You then convert each proportion into its equivalent logit (log-odds) and plot this (on the Y axis) against the mid-point of each bin of the predictor on the X axis. If the best-fitting line in that plot is approximately linear, then the assumption of linearity of the continuous predictor with the binary outcome is upheld.\nWell I did say this was more challenging‚Ä¶\nUltimately, visualise your data where it‚Äôs easy enough to do so (which will primarily be the continuous predictor vs continuous outcome case). But when this isn‚Äôt so straightforward or practical, as in the binary outcome case above, we can in lieu use model-fitting statistics to help us decide whether incorporating non-linear predictor terms in our model is of value or not. In the basic comparison we fit two models - one assuming linearity and one assuming non-linearity (via one of the other methods) and let either some information criterion (e.g.¬†the AIC), or a likelihood ratio test guide us as to the better fit. So it is certainly still possible to incorporate non-linear terms in a statistical model without having first plotted that data. I‚Äôll illustrate this shortly.\nNow let‚Äôs have a look at some simulated data that demonstrates a non-linear relationship of the predictor with the outcome, and how these different approaches may be applied to model this."
  },
  {
    "objectID": "posts/003_08Dec_2023/index.html",
    "href": "posts/003_08Dec_2023/index.html",
    "title": "A Very Merry Christmas",
    "section": "",
    "text": "This figure was made using ggplot2 and while I can‚Äôt take credit for coming up with the idea (source), I have added a couple of flourishes including the animated lights.\nI hope everyone has a safe, happy and enjoyable holiday period.\n\n\nCode\nlibrary(ggplot2)\nlibrary(gganimate)\nlibrary(gifski)\nlibrary(extrafont)\nloadfonts()\n\n# Read in the base Christmas tree data\nChristmasTree &lt;- read.csv(\"https://raw.githubusercontent.com/t-redactyl/Blog-posts/master/Christmas%20tree%20base%20data.csv\")\n\n# Change tree colour\nChristmasTree$Tree.Colour[ChristmasTree$Tree.Colour == \"#143306\"] &lt;- \"green4\"\n\n# Generate the \"lights\"\nDesired.Lights &lt;- 100\nTotal.Lights &lt;- sum(round(Desired.Lights * 0.35) + round(Desired.Lights * 0.20) + \n                    round(Desired.Lights * 0.17) + round(Desired.Lights * 0.13) +\n                    round(Desired.Lights * 0.10) + round(Desired.Lights * 0.05))\n\nLights &lt;- data.frame(Lights.X = c(round(runif(round(Desired.Lights * 0.35), 4, 18), 0),\n                                  round(runif(round(Desired.Lights * 0.20), 5, 17), 0),\n                                  round(runif(round(Desired.Lights * 0.17), 6, 16), 0),\n                                  round(runif(round(Desired.Lights * 0.13), 7, 15), 0),\n                                  round(runif(round(Desired.Lights * 0.10), 8, 14), 0),\n                                  round(runif(round(Desired.Lights * 0.05), 10, 12), 0)))\nLights$Lights.Y &lt;- c(round(runif(round(Desired.Lights * 0.35), 4, 6), 0),\n                     round(runif(round(Desired.Lights * 0.20), 7, 8), 0),\n                     round(runif(round(Desired.Lights * 0.17), 9, 10), 0),\n                     round(runif(round(Desired.Lights * 0.13), 11, 12), 0),\n                     round(runif(round(Desired.Lights * 0.10), 13, 14), 0),\n                     round(runif(round(Desired.Lights * 0.05), 15, 17), 0))\nLights$Lights.Colour &lt;- c(round(runif(Total.Lights, 1, 3), 0))\n\n# Generate the \"baubles\"\nBaubles &lt;- data.frame(Bauble.X = c(6, 9, 15, 17, 5, 13, 16, 7, 10, 14, 7, 9, 11, 14, 8, 14, 9, 12, 11, 12, 14, 11, 17, 10))\nBaubles$Bauble.Y &lt;- c(4, 5, 4, 4, 5, 5, 5, 6, 6, 6, 8, 8, 8, 8, 10, 10, 11, 11, 12, 13, 10, 16, 7, 14)\nBaubles$Bauble.Colour &lt;- factor(c(1, 2, 2, 3, 2, 3, 1, 3, 1, 1, 1, 2, 1, 2, 3, 3, 2, 1, 3, 2, 1, 3, 3, 1))\nBaubles$Bauble.Size &lt;- c(6, 18, 6, 6, 12, 6, 12, 12, 12, 6, 6, 6, 18, 18, 18, 12, 18, 6, 6, 12, 12, 18, 18, 12)\n\n# Generate the plot\np &lt;- ggplot() + \n  geom_tile(data = ChristmasTree, aes(x = Tree.X, y = Tree.Y, fill = Tree.Colour)) +\n  scale_fill_identity() + \n  geom_point(data = Lights, aes(x = Lights.X, y = Lights.Y), color = \"lightgoldenrodyellow\", shape = 8) +\n  geom_point(data = Baubles, aes(x = Bauble.X, y = Bauble.Y, colour = Bauble.Colour), size = Baubles$Bauble.Size, shape = 16) +\n  scale_colour_manual(values = c(\"firebrick2\", \"gold\", \"blue3\")) +\n  scale_size_area(max_size = 12) +\n  theme_bw() +\n  scale_x_continuous(breaks = NULL) + \n  scale_y_continuous(breaks = NULL) +\n  geom_segment(aes(x = 2.5, xend = 4.5, y = 1.5, yend = 1.5), colour = \"blueviolet\", size = 2) +\n  geom_segment(aes(x = 5.5, xend = 8.5, y = 1.5, yend = 1.5), colour = \"dodgerblue3\", size = 2) +\n  geom_segment(aes(x = 13.5, xend = 16.5, y = 1.5, yend = 1.5), colour = \"blueviolet\", size = 2) +\n  geom_segment(aes(x = 17.5, xend = 19.5, y = 1.5, yend = 1.5), colour = \"dodgerblue3\", size = 2) +\n  geom_segment(aes(x = 3.5, xend = 3.5, y = 0.5, yend = 2.5), colour = \"blueviolet\", size = 2) +\n  geom_segment(aes(x = 7.0, xend = 7.0, y = 0.5, yend = 2.5), colour = \"dodgerblue3\", size = 2) +\n  geom_segment(aes(x = 15.0, xend = 15.0, y = 0.5, yend = 2.5), colour = \"blueviolet\", size = 2) +\n  geom_segment(aes(x = 18.5, xend = 18.5, y = 0.5, yend = 2.5), colour = \"dodgerblue3\", size = 2) +\n  annotate(\"text\", x = 11, y = 20, label = \"Merry Christmas!\",family = \"Luminari\", color = \"white\", size = 12) +\n  transition_states(states=Lights.Colour, transition_length = 0, state_length = 0.0001) +\n  labs(x = \"\", y = \"\") +\n  theme(legend.position = \"none\") +\n  theme(panel.background = element_rect(fill = 'midnightblue', colour = \"yellow\"))\n\n# Animate\nanimate(p, nframe = 20, fps = 20)"
  },
  {
    "objectID": "posts/004_02Feb_2024/index.html",
    "href": "posts/004_02Feb_2024/index.html",
    "title": "Put your ggplot on steroids",
    "section": "",
    "text": "Welcome back to Stats Tips for 2024 - hope you managed a nice break.\nIt‚Äôs a short one today. If you didn‚Äôt already now it existed, check out plotly for taking your ggplots to the next level.\nSometimes it can be extremely helpful to quickly link discrete elements of a plot to the corresponding observation/s in your dataframe. For example, you have a suspected outlier in a scatterplot and you want to know which individual that belongs to. Or, you have an unavoidably busy plot; for example, plotting the predictions from a mixed model for longitudinal data overlaid on the observed data for comparison. In these cases it‚Äôs nearly impossible to discern the origin of the plotted data. In both use-case scenarios (and many more), plotly can help.\nIn this example of the latter use-case, we are going to use data from a built-in dataset in the lme4 package. The sleepstudy data looks at reaction times over time in sleep-deprived individuals. For the sake of the exercise we will fit a mixed model with reaction time (ms) as the outcome, time (days) as a fixed-effect and time (days) and individual as random-effects. So this is a random slopes model allowing the ‚Äòeffect‚Äô of sleep-deprivation on reaction time to vary over time for each individual. We fit the model and view a few lines of the dataframe which now contains the fixed (mod_pred_fix) and random (mod_pred_ran) predictions.\n\n\nCode\nlibrary(lme4)\nlibrary(ggplot2)\nlibrary(plotly)\n# Load data\ndata(\"sleepstudy\")\n# Model\nmod &lt;- lmer(Reaction ~ Days + (Days | Subject), data = sleepstudy)\n# Predict\nsleepstudy$mod_pred_fix &lt;- predict(mod, re.form = NA) # predict fixed effects\nsleepstudy$mod_pred_ran &lt;- predict(mod) # predict random effects\n# View data\nhead(sleepstudy, 10)\n\n\n\n\n\n\nReaction\nDays\nSubject\nmod_pred_fix\nmod_pred_ran\n\n\n\n\n249.5600\n0\n308\n251.4051\n253.6637\n\n\n258.7047\n1\n308\n261.8724\n273.3299\n\n\n250.8006\n2\n308\n272.3397\n292.9962\n\n\n321.4398\n3\n308\n282.8070\n312.6624\n\n\n356.8519\n4\n308\n293.2742\n332.3287\n\n\n414.6901\n5\n308\n303.7415\n351.9950\n\n\n382.2038\n6\n308\n314.2088\n371.6612\n\n\n290.1486\n7\n308\n324.6761\n391.3275\n\n\n430.5853\n8\n308\n335.1434\n410.9937\n\n\n466.3535\n9\n308\n345.6107\n430.6600\n\n\n\n\n\n\nWe can then plot the data interactively by simply ‚Äòwrapping‚Äô the ggplot object in a plotly call. If you hover over a data point you can easily identify which individual it belongs to as well as the observed reaction time. Similarly, by hovering over one of the random slopes you will see the predicted reaction time and the individual that corresponds to.\nYou won‚Äôt want to do this for every plot you make but it does provide a simple way to make some of your more complex visualisations using ggplot that bit more useful (and fun!) in helping to understand your data.\n\n\nCode\n# Plot\np &lt;- sleepstudy |&gt;\n    ggplot(aes(x = Days, y = Reaction, color = factor(Subject))) +\n    geom_line(aes(x = Days, y = mod_pred_ran)) +\n    geom_line(aes(x = Days, y = mod_pred_fix), linewidth = 2, color = \"blue\") +\n    geom_point(alpha = 0.5) +\n    xlab(\"Time (days)\") + ylab(\"Reaction Time (ms)\") +\n    guides(color = \"none\") +\n    theme_bw(base_size = 15)\nggplotly(p)"
  },
  {
    "objectID": "posts/005_16Feb_2024/index.html",
    "href": "posts/005_16Feb_2024/index.html",
    "title": "Immortal time bias - ‚ÄúThe fallacy that never dies‚Äù (Part 1)",
    "section": "",
    "text": "In 2001, a paper published in the Annals of Internal Medicine reported that Oscar winners had a longer life expectancy - by about 4 years - compared to their less successful peers. The authors conclusions were that:\n‚ÄúThe association of high status with increased longevity that prevails in the public also extends to celebrities, contributes to a large survival advantage, and is partially explained by factors related to success.‚Äù\nThe study received widespread attention in the media, with one future Oscar winner acknowledging the work in her acceptance speech.\nThe problem was that the reported survival advantage was illusory, and the reason for this was an invalid analysis that is not alone in the literature. As in any simple time-to-event analysis, two groups may be compared in their respective ‚Äòsurvival‚Äô times. In this study, subjects were first classified as winners or non-winners and observation time counted as their time alive. The error in this case was to consider winning status time-fixed (A), when in reality it is time-varying (B). By naively assuming it is time-fixed, we are erroneously attributing the time that a winner was in fact a loser prior to getting their gong, to their winning observation time.\n\nThis creates a distortion or bias in the exposure/treatment -&gt; outcome association, usually in a direction that overestimates the benefit of the exposure/treatment. When proper methods are then employed, the perceived benefits are reduced or sometimes reversed. And in fact that is exactly what was found when a re-analysis of the data was conducted in 2006 - the survival advantage was calculated to be closer to 1 year and not deemed statistically significant.\nIn general, the observation time prior to the exposure/treatment commencing (for those exposed/treated) is considered ‚Äòimmortal‚Äô, because the subject cannot experience the outcome during this period as they have yet to receive the exposure/treatment. If you are like me, this fairly classic description of immortal time hurts my brain and so I just like to simply think of it as the period that a person‚Äôs observation time has been misclassified.\nObservational research that involves time-to-event outcomes is particularly prone to immortal time bias and central to the problem is the specification of ‚Äòtime zero‚Äô - i.e.¬†when does the clock start? There are several examples of study design choices that can lead you down the wrong analysis path if you are not careful, and an especially pertinent one in this field is drawing contrasts between treated and untreated patients (hint: a patient is not ‚Äòtreated‚Äô for the duration of their observation time if they were only on treatment for the last 10% of that time).\nSo, what‚Äôs the solution?\nTime-varying covariates\nI will illustrate their use in an example in the next post."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Stats Tips - Welcome",
    "section": "",
    "text": "Hi Everyone,\nI‚Äôm not sure how much everyone‚Äôs getting out of the stats tips that I put on WhatsApp on Fridays, but maybe some of it is helpful. For those of you who are interested, I thought that if I was going to do this on a semi-regular basis, I might as well turn it into a resource. So I am having a go at a blog-style format for posting these tips. It also means I can more easily illustrate concepts where needed with code, etc. And it also helps to not overload your WhatsApp with a bunch of text. Some posts will be short and some will be longer and I may not be able to put something up every week, depending on workload, but will do my best. I hope it‚Äôs something people find useful.\nSome general housekeeping:\n\nYou can view and copy the code as blocks just before each set of output (there will be a Copy to Clipboard button at the top right of each code block); or by clicking the &lt;/&gt; Code button at the top right of the page, then View Source and copying the entire block.\nThere is a light/dark mode toggle on the top right of the page, depending on how you like to view your internet.\nFeel free to add any comments/questions to a post and/or provide general feedback."
  },
  {
    "objectID": "posts/002_01Dec_2023/index.html",
    "href": "posts/002_01Dec_2023/index.html",
    "title": "It pays to think like a Bayesian",
    "section": "",
    "text": "Recall that the question this week was to choose between:\nA) Switch to another door.\nB) Stay with your original door.\nC) It doesn‚Äôt matter if you switch or stay."
  },
  {
    "objectID": "posts/002_01Dec_2023/index.html#the-question",
    "href": "posts/002_01Dec_2023/index.html#the-question",
    "title": "It pays to think like a Bayesian",
    "section": "",
    "text": "Recall that the question this week was to choose between:\nA) Switch to another door.\nB) Stay with your original door.\nC) It doesn‚Äôt matter if you switch or stay."
  },
  {
    "objectID": "posts/002_01Dec_2023/index.html#the-answer",
    "href": "posts/002_01Dec_2023/index.html#the-answer",
    "title": "It pays to think like a Bayesian",
    "section": "The Answer",
    "text": "The Answer\nThe answer is that you should switch doors, and in fact if you do switch, you double your chances of winning the car - from 33.3% to 66.7%.\nThis is known as the Monty Hall problem and when it was first posed in a magazine column in 1975 managed to confuse readers to the extent that even mathematicians were writing in to the magazine to claim that answer was in fact wrong and staying with the originally chosen door was the better strategy for success.\nThe simplest way that I can explain this is that you start out with a 33.3% chance of winning the car and those probabilities don‚Äôt change once you lock in your selection and Monty offers you another chance to choose (i.e.¬†the probabilities don‚Äôt change to 50/50 once Monty reveals what‚Äôs behind one of the doors).\n\nIf you stay\nIf you choose the correct door to start with (for which there is a 33.3% chance), staying will result in you ending up with the car (winning).\nIf you choose the incorrect door to start with (for which there is a 66.7% chance), staying will necessarily result in you ending up with a goat (losing).\n\n\nIf you switch\nIf you choose the correct door to start with (for which there is a 33.3% chance), switching will result in you ending up with a goat (losing).\nIf you choose the incorrect door to start with (for which there is a 66.7% chance), switching will necessarily result in you ending up with the car, because Monty has to pick the only other losing door to open (winning).\nStaying is associated with a 33.3% success rate, whereas switching doubles your chance of success to 66.7%.\nStop here if equations give you the equivalent of the aftermath of eating Mexican food. What I have done below is show how we can arrive at the same answer using an analytical approach when our logic/intuition fails. You may not want to venture that far‚Ä¶\nWhat I think is cool about this problem is that while the result might seem counterintuitive to how we naturally process chance, using Bayesian reasoning provides a formulaic way to get at the right answer. This again uses conditional probabilities as I introduced them a few weeks ago. Bayesian thinking is about utilising prior knowledge in conjunction with new data to improve or update our knowledge (whereas the Frequentist approach to statistics doesn‚Äôt care so much about prior knowledge and instead just uses the data at hand).\n\n\n\n\n\n\nImportant Concept\n\n\n\nBayesian reasoning enables the analysis of data under the light of prior knowledge.\n\n\nBayes Theorem can be written as:\n\\[\nPr(\\theta | data) = \\frac{Pr(data | \\theta) Pr(\\theta)}{Pr(data)}\n\\]\nwhere \\(\\theta\\) could be a particular parameter or hypothesis.\nHere:\n\\(Pr(data | \\theta)\\) is the likelihood function (the data, or what we measure)\n\\(Pr(\\theta)\\) is the prior probability of our hypothesis (prior knowledge before we the measurement)\n\\(Pr(data)\\) is the prior probability of the data\n\\(Pr(\\theta | data)\\) is the posterior probability of our hypothesis (i.e.¬†‚Äúin light of the data‚Äù)\nOn the Bayesian/Frequentist topic, note that \\(Pr(data | \\theta)\\) is what null-hypothesis significance testing (NHST) encapsulates and this is a Frequentist concept. Whenever we calculate a p value we are asking:\n\n‚ÄúWhat is the probability of this new data (or data even more extreme) occurring by chance given the null hypothesis is true?‚Äù\n\nBut really, what we want to know most of the time is the opposite:\n\n‚ÄúWhat is the probability of the null hypothesis being true given this new data?‚Äù\n\nThat is a Bayesian concept and is answered with \\(Pr(\\theta | data)\\). Maybe we should become more Bayesian in how we handle our research‚Ä¶\nAnyway, excuse the digression. We can generalise Bayes Theorem to the Monty Hall problem as:\n\\[\nPr(\\text{car behind door x} | \\text{Monty opens door y}) = \\frac{Pr(\\text{Monty opens door y} | \\text{car behind door x}) Pr(\\text{car behind door x})}{Pr(\\text{Monty opens door y})}\n\\]\nFor the sake of the exercise, let x = door 1 and y = door 3.\nSo we are interested in the probability the car is behind door 1 (that means we picked door 1) when Monty opens door 3 to reveal a goat.\nIn calculating the different components of Bayes Theorem, we first need to enumerate the various probabilities.\n\\(Pr(\\text{car behind door 1}) = Pr(\\text{car behind door 2}) = Pr(\\text{car behind door 3}) = 33.3\\%\\)\nThese are the prior probabilities.\nThen:\n\\(Pr(\\text{Monty opens door 3} | \\text{car behind door 1}) = 50\\%\\)\nMonty can only pick doors 2 or 3, as we picked door 1.\n\\(Pr(\\text{Monty opens door 3} | \\text{car behind door 2}) = 100\\%\\)\nMonty can only pick door 3, as we picked door 1 and he doesn‚Äôt want to reveal the car behind door 2.\n\\(Pr(\\text{Monty opens door 3} | \\text{car behind door 3}) = 0\\%\\)\nMonty won‚Äôt reveal the car as part of his playing rules.\nThese are the likelihoods or the data.\nThe \\(Pr(\\text{Monty opens door 3})\\) is a little trickier to calculate. Here we don‚Äôt need to worry about the car being behind any specific door, only that Monty won‚Äôt reveal it. Intuitively, this would be \\(50\\%\\) as he only has two doors to choose from. But you can also work this out by summing the product of each of the prior probabilities and the evidence:\n\\(Pr(\\text{Monty opens door 3}) = (0.33 * 0.5) + (0.33 * 1) + (0.33 * 0) = 0.5\\)\nFinally, we can get to working out the posterior probabilities of the car being behind each door given Monty opens door 3. We use Bayes Theorem as shown above to do this.\n\\[\nPr(\\text{car behind door 1} | \\text{Monty opens door 3}) = \\frac{Pr(\\text{Monty opens door 3} | \\text{car behind door 1}) Pr(\\text{car behind door 1})}{Pr(\\text{Monty opens door 3})}\n\\] \\[\n= \\frac{0.5 * 0.33}{0.5} = 33.3\\%\n\\] Likewise:\n\\[\nPr(\\text{car behind door 2} | \\text{Monty opens door 3})  = \\frac{1 * 0.33}{0.5} = 66.7\\%\n\\] and\n\\[\nPr(\\text{car behind door 3} | \\text{Monty opens door 3})  = \\frac{0 * 0.33}{0.5} = 0\\%\n\\]\nRemember, we initially chose door 1. So, when Monty opens door 3 (this could have been door 2 - we just needed to pick a door for the exercise), we double our chances of winning by switching to door 2. And this is how Bayesian reasoning can come to the rescue when our own intuition fails.\nFurther explanation can be found here if you remain unconvinced:\nhttps://en.wikipedia.org/wiki/Monty_Hall_problem\nhttps://statisticsbyjim.com/fun/monty-hall-problem/"
  },
  {
    "objectID": "posts/006_23Feb_2024/index.html",
    "href": "posts/006_23Feb_2024/index.html",
    "title": "Immortal time bias - ‚ÄúThe fallacy that never dies‚Äù (Part 2)",
    "section": "",
    "text": "In the last post I introduced the concept of immortal time bias and how it can distort associations in your survival analysis, if you naively misclassify unexposed/untreated observation time as exposed/treated. This week I am going to illustrate the concept with some data and R code. It would have been good to analyse the Oscar Winner‚Äôs data but as I could not locate that anywhere online, we are instead going to look at one of the first studies in which immortal time bias was subsequently recognised to be a problem.\nThe work came out of Stanford University in the early 1970s and assessed the survival benefit of potential heart transplant recipients. In the analysis, the event of interest was death and the primary treatment was heart transplantation - so survival amongst transplant recipients was compared to that amongst accepted patients into the program that did not end up receiving a transplant. Treatment was initially considered time-fixed and the patients divided into two groups - ‚Äòever transplanted‚Äô vs ‚Äònever transplanted‚Äô. Survival time amongst recipients was found to be longer than those who didn‚Äôt receive transplantation.\nThe immortal time bias here involves the waiting time of those patients who survived to make it to the transplant. Because this portion of the observation time was classified as exposed to transplantation instead of unexposed, it offered a guaranteed survival time to the transplanted group. The result of this misclassification was to produce an artificial increase in the mortality rate of the reference group, thus suggesting a benefit of heart transplant surgery. In a later reanalysis of the data, the apparent survival benefit of the transplanted group disappeared when the immortal time was properly accounted for by a time-dependent analysis."
  },
  {
    "objectID": "posts/006_23Feb_2024/index.html#load-data",
    "href": "posts/006_23Feb_2024/index.html#load-data",
    "title": "Immortal time bias - ‚ÄúThe fallacy that never dies‚Äù (Part 2)",
    "section": "1 Load data",
    "text": "1 Load data\nAs this study is considered a canonical example of immortal time bias, the data comes built into R‚Äôs survival package. We can load the data and inspect the relevant jasa dataframe as below.\n\n\nCode\nlibrary(survival)\nlibrary(survminer)\nlibrary(gtsummary)\nlibrary(dplyr)\ndata(heart, package = \"survival\")\nhead(jasa)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbirth.dt\naccept.dt\ntx.date\nfu.date\nfustat\nsurgery\nage\nfutime\nwait.time\ntransplant\nmismatch\nhla.a2\nmscore\nreject\n\n\n\n\n1937-01-10\n1967-11-15\nNA\n1968-01-03\n1\n0\n30.84463\n49\nNA\n0\nNA\nNA\nNA\nNA\n\n\n1916-03-02\n1968-01-02\nNA\n1968-01-07\n1\n0\n51.83573\n5\nNA\n0\nNA\nNA\nNA\nNA\n\n\n1913-09-19\n1968-01-06\n1968-01-06\n1968-01-21\n1\n0\n54.29706\n15\n0\n1\n2\n0\n1.11\n0\n\n\n1927-12-23\n1968-03-28\n1968-05-02\n1968-05-05\n1\n0\n40.26283\n38\n35\n1\n3\n0\n1.66\n0\n\n\n1947-07-28\n1968-05-10\nNA\n1968-05-27\n1\n0\n20.78576\n17\nNA\n0\nNA\nNA\nNA\nNA\n\n\n1913-11-08\n1968-06-13\nNA\n1968-06-15\n1\n0\n54.59548\n2\nNA\n0\nNA\nNA\nNA\nNA\n\n\n\n\n\n\nThe variables that we‚Äôre going to use are:\n\nfustat - the ‚Äòevent‚Äô variable; 0 = alive, 1 = dead at the end of follow-up.\nfutime - the primary ‚Äòtime‚Äô variable; time (days) from acceptance into the transplant program until death or censoring.\nwait.time - the secondary ‚Äòtime‚Äô variable; time (days) from acceptance into the transplant program until receiving a heart if transplanted (NA for those who never underwent transplant surgery).\ntransplant - the ‚Äòtreatment/exposure‚Äô variable; 0 = did not receive heart, 1 = received heart."
  },
  {
    "objectID": "posts/006_23Feb_2024/index.html#visualise-individual-survival-trajectories",
    "href": "posts/006_23Feb_2024/index.html#visualise-individual-survival-trajectories",
    "title": "Immortal time bias - ‚ÄúThe fallacy that never dies‚Äù (Part 2)",
    "section": "2 Visualise individual survival trajectories",
    "text": "2 Visualise individual survival trajectories\nUsing a bit of ggplot2 magic, we can now plot the individual observation times for the 103 patients in the study. Note that I have stratified observation time by transplant status (orange for the period a patient remains untransplanted and blue for the period following a transplant).\n\n\nCode\n# Create 'id' variable\njasa$id &lt;- seq(1:dim(jasa)[1])\n# Replace wait.time with futime if didn't undergo transplant\njasa$wait.time[is.na(jasa$wait.time)] &lt;- jasa$futime[is.na(jasa$wait.time)]\n# Plot\njasa |&gt;\n  ggplot(aes(x = id, y = futime)) +\n  geom_linerange(aes(ymin = 0, ymax = wait.time), color = \"#E7B800\", linewidth = 1) +\n  geom_linerange(aes(ymin = wait.time, ymax = futime), color = \"#2E9FDF\", linewidth = 1) +\n  geom_point(aes(shape = factor(fustat)), stroke = 1, cex = 1, color = \"black\") +\n  scale_shape_manual(values = c(1, 3), labels = c(\"Censored\", \"Died\"), name = \"Outcome\") +\n  annotate(\"text\", x = 95, y = 1400, label = \"Observation time = yellow - untransplanted\", size = 5, color = \"#E7B800\") +\n  annotate(\"text\", x = 92, y = 1380, label = \"Observation time = blue - post-transplant\", size = 5, color = \"#2E9FDF\") +\n  ggtitle(\"Survival Trajectories for Heart Transplant Patients\") +   \n  ylab(\"Time (days)\") +\n  xlab(\"Patient Number\") + \n  coord_flip() + \n  theme_bw(base_size = 20) +\n  theme(axis.text.y = element_text(size = 15))"
  },
  {
    "objectID": "posts/006_23Feb_2024/index.html#naive-analysis-assuming-treatment-status-is-time-fixed",
    "href": "posts/006_23Feb_2024/index.html#naive-analysis-assuming-treatment-status-is-time-fixed",
    "title": "Immortal time bias - ‚ÄúThe fallacy that never dies‚Äù (Part 2)",
    "section": "3 Naive analysis assuming treatment status is time-fixed",
    "text": "3 Naive analysis assuming treatment status is time-fixed\n\n3.1 Visualise survival curves\nPlotting the Kaplan-Meier survival curves are easy by first saving the survfit object:\nfit &lt;- survfit(Surv(futime, fustat) ~ transplant, data = jasa)\nand then passing this ggsurvplot which does a nicer job of plotting survival data then using R‚Äôs base functions. Note that we ignore wait.time and only specify futime in our fit function. This is because we are assuming if a patient was transplanted, the entire duration of their observation period was considered as such.\n\n\nCode\nfit_naive &lt;- survfit(Surv(futime, fustat) ~ transplant, data = jasa)\nggsurvplot(fit_naive,\n          risk.table = TRUE,\n          risk.table.col = \"strata\",\n          linetype = \"strata\",\n          surv.median.line = \"hv\",\n          ggtheme = theme_bw(base_size = 20),\n          palette = c(\"#E7B800\", \"#2E9FDF\"))\n\n\n\n\n\n\n\n\n\n\n\n3.2 Cox model\nFitting a Cox model is also simple with:\nmod_naive &lt;- coxph(Surv(futime, fustat) ~ transplant, data = jasa)\n\n\nCode\nmod_naive &lt;- coxph(Surv(futime, fustat) ~ transplant, data = jasa)\ntbl_regression(mod_naive, exp = T)\n\n\n\n\n\n\n\n\nCharacteristic\nHR1\n95% CI1\np-value\n\n\n\n\ntransplant\n0.27\n0.17, 0.43\n&lt;0.001\n\n\n\n1 HR = Hazard Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\n\nThis gives a HR = 0.27 (95% CI 0.17, 0.43; p &lt; 0.001) indicating that there is about a 73% reduction in the risk of death with transplantation. Pretty effective, right?"
  },
  {
    "objectID": "posts/006_23Feb_2024/index.html#correct-analysis-assuming-treatment-status-is-time-varying",
    "href": "posts/006_23Feb_2024/index.html#correct-analysis-assuming-treatment-status-is-time-varying",
    "title": "Immortal time bias - ‚ÄúThe fallacy that never dies‚Äù (Part 2)",
    "section": "4 Correct analysis assuming treatment status is time-varying",
    "text": "4 Correct analysis assuming treatment status is time-varying\nUp until now we have just used the data as it‚Äôs been presented to us. Each patient has a single observation with all information about them contained in that row of data. However, to perform the correct time-dependent analysis we first need to construct a time-varying version of the treatment (i.e.¬†transplant) variable. This data format is known as ‚Äòcounting process‚Äô and in the general case involves creating potentially multiple rows of data for each patient with each row corresponding to a different exposure/treatment period of that patients observation time. In this specific example, we will create an additional row of data for transplanted patients splitting time at the point of transplant, so that the first row contains the time from acceptance into the transplant program to the point of transplant, and the second row contains the time from transplant to either death or censoring. We specify this in ‚Äòstart, stop‚Äô format rather than the duration of the interval itself. We will use the tmerge function to do this, although a little bit of manual programming can also achieve the same result.\n\n\nCode\n# Create subset of data selecting relevant variables\njasa_subset &lt;- jasa |&gt; \n  select(id, wait.time, futime, fustat, transplant)\n# Can't have an end time of 0 (one obs) - change this to 0.5\njasa_subset$futime[jasa_subset$futime == 0] &lt;- 0.5\n# Create dataframe in counting process format\njasa_cp &lt;- tmerge(data1 = jasa_subset |&gt; select(id, futime, fustat), \n                  data2 = jasa_subset |&gt; select(id, futime, fustat, wait.time, transplant), \n                  id = id, \n                  death = event(futime, fustat),\n                  transplant = tdc(wait.time)) |&gt; \n            select(-c(futime, fustat))\n\n\nRemember that the original data looked like:\n\n\nCode\nhead(jasa_subset, 7)\n\n\n\n\n\n\nid\nwait.time\nfutime\nfustat\ntransplant\n\n\n\n\n1\n49\n49\n1\n0\n\n\n2\n5\n5\n1\n0\n\n\n3\n0\n15\n1\n1\n\n\n4\n35\n38\n1\n1\n\n\n5\n17\n17\n1\n0\n\n\n6\n2\n2\n1\n0\n\n\n7\n50\n674\n1\n1\n\n\n\n\n\n\nAnd the newly created dataframe in counting process format:\n\n\nCode\nhead(jasa_cp, 9)\n\n\n\n\n\n\nid\ntstart\ntstop\ndeath\ntransplant\n\n\n\n\n1\n0\n49\n1\n0\n\n\n2\n0\n5\n1\n0\n\n\n3\n0\n15\n1\n1\n\n\n4\n0\n35\n0\n0\n\n\n4\n35\n38\n1\n1\n\n\n5\n0\n17\n1\n0\n\n\n6\n0\n2\n1\n0\n\n\n7\n0\n50\n0\n0\n\n\n7\n50\n674\n1\n1\n\n\n\n\n\n\nNote the new ‚Äòstart, stop‚Äô time variables. We have also renamed fustat to death for a more intuitive name. In this small data subset, Subject‚Äôs 3, 4 and 7 underwent a transplant, but only the latter two had both unexposed and exposed time periods during observation (Subject 3 was transplanted at the beginning of their observation), hence each subject now has two rows of data.\n\n4.1 Visualise survival curves\nPlotting the Kaplan-Meier survival curves for the data in this correct format reveals a vastly different result to that which we viewed earlier. There is now almost no separation in the curves.\n\n\nCode\nfit_correct &lt;- survfit(Surv(tstart, tstop, death) ~ transplant, data = jasa_cp)\nggsurvplot(fit_correct,\n          risk.table = TRUE,\n          risk.table.col = \"strata\",\n          linetype = \"strata\",\n          surv.median.line = \"hv\",\n          ggtheme = theme_bw(base_size = 20),\n          palette = c(\"#E7B800\", \"#2E9FDF\"))\n\n\n\n\n\n\n\n\n\n\n\n4.2 Cox model\nCommensurately, the output of the Cox model now gives a HR = 1.13 (95% CI 0.63, 2.04; p = 0.7) indicating that there is about a 13% increase in the risk of death with transplantation - but this could be as much as a 104% increase or even a 37% decrease. That is, we can‚Äôt be confident the observed effect didn‚Äôt occur just by chance. Clearly, this tells a different story to the naive analysis we previously conducted.\n\n\nCode\nmod_correct &lt;- coxph(Surv(tstart, tstop, death) ~ transplant, data = jasa_cp)\ntbl_regression(mod_correct, exp = T)\n\n\n\n\n\n\n\n\nCharacteristic\nHR1\n95% CI1\np-value\n\n\n\n\ntransplant\n1.13\n0.63, 2.04\n0.7\n\n\n\n1 HR = Hazard Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\n\nThe lesson here is to always think about whether your exposure or treatment changes over the course of an individual‚Äôs observation time, and if it does, to account for that in your survival model by constructing a time-varying covariate."
  },
  {
    "objectID": "posts/009_05Apr_2024/index.html#categorising-the-predictor",
    "href": "posts/009_05Apr_2024/index.html#categorising-the-predictor",
    "title": "Don‚Äôt be Scared of Splines",
    "section": "3.1 Categorising the Predictor",
    "text": "3.1 Categorising the Predictor\nI‚Äôm not even really going to talk about this - it‚Äôs very rarely a good thing to categorise a continuous variable. The loss of information and power and introduction of spurious threshold effects (e.g., by grouping 20- to 29-year-olds in one category and 30- to 39-year-olds in another, we create the impression that 20- and 29-year-olds tend to be more alike than 29- and 30-year-olds) are just some of the reasons why this is a bad idea."
  },
  {
    "objectID": "posts/009_05Apr_2024/index.html#lowess-smoother",
    "href": "posts/009_05Apr_2024/index.html#lowess-smoother",
    "title": "Don‚Äôt be Scared of Splines",
    "section": "2.1 Lowess Smoother",
    "text": "2.1 Lowess Smoother\nI mentioned using a lowess smoother above to help visualise any potential association in your data. Lowess regression is a type of non-parametric regression method that fits a smooth curve to your data by calculating a weighted average of Y across a moving span (or window) of X. It is a great initial exploratory method for looking at your data. If we fit a lowess curve to these data, we can see the following:\n\n\nCode\n# Plot lowess\nggplot(dat, aes(x = x, y = y)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"loess\", se = F, linewidth = 2, color = \"#1F77B4FF\") + \n  xlab(\"x\") + ylab(\"y\") + \n  theme_bw(base_size = 20)"
  },
  {
    "objectID": "posts/009_05Apr_2024/index.html#assuming-linearity",
    "href": "posts/009_05Apr_2024/index.html#assuming-linearity",
    "title": "Don‚Äôt be Scared of Splines",
    "section": "3.2 Assuming Linearity",
    "text": "3.2 Assuming Linearity\nIf you bothered to plot the data you would know the association between X and Y was non-linear. But plenty of people don‚Äôt bother to do this and just go ahead and fit a model under the assumption of linearity. If we erroneously did this, the best-fitting regression line would appear as in the following plot. Clearly, for these data, this is a bad modelling choice leading one to think there is no association at all between X and Y.\n\n\nCode\n# Model\nmod1 &lt;- lm(y ~ x, data = dat)\n# Predict Y from model\ndat$mod1_pred &lt;- predict(mod1, dat)\n# Plot linear\nggplot(dat, aes(x = x, y = mod1_pred)) +\n  geom_line(linewidth = 2, color = \"deeppink\") + \n  geom_point(data = dat, aes(x = x, y = y), size = 3) +\n  xlab(\"x\") + ylab(\"y\") + \n  theme_bw(base_size = 20)"
  },
  {
    "objectID": "posts/009_05Apr_2024/index.html#assuming-non-linearity---segmented-regression",
    "href": "posts/009_05Apr_2024/index.html#assuming-non-linearity---segmented-regression",
    "title": "Don‚Äôt be Scared of Splines",
    "section": "3.3 Assuming Non-Linearity - Segmented Regression",
    "text": "3.3 Assuming Non-Linearity - Segmented Regression\nLet‚Äôs now look at a piecewise or linear spline model. Another name for this is segmented regression - a method in which the predictor is partitioned into intervals and a separate line segment is fit to each interval. Essentially, we are fitting multiple, linked linear regression models. To do this we need to first decide where sensible threshold/s exist in the data for us to partition the predictor, allowing approximate linearity within those partitions. In this case, if we look back at the lowess plot, the vertex of the curve represents a reasonable threshold and so we might decide to use a predictor cut-point at X = 50.\nI won‚Äôt go into the details of the parameterisation (it‚Äôs there in the code), but if we fit such a model and then make model predictions from that, we get the following plot. Clearly this is a much better representation of the actual trend in the data, compared to assuming a linear relationship.\n\n\nCode\n# Create a new variable corresponding to change in slope (using 50 as threshold)\ndat &lt;- dat |&gt; \n  mutate(x50 = (x - 50) * (x &gt;= 50))  # will be 0 if x &lt; 50\n# Model\nmod2 &lt;- lm(y ~ x + x50, data = dat)\n# Predict Y from model\ndat$mod2_pred &lt;- predict(mod2, dat)\n# Plot piecewise\nggplot(dat, aes(x = x, y = mod2_pred)) +\n  geom_line(linewidth = 2, color = \"chartreuse\") + \n  geom_point(data = dat, aes(x = x, y = y), size = 3) +\n  xlab(\"x\") + ylab(\"y\") + \n  theme_bw(base_size = 20)"
  },
  {
    "objectID": "posts/009_05Apr_2024/index.html#assuming-non-linearity---polynomial-regression",
    "href": "posts/009_05Apr_2024/index.html#assuming-non-linearity---polynomial-regression",
    "title": "Don‚Äôt be Scared of Splines",
    "section": "3.4 Assuming Non-Linearity - Polynomial Regression",
    "text": "3.4 Assuming Non-Linearity - Polynomial Regression\nPolynomial regression takes this idea further by allowing smoothness to be incorporated into the modelling of the non-linearity. It is a form of regression analysis in which the association between X and Y is modelled as an nth degree polynomial in X. It is important to keep in mind that while the model fits a non-linear curve to the data, the statistical estimation of the model is still considered linear (in the unknown parameters). This differentiates this and models with RCS splines from true non-linear models. See here for some further explanation.\nSo now let‚Äôs fit a quadratic model to these data. It doesn‚Äôt look like too bad a fit either, does it.\n\n\nCode\n# Model - quadratic\nmod3 &lt;- lm(y ~ x + I(x^2), data = dat)\n# Predict Y from models\ndat$mod3_pred &lt;- predict(mod3, dat)\n# Plot piecewise\nggplot(dat, aes(x = x, y = mod3_pred)) +\n  geom_line(linewidth = 2, color = \"chocolate1\") + \n  geom_point(data = dat, aes(x = x, y = y), size = 3) +\n  xlab(\"x\") + ylab(\"y\") + \n  theme_bw(base_size = 20)"
  },
  {
    "objectID": "posts/009_05Apr_2024/index.html#assuming-non-linearity---rcss",
    "href": "posts/009_05Apr_2024/index.html#assuming-non-linearity---rcss",
    "title": "Don‚Äôt be Scared of Splines",
    "section": "3.5 Assuming Non-Linearity - RCS‚Äôs",
    "text": "3.5 Assuming Non-Linearity - RCS‚Äôs\n\n3.5.1 The Basics of RCS‚Äôs\nI‚Äôd like to make an important first point in that RCS‚Äôs can be applied in any statistical model that linearly relates a predictor to an outcome. We have been emphasising continuous (predictor) vs continuous (outcome) associations because these are the simplest to conceptualise. But the same applies to any generalised linear or survival model.\n\n\n\n\n\n\nNote\n\n\n\nGeneralised linear models use link functions to linearise a predictor on the link scale and it is that scale that we are interested in knowing whether the predictor has an approximately linear relationship with the outcome to ensure model assumptions are met. E.g. for binary outcomes we want to know if the association of the continuous predictor and the logit (log-odds) of the outcome is linear or not. We don‚Äôt so much care about the association of the continuous predictor with the odds or the probability of the outcome because we know these to be non-linear. I will hopefully elaborate on this idea in a future post.\n\n\nThe intuition behind RCS‚Äôs is that the continuous predictor is broken into multiple intervals at locations called knots and for each interval the association between the predictor and the outcome is estimated separately. The association within each interval can be estimated with increasing complexity - from the linear splines that we have already explored in segmented regression, to cubic splines (polynomials) as we describe them here. I won‚Äôt go into detail of the underlying maths because it does get complicated, but a series of spline basis functions are used to ‚Äòbuild‚Äô the resulting cubic spline within each interval (please see the papers below for more detail.) The cubic splines within each interval are restricted in a couple of ways: firstly, adjacent splines join smoothly at knot locations because their slopes are constrained to be equal at these boundaries, and secondly, the spline functions are constrained to be linear in the tails (i.e., before the Ô¨Årst and after the last knot)\n\n\n3.5.2 Fitting RCS‚Äôs to the Current Data\nThere are multiple packages in R that allow you to fit RCS‚Äôs to your data but my go to is the ns() function in the splines package. I would encourage you to look at the papers listed below if you want to explore alternatives. Using ns(), the way to specify a RCS term on the relevant predictor in your model is really quite simple. The main argument that you need to specify is the degrees of freedom (df) which is equivalent to the number of different intervals that you want to model in your predictor-outcome relationship. This also corresponds to the number of RCS coefficients in your model output. However, as alluded to above, this DOES NOT represent the number of internal knots that the model uses under the hood to achieve this - which is always one less. So the take home here is that if you want to model 4 intervals of your predictor for which you feel the association differs with your outcome, you specify df = 4 which signals to ns() that it needs to define 3 internal knots.\nNow the placement of the knots can also be specified, but to be honest I‚Äôve never felt the need to do this. For the most part things seem to work fine with ns() default placement of knots at quantiles of the distribution of the predictor. For example, if you specified df = 4, then 3 internal knots would be placed at the 25th, 50th and 75th percentiles of the distribution of X.\nSo the basic form of a linear model with an ns() term included is then:\nlm(y ~ ns(x, df = 4), data = dat)\nand if you wish to check at what actual values of your predictor ns() has placed the knots, you can use:\nattr(ns(x, df = 4), \"knots\")\nFor an interesting comparison, we are now going to fit 4 models with RCS‚Äôs:\n\n2 knots (df = 3)\n3 knots (df = 4)\n4 knots (df = 5)\n20 knots (df = 21)\n\nThe resultant model predictions are shown below.\n\n\nCode\n# Model - rcs with 2 knots\nmod4a &lt;- lm(y ~ ns(x, df = 3), data = dat)\n# Model - rcs with 3 knots\nmod4b &lt;- lm(y ~ ns(x, 4), data = dat)\n# Model - rcs with 4 knots\nmod4c &lt;- lm(y ~ ns(x, 5), data = dat)\n# Model - rcs with 20 knots\nmod4d &lt;- lm(y ~ ns(x, 21), data = dat)\n# Predict Y from models\ndat$mod4a_pred &lt;- predict(mod4a, dat)\ndat$mod4b_pred &lt;- predict(mod4b, dat)\ndat$mod4c_pred &lt;- predict(mod4c, dat)\ndat$mod4d_pred &lt;- predict(mod4d, dat)\n# Convert to long format for easier plotting\ndat_long &lt;- dat |&gt; \n  select(1:2, 7:10) |&gt; \n  pivot_longer(3:6)\n# Plot rcs \nggplot() +\n  geom_line(data = dat_long, aes(x = x, y = value, color = name), linewidth = 2) + \n  geom_point(data = dat, aes(x = x, y = y), size = 3) +\n  scale_color_paletteer_d(\"ggsci::category20_d3\", name = \"RCS - # of knots\", labels = c(\"2\", \"3\", \"4\", \"20\")) +\n  xlab(\"x\") + ylab(\"y\") + \n  theme_bw(base_size = 20) +\n  theme(legend.position = c(1,1), legend.justification = c(2.8,1.1))\n\n\n\n\n\n\n\n\n\nWhat can we gather from this. Well there is no doubt some subjectivity to the interpretation of these plots, but my take is that the RCS with 2 internal knots is actually very similar to the quadratic (polynomial) model - these are both quite ‚Äòsmoothed‚Äô. We then start to see a little more flexibility in the model fit for the models with 3 and 4 internal knots - and really I‚Äôd be hard-pushed to say they‚Äôre that different. We can unequivocally say, though, that the model with 20 internal knots looks like it‚Äôs picking up a lot of noise in the data - this is a classic case of model over-fitting and we want to avoid this as much as possible. The main issue with overfit models is that they appear to work very well with the data that they were fit to - the predictions are excellent! But the catch is that the model has been fit to the idiosyncrasies of that specific dataset and consequently doesn‚Äôt generalise well to any other dataset that you might want to test your model on - for these new data the predictions are now terrible! We should always keep this in mind when we are formulating models to fit to our data, irrespective of whether we are using RCS‚Äôs or not.\nWhen we are using RCS‚Äôs though, for most applications, three to five internal knots strike a nice balance between complicating the model needlessly and fitting data pleasingly. For these data, it would not be unreasonable to suggest that the models with 3 or 4 internal knots capture the fit nicely (one could argue that the 2-knot model is a little underfit, and of course the 20 knot model is grossly overfit). So, from purely eyeballing the plots, I would tend to settle on the 3-knot model.\n\n\n3.5.3 Model Comparisons\nWe can add some statistical rigour to this intuition by calculating model-fit statistics, and I have done this using the AIC for all the models we have considered in this post. When we use the AIC to help decide on model fit we are looking for (relatively) lower (i.e.¬†more negative numbers). When we calculate these we can see some interesting results. The model assuming linearity is comparatively a terrible fit (AIC = 227). The piecewise model isn‚Äôt too bad though (AIC = -23) if we are looking to the RCS models as a gold standard. The quadratic model has a comparatively poorer fit (AIC = 31) and this is actually fairly similar to the 2-knot RCS model (AIC = 11 - remember we said they looked similar). The 3-knot and greater RCS models seem to perform the best, but this is really a case of diminishing returns. We can fairly justify either a 3- (AIC = -34) or 4-knot (AIC = -38) model and I don‚Äôt think any reasonable reviewer would criticise you for either choice.\n\n\nCode\n# AIC for each model\nmods_aic &lt;- data.frame(AIC(mod1, mod2, mod3, mod4a, mod4b, mod4c, mod4d))\nmods_aic &lt;- tibble::rownames_to_column(mods_aic, var = \"Model\")\nmods_aic &lt;- mods_aic |&gt; \n  select(-df) |&gt; \n  mutate(Model = case_when(Model == \"mod1\" ~ \"Linear Regression\",\n                           Model == \"mod2\" ~ \"Segmented Regression\",\n                           Model == \"mod3\" ~ \"Polynomial Regression\",\n                           Model == \"mod4a\" ~ \"RCS - 2 knots\",\n                           Model == \"mod4b\" ~ \"RCS - 3 knots\",\n                           Model == \"mod4c\" ~ \"RCS - 4 knots\",\n                           Model == \"mod4d\" ~ \"RCS - 20 knots\"))\nmods_aic\n\n\n\n\n\n\nModel\nAIC\n\n\n\n\nLinear Regression\n226.55549\n\n\nSegmented Regression\n-22.98867\n\n\nPolynomial Regression\n30.77121\n\n\nRCS - 2 knots\n10.55193\n\n\nRCS - 3 knots\n-33.66342\n\n\nRCS - 4 knots\n-38.49374\n\n\nRCS - 20 knots\n-34.52662\n\n\n\n\n\n\n\n\n3.5.4 Interpretation and Presentation of your Results\nOk, so we‚Äôre nearly done. You‚Äôve done the hard work of recognising your predictor has a non-linear relationship with your outcome, assessed multiple approaches to modelling that non-linearity and settled on a RCS with 3 knots on the predictor as the best-fitting model. You excitedly run your model and get the following output:\n\n\nCode\n# Model - rcs with 3 knots\nmod4b &lt;- lm(y ~ ns(x, 4), data = dat)\n# Format model results in a table\nmod4b |&gt; gtsummary::tbl_regression()\n\n\n\n\n\n\nModel Output\n\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI1\np-value\n\n\n\n\nns(x, 4)\n\n\n\n\n\n\n\n\n¬†¬†¬†¬†ns(x, 4)1\n-2.8\n-3.0, -2.6\n&lt;0.001\n\n\n¬†¬†¬†¬†ns(x, 4)2\n-0.69\n-0.89, -0.50\n&lt;0.001\n\n\n¬†¬†¬†¬†ns(x, 4)3\n-1.2\n-1.6, -0.82\n&lt;0.001\n\n\n¬†¬†¬†¬†ns(x, 4)4\n0.53\n0.34, 0.71\n&lt;0.001\n\n\n\n1 CI = Confidence Interval\n\n\n\n\n\n\n\n\nWTH?! What does that all mean? Paul, what are you doing to me? I just want the simple output that I‚Äôm used to where I can say that a one-unit change in my predictor corresponds to some change in my outcome!\nI apologise for my facetiousness - no doubt you have cottoned on to the fact that you when you specifically model a non-linear association between two variables, there is no longer any constancy in the relationship between the two variables. A one-unit change in X will give a different change in Y depending on the values of X.\nSo, what to do? First recognise that the RCS coefficients presented to you in a regression output are essentially useless from an interpretation point of view. You can‚Äôt easily use these to describe the association between X and Y in reporting your results.\nThe general approach to interpretation and reporting of results in the presence of non-linearity in a regression model is to pick salient values (biological, clinical) of X to predict model-estimated values of Y. You can quite easily calculate model-estimated means and differences using our friend emmeans which I described to you in an earlier post.\nFor illustrative purposes, let‚Äôs say we‚Äôre interested in knowing the model-estimated values of Y corresponding to X values of 20, 30, 50 and 60. We can estimate these values and differences (contrasts) of interest using emmeans.\n\n\nCode\n# Plot rcs \nggplot() +\n  geom_line(data = dat, aes(x = x, y = mod4b_pred), color = \"#EE8635\", linewidth = 2) + \n  geom_point(data = dat, aes(x = x, y = y), size = 3) +\n  geom_vline(xintercept = c(20,30,50,60), color = \"red\", linetype = \"dotted\", linewidth = 1) +\n  scale_x_continuous(limits = c(0, 100), breaks = c(20, 30, 50, 60)) +\n  xlab(\"x\") + ylab(\"y\") + \n  theme_bw(base_size = 20)\n\n\n\n\n\n\n\n\n\nCode\n# emmeans\nemmeans(mod4b, ~ x, at = list(x = c(20,30,50,60))) |&gt; \n  data.frame() |&gt; \n  select(-df) |&gt; \n  rename(\"X\" = \"x\",\n         \"Emmean (Y)\" = \"emmean\",\n         \"95% C.I. (lower)\" = \"lower.CL\",\n         \"95% C.I. (upper)\" = \"upper.CL\") |&gt; \n  flextable() |&gt; \n  colformat_double(j = c(2:5), digits = 3, na_str = \"N/A\") |&gt;\n  set_table_properties(layout = \"autofit\") |&gt; \n  height(height = 1, unit = \"cm\") |&gt; \n  hrule(rule = \"atleast\", part = \"header\") |&gt; \n  align(align = \"center\", part = \"body\") |&gt;\n  bg(bg = \"white\", part = \"all\") |&gt; \n  flextable::font(fontname = \"Consolas\", part = \"all\") |&gt;\n  theme_vanilla()\n\n\nEstimated Marginal MeansXEmmean (Y)SE95% C.I. (lower)95% C.I. (upper)200.3050.0420.2220.38830-0.2480.040-0.328-0.16850-1.0120.043-1.098-0.92560-0.7650.036-0.837-0.693\n\n\n\n\nCode\n# contrasts\nemm &lt;- emmeans(mod4b, ~ x, at = list(x = c(20,30,50,60)))\ncustom &lt;- list(`Change in Y corresponding to change in X from 20 to 30` = c(-1,1,0,0),\n               `Change in Y corresponding to change in X from 50 to 60` = c(0,0,-1,1))\ncontrast(emm, custom) |&gt; \n  summary(infer = T) |&gt; \n  data.frame() |&gt; \n  select(c(-df, -t.ratio)) |&gt; \n  rename(\"Contrast\" = \"contrast\",\n         \"Estimate\" = \"estimate\",\n         \"95% C.I. (lower)\" = \"lower.CL\",\n         \"95% C.I. (upper)\" = \"upper.CL\",\n         \"p\" = \"p.value\") |&gt; \n  flextable() |&gt; \n  colformat_double(digits = 3, na_str = \"N/A\") |&gt;\n  set_table_properties(layout = \"autofit\") |&gt; \n  height(height = 1, unit = \"cm\") |&gt; \n  hrule(rule = \"atleast\", part = \"header\") |&gt; \n  align(align = \"center\", part = \"body\") |&gt;\n  bg(bg = \"white\", part = \"all\") |&gt; \n  flextable::font(fontname = \"Consolas\", part = \"all\") |&gt;\n  theme_vanilla()\n\n\nContrasts of Estimated Marginal MeansContrastEstimateSE95% C.I. (lower)95% C.I. (upper)pChange in Y corresponding to change in X from 20 to 30-0.5530.019-0.592-0.5150.000Change in Y corresponding to change in X from 50 to 600.2470.0260.1960.2970.000\n\n\nThat‚Äôs probably enough on RCS‚Äôs for now - this post has turned out longer than I initially anticipated. I hope you have found it helpful and above all, found some motivation to using RCS‚Äôs in your modelling endeavours if you are not already.\n\n\n3.5.5 Extra Reading\nIf you want to dive a little deeper into RCS‚Äôs than we‚Äôve done here, I can thoroughly recommend the following 3 papers:\nModeling non-linear relationships in epidemiological data: The application and interpretation of spline models\nCubic splines to model relationships between continuous variables and outcomes: a guide for clinicians\nA review of spline function procedures in R"
  },
  {
    "objectID": "posts/010_19Apr_2024/index.html",
    "href": "posts/010_19Apr_2024/index.html",
    "title": "Everything is a Linear Model",
    "section": "",
    "text": "I want to share with you a secret - maybe you already know it. It took me a while into my statistical learnings to realise this and since then I‚Äôve seen people write about it (see here and here for examples). But the basic idea is that many of the common statistical tests that we use (e.g.¬†t-test, ANOVA, etc) are really nothing more than variations on the general linear model that we‚Äôre all accustomed to:\n\\[ y = ax + b \\]\nThe former are specific-use tests, whereas the latter is an ‚Äòumbrella‚Äô model that can be broadly adapted to accomplish each of the same tasks - perhaps there‚Äôs something to be said for learning just one set of syntax. Let me illustrate this to you with one example using the two-sample t-test. We‚Äôll use the genderweight dataset from the datarium package in R which consists of the bodyweights of 40 subjects (20 males, 20 females). We‚Äôre interested in working out whether there is a gender difference. A look at the data shows:\n\n\nCode\nlibrary(ggplot2)\ndata(\"genderweight\", package = \"datarium\")\nhead(genderweight, 10)\n\n\n\n\n\n\nid\ngroup\nweight\n\n\n\n\n1\nF\n61.58587\n\n\n2\nF\n64.55486\n\n\n3\nF\n66.16888\n\n\n4\nF\n59.30860\n\n\n5\nF\n64.85825\n\n\n6\nF\n65.01211\n\n\n7\nF\n62.85052\n\n\n8\nF\n62.90674\n\n\n9\nF\n62.87110\n\n\n10\nF\n62.21992\n\n\n\n\n\n\n\n1 Plot the Data\nIt‚Äôs always helpful to first plot the data:\n\n\nCode\nggplot(genderweight, aes(x = group, y = weight)) +\n  geom_jitter(size = 3, width = 0.05) +\n  scale_y_continuous(limits = c(50, 100), breaks = seq(50, 100, by = 10)) +\n  stat_summary(fun = mean, \n               geom = \"errorbar\", \n               aes(ymax = after_stat(y), ymin = after_stat(y)), \n               width = 0.25) +\n  theme_bw(base_size = 20)\n\n\n\n\n\n\n\n\n\n\n\n2 Two-Sample t-Test\nNow, we can run our standard t-test as follows (by default, computing the Welch version of the test which does not assume the same variances in each group). In words, we are asking to test the difference in weight by group (i.e.¬†males vs females).\nt.test(weight ~ group, data = genderweight)\n\n\nCode\nt.test(weight ~ group, data = genderweight)\n\n\n\n    Welch Two Sample t-test\n\ndata:  weight by group\nt = -20.791, df = 26.872, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group F and group M is not equal to 0\n95 percent confidence interval:\n -24.53135 -20.12353\nsample estimates:\nmean in group F mean in group M \n       63.49867        85.82612 \n\n\nThis output tells us that the mean weight in females and males is 63.5 kg and 85.8 kg, respectively. Furthermore, the 95% C.I. for the difference (note that is does not give us the actual difference) in those two weights is -24.5, -20.1 and as the interval does not contain 0 this is statistically significant (as also reflected in the p-value).\n\n\n3 Linear Model\nNow, the equivalent linear model (i.e.¬†linear regression) in R is simply:\nsummary(lm(weight ~ group, data = genderweight))\n\n\nCode\nsummary(lm(weight ~ group, data = genderweight))\n\n\n\nCall:\nlm(formula = weight ~ group, data = genderweight)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.8163 -1.3647 -0.4869  1.3980  9.2365 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  63.4987     0.7593   83.62   &lt;2e-16 ***\ngroupM       22.3274     1.0739   20.79   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.396 on 38 degrees of freedom\nMultiple R-squared:  0.9192,    Adjusted R-squared:  0.9171 \nF-statistic: 432.3 on 1 and 38 DF,  p-value: &lt; 2.2e-16\n\n\nThe output is slightly different but the information contained is almost the same. (Intercept) represents the mean weight in the reference category of the group variable (in this case females). groupM represents the difference in means between females and males (22.3 kg). Note that the 95% C.I.‚Äôs aren‚Äôt presented as part of this standard output, but we can obtain that information easily enough with:\nconfint(lm(weight ~ group, data = genderweight))\n\n\nCode\nconfint(lm(weight ~ group, data = genderweight))\n\n\n               2.5 %   97.5 %\n(Intercept) 61.96145 65.03589\ngroupM      20.15349 24.50140\n\n\nNote the slight difference in the 95% C.I.‚Äôs to that obtained from the t-test. The general linear model, by assumption, assumes homogeneity of variances among the two groups.\nFinally, if you would prefer to know the actual mean values of each group as well, it‚Äôs possible to amend the lm call slightly by removing the intercept term. This gives:\nsummary(lm(weight ~ group - 1, data = genderweight))\n\n\nCode\nsummary(lm(weight ~ group - 1, data = genderweight))\n\n\n\nCall:\nlm(formula = weight ~ group - 1, data = genderweight)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.8163 -1.3647 -0.4869  1.3980  9.2365 \n\nCoefficients:\n       Estimate Std. Error t value Pr(&gt;|t|)    \ngroupF  63.4987     0.7593   83.62   &lt;2e-16 ***\ngroupM  85.8261     0.7593  113.03   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.396 on 38 degrees of freedom\nMultiple R-squared:  0.9981,    Adjusted R-squared:  0.998 \nF-statistic:  9884 on 2 and 38 DF,  p-value: &lt; 2.2e-16\n\n\nThe two-sample t-test is just one example of a special case of the general linear model. The first link I provided above contains a neat pdf describing many other special cases and I would encourage you to have a look at these. While you might still use these specific tests in your day to day work, it is nonetheless helpful to broaden your statistical knowledge in the realisation that the general linear model is fundamental to all of these."
  },
  {
    "objectID": "posts/013_31May_2024/index.html",
    "href": "posts/013_31May_2024/index.html",
    "title": "Logistic regression under the hood",
    "section": "",
    "text": "Code\n# Recreate data from Ophthalmic statistics note 11: logistic regression.\n# Original source: A comparison of several methods of macular hole measurement using optical coherence tomography, and their value in predicting anatomical and visual outcomes.\n\nlibrary(tidyverse)\nlibrary(ggpubr)\nlibrary(ggmagnify)\nlibrary(emmeans)\n\n# Simulate data ----\nn &lt;- 1000                    # don't change this unless necessary (plots might be fragile)\nset.seed(1234)\nx  &lt;-  rnorm(n, 486, 142)    # generate macular hole inner opening data with mean 486 and sd = 152\nz  &lt;-  10.89 - 0.016 * x     # generate variable that is linear combination of intercept = 10.89 and coefficient for macular hole -0.016 (logit scale)\npr  &lt;-  1/(1 + exp(-z))      # generate probabilities from this\ny  &lt;-  rbinom(n, 1, pr)      # generate outcome variable as a function of those probabilities\n\n# Create dataframe from these:\ndf &lt;-  data.frame(y = y, x = x, z = z, pr = pr)\ndf &lt;- df |&gt; \n  filter(x &gt; 100) # only include those with thickness &gt; 100\n\n# Logistic regression model ----\n# Rescale x to 1 unit = 100 microns instead of 1 micron\nsummary(mod_logistic &lt;- glm(y ~ I(x/100), data = df, family = \"binomial\"))\n\n\n\nCall:\nglm(formula = y ~ I(x/100), family = \"binomial\", data = df)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  10.3501     0.7456   13.88   &lt;2e-16 ***\nI(x/100)     -1.5045     0.1212  -12.42   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 773.74  on 989  degrees of freedom\nResidual deviance: 494.67  on 988  degrees of freedom\nAIC: 498.67\n\nNumber of Fisher Scoring iterations: 6\n\n\nCode\n# Emmeans of logodds at 600 and 700 microns\nemmeans_df &lt;- data.frame(emmeans(mod_logistic, ~ x, at = list(x = c(600, 700))))\n# Create df of emmeans and corresponding odds and probs, for plotting\nemmeans_df &lt;- emmeans_df |&gt; \n  select(x, emmean) |&gt; \n  rename(logodds = emmean) |&gt; \n  mutate(odds = round(exp(logodds), 3),\n         probs = round(plogis(logodds), 2),\n         logodds = round(logodds, 3))\n\n# Predictions ----\n# Create new df to predict on new values of x\nnew_dat &lt;- data.frame(x = seq(from = 0, to = 1200, length.out = 100))\n# Predict new fitted values and SE's on logodds scale\npred_logodds &lt;- predict(mod_logistic, newdata = new_dat, type = \"link\", se = TRUE)\nnew_dat &lt;- cbind(new_dat, pred_logodds)\n# Create new df of predictions\npredictions &lt;- new_dat |&gt; \n  rename(pred_logodds_est = fit) |&gt; \n  mutate(pred_logodds_LL = pred_logodds_est - (1.96 * se.fit),\n         pred_logodds_UL = pred_logodds_est + (1.96 * se.fit)) |&gt; \n  select(-c(se.fit, residual.scale))\n# Predict new fitted values and SE's on odds scale\npredictions &lt;- predictions |&gt; \n  mutate(pred_odds_est = exp(pred_logodds_est),\n         pred_odds_LL = exp(pred_logodds_LL),\n         pred_odds_UL = exp(pred_logodds_UL))\n# Predict new fitted values and SE's on probability scale\npred_probs &lt;- predict(mod_logistic, newdata = new_dat, type = \"response\", se = TRUE)\nnew_dat &lt;- cbind(new_dat[1], pred_probs)\nnew_dat &lt;- new_dat |&gt; \n  mutate(pred_probs_LL = fit - (1.96 * se.fit),\n         pred_probs_UL = fit + (1.96 * se.fit))\n# Add predicted probs and CIs to predictions df\npredictions &lt;- cbind(predictions, \n                     pred_probs_est = new_dat$fit, \n                     pred_probs_LL = new_dat$pred_probs_LL,\n                     pred_probs_UL = new_dat$pred_probs_UL)\n\n# Reformat plots slightly for ggarrange ----\np3a &lt;- ggplot(predictions, aes(x = x, y = pred_logodds_est)) + \n  geom_ribbon(aes(ymin = pred_logodds_LL, ymax = pred_logodds_UL), alpha = 0.2) + \n  geom_line(color = \"cornflowerblue\", linewidth = 1) +\n  geom_point(data = df, aes(x = x, y = y), size = 2, alpha = 0.1) +\n  annotate(\"text\", x = 1150, y = 6, label = \"log-odds\", size = 10) +\n  scale_x_continuous(limits = c(0, 1200), breaks = seq(0, 1200, by = 100)) +\n  scale_y_continuous(limits = c(-100, 100), breaks = seq(-100, 100, by = 2)) +\n  coord_cartesian(xlim = c(0, 1200), ylim = c(-8, 8)) +\n  geom_vline(xintercept = 600, color = \"red\", linetype = \"dotted\", linewidth = 0.6) +\n  geom_vline(xintercept = 700, color = \"red\", linetype = \"dotted\", linewidth = 0.6) +\n  ggrepel::geom_label_repel(data = emmeans_df, aes(x, logodds),\n                            label = emmeans_df$logodds, \n                            nudge_x = c(-50, 50), nudge_y = c(4, -4),\n                            color = \"red\", segment.size = 0.2, size = 5) +\n  theme_bw(base_size = 25) +\n  ylab(\"\") +\n  theme(axis.title.x = element_blank(), axis.text.x = element_blank())\n\np4a &lt;- ggplot(predictions, aes(x = x, y = pred_odds_est)) + \n  geom_ribbon(aes(ymin = pred_odds_LL, ymax = pred_odds_UL), alpha = 0.2) + \n  geom_line(color = \"cornflowerblue\", linewidth = 1) +\n  geom_point(data = df, aes(x = x, y = y), size = 2, alpha = 0.1) +\n  annotate(\"text\", x = 1150, y = 6000, label = \"odds\", size = 10) +\n  scale_x_continuous(limits = c(0, 1200), breaks = seq(0, 1200, by = 100)) +\n  scale_y_continuous(limits = c(-20, 1000000), breaks = c(seq(0, 1000000, by = 1000))) +\n  coord_cartesian(xlim = c(0, 1200), ylim = c(0, 7000)) +\n  geom_vline(xintercept = 600, color = \"red\", linetype = \"dotted\", linewidth = 0.6) +\n  geom_vline(xintercept = 700, color = \"red\", linetype = \"dotted\", linewidth = 0.6) +\n  ylab(\"\") +\n  theme_bw(base_size = 25) +\n  theme(axis.title.x = element_blank(), axis.text.x = element_blank())\np4a_inset &lt;- p4a +\n  scale_y_continuous(limits = c(-20, 1000000), breaks = c(1,2,3,4,5, seq(0, 1000000, by = 1000))) +\n  geom_vline(xintercept = 600, color = \"red\", linetype = \"dotted\", linewidth = 0.6) +\n  geom_vline(xintercept = 700, color = \"red\", linetype = \"dotted\", linewidth = 0.6) +\n  ggrepel::geom_label_repel(data = emmeans_df, aes(x, odds),\n                            label = emmeans_df$odds, \n                            nudge_x = c(-50, 50), nudge_y = c(-1, 2),\n                            color = \"red\", segment.size = 0.2, size = 5)\np4a &lt;- p4a + geom_magnify(from = c(xmin = 500, xmax = 1000, ymin = 0, ymax = 5), \n                          to = c(xmin = 465, xmax = 1010, ymin = 1000, ymax = 5000), \n                          shadow = T, axes = \"y\", plot = p4a_inset)\n\np5a &lt;- ggplot(predictions, aes(x = x, y = pred_probs_est)) + \n  geom_ribbon(aes(ymin = pred_probs_LL, ymax = pred_probs_UL), alpha = 0.2) + \n  geom_line(color = \"cornflowerblue\", linewidth = 1) +\n  geom_point(data = df, aes(x = x, y = y), size = 2, alpha = 0.1) +\n  annotate(\"text\", x = 1150, y = 0.8, label = \"probability\", size = 10) +\n  scale_x_continuous(limits = c(0, 1200), breaks = seq(0, 1200, by = 100)) +\n  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.2)) +\n  geom_vline(xintercept = 600, color = \"red\", linetype = \"dotted\", linewidth = 0.6) +\n  geom_vline(xintercept = 700, color = \"red\", linetype = \"dotted\", linewidth = 0.6) +\n  ggrepel::geom_label_repel(data = emmeans_df, aes(x, probs),\n                            label = emmeans_df$probs, \n                            nudge_x = c(-50, 50), nudge_y = c(-0.1, 0.1),\n                            color = \"red\", segment.size = 0.2, size = 5) +\n  ylab(\"\") + xlab(\"Macular hole thickness\") +\n  theme_bw(base_size = 25)\nggarrange(p3a, p4a, p5a, align = \"v\", ncol = 1, heights = c(1,1,1.2))"
  },
  {
    "objectID": "posts/011_03May_2024/index.html",
    "href": "posts/011_03May_2024/index.html",
    "title": "gtsummary - Your New Go-To for Tables",
    "section": "",
    "text": "I thought I should bring this excellent package to your attention if you weren‚Äôt aware that it exists, as I have taken gtsummary somewhat for granted over the last few years since it first appeared on CRAN. I‚Äôm prompted in part due to a research student having to recently remake several ‚ÄúTable 1‚Äù - style tables (following a data change) in manuscript preparation for submission and they were going to redo this manually. When they realised what gtsummary could do in terms of saving them time, I think they were fairly impressed. So today, I‚Äôm just going to show you a couple of basic functionalities of this package. It is extremely extensible and if you can‚Äôt find answers for your own customisation needs on the homepage or vignette, I have found googling the issue often brings an answer. The developer is also quite active on stackoverflow.com. The homepage can be found at:\nhttps://www.danieldsjoberg.com/gtsummary/index.html\nWe going to use a publicly available MS dataset, so if you want to run the code yourself you will first need to download the data from:\nBrain MRI dataset of multiple sclerosis with consensus manual lesion segmentation and patient meta information\nThis dataset contains the demographic and clinical data on 60 patients (MRI data in accompanying datasets available at link).\n\n1 Load and Inspect the Data\nLet‚Äôs have a look at the first few lines:\n\n\nCode\nhead(dat, 10)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nID\nGender\nAge\nAge.of.onset\nEDSS\nDoes.the.time.difference.between.MRI.acquisition.and.EDSS‚Ä¶two.months\nTypes.of.Medicines\nPresenting.Symptom\nDose.the.patient.has.Co.moroidity\nPyramidal\nCerebella\nBrain.stem\nSensory\nSphincters\nVisual\nMental\nSpeech\nMotor.System\nSensory.System\nCoordination\nGait\nBowel.and.bladder.function\nMobility\nMental.State\nOptic.discs\nFields\nNystagmus\nOcular.Movement\nSwallowing\n\n\n\n\n1\nF\n56\n43\n3.0\nNo\nGelenia\nMotor\nNo\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n\n\n2\nF\n29\n19\n1.5\nNo\nGelenia\nSensory\nNo\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n\n\n3\nF\n15\n8\n4.0\nNo\nTysabri\nMotor\nNo\n1\n1\n0\n0\n0\n1\n0\n0\n1\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n\n\n4\nF\n24\n20\n6.0\nNo\nTysabri\nSensory\nNo\n1\n1\n1\n0\n1\n0\n0\n0\n1\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n5\nF\n33\n31\n0.0\nNo\nAvonex\nPain\nNo\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n6\nF\n44\n40\n5.0\nNo\nAvonex\nMotor\nNo\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n1\n1\n1\n0\n0\n0\n0\n1\n0\n0\n\n\n7\nM\n43\n40\n3.5\nNo\nBetaferon\nMotor & Visual\nNo\n0\n1\n0\n0\n0\n0\n1\n0\n1\n1\n1\n0\n0\n1\n0\n1\n0\n0\n0\n0\n\n\n8\nF\n32\n30\n1.0\nNo\nGelenia\nVisual\nNo\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n9\nF\n36\n33\n6.0\nNo\nGelenia\nMotore\nNo\n1\n0\n0\n0\n0\n0\n0\n0\n1\n0\n1\n1\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n10\nF\n39\n35\n3.0\nNo\nBetaferon\nMotor & Behavioural\nNo\n1\n0\n0\n0\n0\n1\n0\n0\n1\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n\n\n\n\n\n\n\n\n2 Summary Table\nLet‚Äôs say you want to create a summary table showing descriptive statistics of the various demographic and clinical characteristics, stratified by DMT (Types.of.Medicines). In the first instance, this can be a basic call of tbl_summary() specifying Types.of.Medicines as the stratifying variable. We want to specify medians (IQR) and n‚Äôs (%‚Äôs) as the summary statistics.\n\n\nCode\nlibrary(gtsummary)\ndat |&gt; \n  select(-ID) |&gt; \n  tbl_summary(\n    by = Types.of.Medicines,\n    statistic = list(all_continuous() ~ \"{median} ({p25},{p75})\",\n                     all_categorical() ~ \"{n}/{N} ({p}%)\"),\n    digits = all_continuous() ~ 1) |&gt; \n  add_overall()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nOverall, N = 601\nAvonex, N = 51\nBetaferon, N = 241\nGelenia, N = 91\nRebif, N = 141\nTysabri, N = 81\n\n\n\n\nGender\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†¬†¬†¬†F\n46/60 (77%)\n5/5 (100%)\n15/24 (63%)\n9/9 (100%)\n10/14 (71%)\n7/8 (88%)\n\n\n¬†¬†¬†¬†M\n13/60 (22%)\n0/5 (0%)\n8/24 (33%)\n0/9 (0%)\n4/14 (29%)\n1/8 (13%)\n\n\n¬†¬†¬†¬†N\n1/60 (1.7%)\n0/5 (0%)\n1/24 (4.2%)\n0/9 (0%)\n0/14 (0%)\n0/8 (0%)\n\n\nAge\n33.0 (20.0,42.3)\n24.0 (23.0,33.0)\n37.5 (23.8,43.0)\n42.0 (36.0,52.0)\n32.5 (18.5,38.0)\n20.5 (15.0,24.3)\n\n\nAge.of.onset\n30.5 (19.8,40.0)\n20.0 (20.0,31.0)\n35.0 (23.0,41.0)\n40.0 (30.0,42.0)\n31.0 (18.5,37.0)\n17.0 (16.3,21.3)\n\n\nEDSS\n2.0 (1.0,3.5)\n1.5 (1.0,4.0)\n2.3 (1.0,3.1)\n3.0 (1.5,3.0)\n1.3 (1.0,2.4)\n3.0 (1.4,4.3)\n\n\nDoes.the.time.difference.between.MRI.acquisition.and.EDSS...two.months\n26/60 (43%)\n0/5 (0%)\n10/24 (42%)\n3/9 (33%)\n11/14 (79%)\n2/8 (25%)\n\n\nPresenting.Symptom\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†¬†¬†¬†Balance\n4/60 (6.7%)\n0/5 (0%)\n2/24 (8.3%)\n0/9 (0%)\n2/14 (14%)\n0/8 (0%)\n\n\n¬†¬†¬†¬†Balance &Motor\n1/60 (1.7%)\n0/5 (0%)\n0/24 (0%)\n0/9 (0%)\n0/14 (0%)\n1/8 (13%)\n\n\n¬†¬†¬†¬†Motor\n10/60 (17%)\n1/5 (20%)\n3/24 (13%)\n1/9 (11%)\n3/14 (21%)\n2/8 (25%)\n\n\n¬†¬†¬†¬†Motor & Behavioural\n1/60 (1.7%)\n0/5 (0%)\n1/24 (4.2%)\n0/9 (0%)\n0/14 (0%)\n0/8 (0%)\n\n\n¬†¬†¬†¬†Motor & Sensory\n1/60 (1.7%)\n0/5 (0%)\n1/24 (4.2%)\n0/9 (0%)\n0/14 (0%)\n0/8 (0%)\n\n\n¬†¬†¬†¬†Motor & Visual\n2/60 (3.3%)\n0/5 (0%)\n2/24 (8.3%)\n0/9 (0%)\n0/14 (0%)\n0/8 (0%)\n\n\n¬†¬†¬†¬†Motore\n1/60 (1.7%)\n0/5 (0%)\n0/24 (0%)\n1/9 (11%)\n0/14 (0%)\n0/8 (0%)\n\n\n¬†¬†¬†¬†Pain\n1/60 (1.7%)\n1/5 (20%)\n0/24 (0%)\n0/9 (0%)\n0/14 (0%)\n0/8 (0%)\n\n\n¬†¬†¬†¬†Sensory\n19/60 (32%)\n0/5 (0%)\n8/24 (33%)\n3/9 (33%)\n7/14 (50%)\n1/8 (13%)\n\n\n¬†¬†¬†¬†Sensory & Visual\n1/60 (1.7%)\n0/5 (0%)\n1/24 (4.2%)\n0/9 (0%)\n0/14 (0%)\n0/8 (0%)\n\n\n¬†¬†¬†¬†Sensory & Motor\n1/60 (1.7%)\n0/5 (0%)\n1/24 (4.2%)\n0/9 (0%)\n0/14 (0%)\n0/8 (0%)\n\n\n¬†¬†¬†¬†Sensory & Visual\n1/60 (1.7%)\n0/5 (0%)\n0/24 (0%)\n1/9 (11%)\n0/14 (0%)\n0/8 (0%)\n\n\n¬†¬†¬†¬†Sensory & Visual ,Balance , Motor, Sexual,Fatigue\n1/60 (1.7%)\n0/5 (0%)\n1/24 (4.2%)\n0/9 (0%)\n0/14 (0%)\n0/8 (0%)\n\n\n¬†¬†¬†¬†Sensory &Motor\n1/60 (1.7%)\n0/5 (0%)\n0/24 (0%)\n0/9 (0%)\n0/14 (0%)\n1/8 (13%)\n\n\n¬†¬†¬†¬†Visual\n14/60 (23%)\n3/5 (60%)\n4/24 (17%)\n2/9 (22%)\n2/14 (14%)\n3/8 (38%)\n\n\n¬†¬†¬†¬†Visual & Balance\n1/60 (1.7%)\n0/5 (0%)\n0/24 (0%)\n1/9 (11%)\n0/14 (0%)\n0/8 (0%)\n\n\nDose.the.patient.has.Co.moroidity\n13/60 (22%)\n0/5 (0%)\n8/24 (33%)\n3/9 (33%)\n2/14 (14%)\n0/8 (0%)\n\n\nPyramidal\n31/60 (52%)\n2/5 (40%)\n14/24 (58%)\n5/9 (56%)\n4/14 (29%)\n6/8 (75%)\n\n\nCerebella\n17/60 (28%)\n1/5 (20%)\n8/24 (33%)\n2/9 (22%)\n3/14 (21%)\n3/8 (38%)\n\n\nBrain.stem\n5/60 (8.3%)\n1/5 (20%)\n1/24 (4.2%)\n0/9 (0%)\n1/14 (7.1%)\n2/8 (25%)\n\n\nSensory\n18/60 (30%)\n1/5 (20%)\n8/24 (33%)\n3/9 (33%)\n3/14 (21%)\n3/8 (38%)\n\n\nSphincters\n9/60 (15%)\n0/5 (0%)\n5/24 (21%)\n0/9 (0%)\n2/14 (14%)\n2/8 (25%)\n\n\nVisual\n17/60 (28%)\n3/5 (60%)\n6/24 (25%)\n2/9 (22%)\n2/14 (14%)\n4/8 (50%)\n\n\nMental\n2/60 (3.3%)\n0/5 (0%)\n2/24 (8.3%)\n0/9 (0%)\n0/14 (0%)\n0/8 (0%)\n\n\nSpeech\n6/60 (10%)\n0/5 (0%)\n4/24 (17%)\n0/9 (0%)\n1/14 (7.1%)\n1/8 (13%)\n\n\nMotor.System\n35/60 (58%)\n3/5 (60%)\n14/24 (58%)\n5/9 (56%)\n6/14 (43%)\n7/8 (88%)\n\n\nSensory.System\n19/60 (32%)\n0/5 (0%)\n8/24 (33%)\n4/9 (44%)\n4/14 (29%)\n3/8 (38%)\n\n\nCoordination\n17/60 (28%)\n2/5 (40%)\n6/24 (25%)\n2/9 (22%)\n2/14 (14%)\n5/8 (63%)\n\n\nGait\n17/60 (28%)\n2/5 (40%)\n7/24 (29%)\n1/9 (11%)\n4/14 (29%)\n3/8 (38%)\n\n\nBowel.and.bladder.function\n9/60 (15%)\n1/5 (20%)\n2/24 (8.3%)\n1/9 (11%)\n3/14 (21%)\n2/8 (25%)\n\n\nMobility\n4/60 (6.7%)\n0/5 (0%)\n2/24 (8.3%)\n1/9 (11%)\n1/14 (7.1%)\n0/8 (0%)\n\n\nMental.State\n3/60 (5.0%)\n0/5 (0%)\n2/24 (8.3%)\n0/9 (0%)\n1/14 (7.1%)\n0/8 (0%)\n\n\nOptic.discs\n22/60 (37%)\n2/5 (40%)\n8/24 (33%)\n3/9 (33%)\n4/14 (29%)\n5/8 (63%)\n\n\nFields\n0/60 (0%)\n0/5 (0%)\n0/24 (0%)\n0/9 (0%)\n0/14 (0%)\n0/8 (0%)\n\n\nNystagmus\n7/60 (12%)\n1/5 (20%)\n3/24 (13%)\n2/9 (22%)\n0/14 (0%)\n1/8 (13%)\n\n\nOcular.Movement\n2/60 (3.3%)\n0/5 (0%)\n0/24 (0%)\n1/9 (11%)\n0/14 (0%)\n1/8 (13%)\n\n\nSwallowing\n3/60 (5.0%)\n0/5 (0%)\n3/24 (13%)\n0/9 (0%)\n0/14 (0%)\n0/8 (0%)\n\n\n\n1 n/N (%); Median (25%,75%)\n\n\n\n\n\n\n\n\nIn fact, that‚Äôs a pretty good start. However, we think that including the column frequency as the denominator in every cell is just clutter, so let‚Äôs remove that. We‚Äôll also include an argument for reporting missingness if any exists. Additionally, we want to tidy up some of the variable names - I‚Äôll just do Age, Age.of.onset and the somewhat convoluted Does.the.time.difference.between.MRI.acquisition.and.EDSS...two.months for now. In fact, for the latter we‚Äôll make it a short name and include a footnote to expand on the variable description.\n\n\nCode\ndat |&gt; \n  select(-ID) |&gt; \n  tbl_summary(\n    by = Types.of.Medicines,\n    statistic = list(all_continuous() ~ \"{median} ({p25},{p75})\",\n                     all_categorical() ~ \"{n} ({p}%)\"),\n    digits = all_continuous() ~ 1,\n    missing_text = \"(Missing)\",\n    label = c(Age ~ \"Age, yrs - median (IQR)\",\n              Age.of.onset ~ \"Age onset, yrs - median (IQR)\",\n              Does.the.time.difference.between.MRI.acquisition.and.EDSS...two.months ~ \"Time difference &lt; 2 months\")) |&gt; \n    modify_table_styling(columns = label,\n                         rows = label == \"Time difference &lt; 2 months\",\n                         footnote = \"Does the time difference between MRI acquisition and EDSS &lt; two months\") |&gt; \n  add_overall()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nOverall, N = 601\nAvonex, N = 51\nBetaferon, N = 241\nGelenia, N = 91\nRebif, N = 141\nTysabri, N = 81\n\n\n\n\nGender\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†¬†¬†¬†F\n46 (77%)\n5 (100%)\n15 (63%)\n9 (100%)\n10 (71%)\n7 (88%)\n\n\n¬†¬†¬†¬†M\n13 (22%)\n0 (0%)\n8 (33%)\n0 (0%)\n4 (29%)\n1 (13%)\n\n\n¬†¬†¬†¬†N\n1 (1.7%)\n0 (0%)\n1 (4.2%)\n0 (0%)\n0 (0%)\n0 (0%)\n\n\nAge, yrs - median (IQR)\n33.0 (20.0,42.3)\n24.0 (23.0,33.0)\n37.5 (23.8,43.0)\n42.0 (36.0,52.0)\n32.5 (18.5,38.0)\n20.5 (15.0,24.3)\n\n\nAge onset, yrs - median (IQR)\n30.5 (19.8,40.0)\n20.0 (20.0,31.0)\n35.0 (23.0,41.0)\n40.0 (30.0,42.0)\n31.0 (18.5,37.0)\n17.0 (16.3,21.3)\n\n\nEDSS\n2.0 (1.0,3.5)\n1.5 (1.0,4.0)\n2.3 (1.0,3.1)\n3.0 (1.5,3.0)\n1.3 (1.0,2.4)\n3.0 (1.4,4.3)\n\n\nTime difference &lt; 2 months2\n26 (43%)\n0 (0%)\n10 (42%)\n3 (33%)\n11 (79%)\n2 (25%)\n\n\nPresenting.Symptom\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†¬†¬†¬†Balance\n4 (6.7%)\n0 (0%)\n2 (8.3%)\n0 (0%)\n2 (14%)\n0 (0%)\n\n\n¬†¬†¬†¬†Balance &Motor\n1 (1.7%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (13%)\n\n\n¬†¬†¬†¬†Motor\n10 (17%)\n1 (20%)\n3 (13%)\n1 (11%)\n3 (21%)\n2 (25%)\n\n\n¬†¬†¬†¬†Motor & Behavioural\n1 (1.7%)\n0 (0%)\n1 (4.2%)\n0 (0%)\n0 (0%)\n0 (0%)\n\n\n¬†¬†¬†¬†Motor & Sensory\n1 (1.7%)\n0 (0%)\n1 (4.2%)\n0 (0%)\n0 (0%)\n0 (0%)\n\n\n¬†¬†¬†¬†Motor & Visual\n2 (3.3%)\n0 (0%)\n2 (8.3%)\n0 (0%)\n0 (0%)\n0 (0%)\n\n\n¬†¬†¬†¬†Motore\n1 (1.7%)\n0 (0%)\n0 (0%)\n1 (11%)\n0 (0%)\n0 (0%)\n\n\n¬†¬†¬†¬†Pain\n1 (1.7%)\n1 (20%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n\n\n¬†¬†¬†¬†Sensory\n19 (32%)\n0 (0%)\n8 (33%)\n3 (33%)\n7 (50%)\n1 (13%)\n\n\n¬†¬†¬†¬†Sensory & Visual\n1 (1.7%)\n0 (0%)\n1 (4.2%)\n0 (0%)\n0 (0%)\n0 (0%)\n\n\n¬†¬†¬†¬†Sensory & Motor\n1 (1.7%)\n0 (0%)\n1 (4.2%)\n0 (0%)\n0 (0%)\n0 (0%)\n\n\n¬†¬†¬†¬†Sensory & Visual\n1 (1.7%)\n0 (0%)\n0 (0%)\n1 (11%)\n0 (0%)\n0 (0%)\n\n\n¬†¬†¬†¬†Sensory & Visual ,Balance , Motor, Sexual,Fatigue\n1 (1.7%)\n0 (0%)\n1 (4.2%)\n0 (0%)\n0 (0%)\n0 (0%)\n\n\n¬†¬†¬†¬†Sensory &Motor\n1 (1.7%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (13%)\n\n\n¬†¬†¬†¬†Visual\n14 (23%)\n3 (60%)\n4 (17%)\n2 (22%)\n2 (14%)\n3 (38%)\n\n\n¬†¬†¬†¬†Visual & Balance\n1 (1.7%)\n0 (0%)\n0 (0%)\n1 (11%)\n0 (0%)\n0 (0%)\n\n\nDose.the.patient.has.Co.moroidity\n13 (22%)\n0 (0%)\n8 (33%)\n3 (33%)\n2 (14%)\n0 (0%)\n\n\nPyramidal\n31 (52%)\n2 (40%)\n14 (58%)\n5 (56%)\n4 (29%)\n6 (75%)\n\n\nCerebella\n17 (28%)\n1 (20%)\n8 (33%)\n2 (22%)\n3 (21%)\n3 (38%)\n\n\nBrain.stem\n5 (8.3%)\n1 (20%)\n1 (4.2%)\n0 (0%)\n1 (7.1%)\n2 (25%)\n\n\nSensory\n18 (30%)\n1 (20%)\n8 (33%)\n3 (33%)\n3 (21%)\n3 (38%)\n\n\nSphincters\n9 (15%)\n0 (0%)\n5 (21%)\n0 (0%)\n2 (14%)\n2 (25%)\n\n\nVisual\n17 (28%)\n3 (60%)\n6 (25%)\n2 (22%)\n2 (14%)\n4 (50%)\n\n\nMental\n2 (3.3%)\n0 (0%)\n2 (8.3%)\n0 (0%)\n0 (0%)\n0 (0%)\n\n\nSpeech\n6 (10%)\n0 (0%)\n4 (17%)\n0 (0%)\n1 (7.1%)\n1 (13%)\n\n\nMotor.System\n35 (58%)\n3 (60%)\n14 (58%)\n5 (56%)\n6 (43%)\n7 (88%)\n\n\nSensory.System\n19 (32%)\n0 (0%)\n8 (33%)\n4 (44%)\n4 (29%)\n3 (38%)\n\n\nCoordination\n17 (28%)\n2 (40%)\n6 (25%)\n2 (22%)\n2 (14%)\n5 (63%)\n\n\nGait\n17 (28%)\n2 (40%)\n7 (29%)\n1 (11%)\n4 (29%)\n3 (38%)\n\n\nBowel.and.bladder.function\n9 (15%)\n1 (20%)\n2 (8.3%)\n1 (11%)\n3 (21%)\n2 (25%)\n\n\nMobility\n4 (6.7%)\n0 (0%)\n2 (8.3%)\n1 (11%)\n1 (7.1%)\n0 (0%)\n\n\nMental.State\n3 (5.0%)\n0 (0%)\n2 (8.3%)\n0 (0%)\n1 (7.1%)\n0 (0%)\n\n\nOptic.discs\n22 (37%)\n2 (40%)\n8 (33%)\n3 (33%)\n4 (29%)\n5 (63%)\n\n\nFields\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n\n\nNystagmus\n7 (12%)\n1 (20%)\n3 (13%)\n2 (22%)\n0 (0%)\n1 (13%)\n\n\nOcular.Movement\n2 (3.3%)\n0 (0%)\n0 (0%)\n1 (11%)\n0 (0%)\n1 (13%)\n\n\nSwallowing\n3 (5.0%)\n0 (0%)\n3 (13%)\n0 (0%)\n0 (0%)\n0 (0%)\n\n\n\n1 n (%); Median (25%,75%)\n\n\n2 Does the time difference between MRI acquisition and EDSS &lt; two months\n\n\n\n\n\n\n\n\nIf you want to save the created table, you can do this in one of two ways. The first is save it directly as a .docx file which should work most of the time. However, if you notice any formatting issues, change the save target file extension to .html, then open that in Word and you should be ok as well. An important point is to first save the table in your R script to an object - e.g.\ntbl &lt;- dat |&gt; tbl_summary(...\nThe command to save the table as a Word (or html file is then):\ngt::gtsave(as_gt(tbl), filename = \"summary_table.docx\", path = \"...your_path.../\")\n\n\n3 Regression Table\ngtsummary‚Äôs other strength is in making regression tables, and the relevant workhorse function here is tbl_regression().\nLet‚Äôs say we‚Äôre interested in the association between Age onset and the presence of Sensory symptoms (I don‚Äôt really know whether this makes sense or not but it‚Äôs just to run a regression). The outcome variable here is binary, so we‚Äôll need to specify a logistic regression model. We can do that as follows in R and we obtain the standard (fairly bland from the point of view of presentation/collaboration) ouput:\n\n\nCode\nmod &lt;- glm(Sensory ~ Age.of.onset, family = 'binomial', data = dat)\nsummary(mod)\n\n\n\nCall:\nglm(formula = Sensory ~ Age.of.onset, family = \"binomial\", data = dat)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)  -1.75743    0.87101  -2.018   0.0436 *\nAge.of.onset  0.02987    0.02641   1.131   0.2581  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 73.304  on 59  degrees of freedom\nResidual deviance: 71.994  on 58  degrees of freedom\nAIC: 75.994\n\nNumber of Fisher Scoring iterations: 4\n\n\nLet‚Äôs pretty this up by passing the model results through tbl_regression():\n\n\nCode\nmod |&gt; \n  tbl_regression()\n\n\n\n\n\n\n\n\nCharacteristic\nlog(OR)1\n95% CI1\np-value\n\n\n\n\nAge.of.onset\n0.03\n-0.02, 0.08\n0.3\n\n\n\n1 OR = Odds Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\n\nNot bad, but we‚Äôd like the output to be in terms of odds-ratios rather than log odds-ratios. That‚Äôs actually quite simple to do:\n\n\nCode\nmod |&gt; \n  tbl_regression(exponentiate = T)\n\n\n\n\n\n\n\n\nCharacteristic\nOR1\n95% CI1\np-value\n\n\n\n\nAge.of.onset\n1.03\n0.98, 1.09\n0.3\n\n\n\n1 OR = Odds Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\n\nWhat if you want to include some model summary fit-statistics:\n\n\nCode\nmod |&gt; \n  tbl_regression(exponentiate = T) |&gt; \n  add_glance_source_note()\n\n\n\n\n\n  \n    \n      Characteristic\n      OR1\n      95% CI1\n      p-value\n    \n  \n  \n    Age.of.onset\n1.03\n0.98, 1.09\n0.3\n  \n  \n    \n      Null deviance = 73.3; Null df = 59.0; Log-likelihood = -36.0; AIC = 76.0; BIC = 80.2; Deviance = 72.0; Residual df = 58; No. Obs. = 60\n    \n  \n  \n    \n      1 OR = Odds Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\ntbl_regression() supports almost any model you can throw at it.\n\n\n4 Last Word\nI hope you find both of these functions useful in your day-to-day coding and data analysis - they are great additions to your R toolkit, not only for their time-saving capabilities, but also the fantastic improvements to the visual style of results formatting that you can achieve, for which base R often falls far short."
  },
  {
    "objectID": "posts/012_17May_2024/index.html",
    "href": "posts/012_17May_2024/index.html",
    "title": "Prop Odds",
    "section": "",
    "text": "I want to share with you a secret - maybe you already know it. It took me a while into my statistical learnings to realise this and since then I‚Äôve seen people write about it (see here and here for examples). But the basic idea is that many of the common statistical tests that we use (e.g.¬†t-test, ANOVA, etc) are really nothing more than variations on the general linear model that we‚Äôre all accustomed to:\n\\[ y = ax + b \\]\nThe former are specific-use tests, whereas the latter is an ‚Äòumbrella‚Äô model that can be broadly adapted to accomplish each of the same tasks - perhaps there‚Äôs something to be said for learning just one set of syntax. Let me illustrate this to you with one example using the two-sample t-test. We‚Äôll use the genderweight dataset from the datarium package in R which consists of the bodyweights of 40 subjects (20 males, 20 females). We‚Äôre interested in working out whether there is a gender difference. A look at the data shows:\n\n\nCode\nlibrary(ggplot2)\ndata(\"genderweight\", package = \"datarium\")\nhead(genderweight, 10)\n\n\n\n\n\n\nid\ngroup\nweight\n\n\n\n\n1\nF\n61.58587\n\n\n2\nF\n64.55486\n\n\n3\nF\n66.16888\n\n\n4\nF\n59.30860\n\n\n5\nF\n64.85825\n\n\n6\nF\n65.01211\n\n\n7\nF\n62.85052\n\n\n8\nF\n62.90674\n\n\n9\nF\n62.87110\n\n\n10\nF\n62.21992\n\n\n\n\n\n\n\n1 Plot the Data\nIt‚Äôs always helpful to first plot the data:\n\n\nCode\nggplot(genderweight, aes(x = group, y = weight)) +\n  geom_jitter(size = 3, width = 0.05) +\n  scale_y_continuous(limits = c(50, 100), breaks = seq(50, 100, by = 10)) +\n  stat_summary(fun = mean, \n               geom = \"errorbar\", \n               aes(ymax = after_stat(y), ymin = after_stat(y)), \n               width = 0.25) +\n  theme_bw(base_size = 20)\n\n\n\n\n\n\n\n\n\n\n\n2 Two-Sample t-Test\nNow, we can run our standard t-test as follows (by default, computing the Welch version of the test which does not assume the same variances in each group). In words, we are asking to test the difference in weight by group (i.e.¬†males vs females).\nt.test(weight ~ group, data = genderweight)\n\n\nCode\nt.test(weight ~ group, data = genderweight)\n\n\n\n    Welch Two Sample t-test\n\ndata:  weight by group\nt = -20.791, df = 26.872, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group F and group M is not equal to 0\n95 percent confidence interval:\n -24.53135 -20.12353\nsample estimates:\nmean in group F mean in group M \n       63.49867        85.82612 \n\n\nThis output tells us that the mean weight in females and males is 63.5 kg and 85.8 kg, respectively. Furthermore, the 95% C.I. for the difference (note that is does not give us the actual difference) in those two weights is -24.5, -20.1 and as the interval does not contain 0 this is statistically significant (as also reflected in the p-value).\n\n\n3 Linear Model\nNow, the equivalent linear model (i.e.¬†linear regression) in R is simply:\nsummary(lm(weight ~ group, data = genderweight))\n\n\nCode\nsummary(lm(weight ~ group, data = genderweight))\n\n\n\nCall:\nlm(formula = weight ~ group, data = genderweight)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.8163 -1.3647 -0.4869  1.3980  9.2365 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  63.4987     0.7593   83.62   &lt;2e-16 ***\ngroupM       22.3274     1.0739   20.79   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.396 on 38 degrees of freedom\nMultiple R-squared:  0.9192,    Adjusted R-squared:  0.9171 \nF-statistic: 432.3 on 1 and 38 DF,  p-value: &lt; 2.2e-16\n\n\nThe output is slightly different but the information contained is almost the same. (Intercept) represents the mean weight in the reference category of the group variable (in this case females). groupM represents the difference in means between females and males (22.3 kg). Note that the 95% C.I.‚Äôs aren‚Äôt presented as part of this standard output, but we can obtain that information easily enough with:\nconfint(lm(weight ~ group, data = genderweight))\n\n\nCode\nconfint(lm(weight ~ group, data = genderweight))\n\n\n               2.5 %   97.5 %\n(Intercept) 61.96145 65.03589\ngroupM      20.15349 24.50140\n\n\nNote the slight difference in the 95% C.I.‚Äôs to that obtained from the t-test. The general linear model, by assumption, assumes homogeneity of variances among the two groups.\nFinally, if you would prefer to know the actual mean values of each group as well, it‚Äôs possible to amend the lm call slightly by removing the intercept term. This gives:\nsummary(lm(weight ~ group - 1, data = genderweight))\n\n\nCode\nsummary(lm(weight ~ group - 1, data = genderweight))\n\n\n\nCall:\nlm(formula = weight ~ group - 1, data = genderweight)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.8163 -1.3647 -0.4869  1.3980  9.2365 \n\nCoefficients:\n       Estimate Std. Error t value Pr(&gt;|t|)    \ngroupF  63.4987     0.7593   83.62   &lt;2e-16 ***\ngroupM  85.8261     0.7593  113.03   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.396 on 38 degrees of freedom\nMultiple R-squared:  0.9981,    Adjusted R-squared:  0.998 \nF-statistic:  9884 on 2 and 38 DF,  p-value: &lt; 2.2e-16\n\n\nThe two-sample t-test is just one example of a special case of the general linear model. The first link I provided above contains a neat pdf describing many other special cases and I would encourage you to have a look at these. While you might still use these specific tests in your day to day work, it is nonetheless helpful to broaden your statistical knowledge in the realisation that the general linear model is fundamental to all of these."
  }
]