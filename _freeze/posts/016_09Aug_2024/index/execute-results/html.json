{
  "hash": "bb9f23341d0a259a01585df21c6e8b5b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Logarithms and Why They're Important in Statistics\"\ndate: 2024-08-09\ncategories: [code, concept, visualisation]\n#image: \"R_small.jpeg\"\ndescription: \"Having to deal with logarithms may send a shiver down your spine, but they're not as hard as you may think\"\n---\n\n\n# Logarithms in the Real World\n\nWhat do the acidity (pH - power of Hydrogen), sound intensity (dB - decibels) and earthquake intensity (measured on the Richter) scales all have in common?\n\n**They are all reported on a log scale.**\n\nIn our real-world experience with these scales, I would be willing to bet that you haven't put a lot of thought into what the numbers actually mean. Sure, we might remember from high school chemistry that something is more acidic if the pH is lower than `7`. We might also know that higher numbers on the decibel scale indicate louder noises, but probably not what sources of sound specific levels relate to. We might also know from it's reporting in the news that the most recent (thankfully infrequently occurring) earthquake wasn't that severe based on a Richter magnitude of `4`. But there's actually much more to those numbers than meets the eye.\n\nLet's take a look at each of these scales in a little more detail:\n\n![pH (taken from: https://www.pmel.noaa.gov/co2/file/The+pH+scale+by+numbers)](images/pH.jpg){width=\"400\"}\n\n![Sound Intensity](images/sound.png)\n\n![Richter (taken from: https://en.m.wikipedia.org/wiki/File:How-the-Richter-Magnitude-Scale-is-determined.jpg)](images/Richter.jpg)\n\nIf you take some time to look at those figures you will realise that there is a commonality among all three of them. In each case, two sets of number scales are presented:\n\n1.  Reporting scale\n\n    -   Acidity (0 - 14)\n    -   Sound Intensity (0 - 150)\n    -   Earthquake Intensity (0 - 9)\n\n2.  Measurement scale\n\n    -   Acidity ($10^0 - 10^{-14}$)\n    -   Sound Intensity ($10^{-12} - 10^{3}$)\n    -   Earthquake Intensity ($10^{-1} - 10^{9}$)\n\nThe reporting scale is the one that we're all familiar with, but in each case the actual measurements are recorded on a different scale behind the scenes.\n\nWhy?\n\nThe reason is that there is just too much variation on the measurement scale - by orders of magnitude - to make it convenient to also use to describe effects. So we convert the measurement scale to a more interpretable (but somewhat arbitrary) scale for reporting.\n\nWell hello, logarithms.\n\nWhen a physical quantity varies over a very large range, it is often convenient to take its logarithm in order to have a more manageable set of numbers (good primers on logarithms and exponents can be found [here](https://www.mathsisfun.com/algebra/logarithms.html) and [here](https://www.mathsisfun.com/algebra/exponents-logarithms.html)). And that's exactly what is happening when we talk about acidity, sound intensity and earthquake intensity.\n\nThere is a key point to know about logarithms:\n\n**Logarithms convert numbers that are related on a multiplicative (exponential) scale to numbers that are related on an additive (linear) scale**.\n\nYou will see that in each of the above cases, the natural scale that the quantity is measured on is multiplicative in nature. Each 'unit' change represents an order of magnitude difference in the quantity. For example, the amplitude of seismic waves (felt as the level of ground shake) in a Richter magnitude 5 earthquake (moderate) are 10 times greater than that of a magnitude 4 earthquake (small). Similarly, a 'major' earthquake (Richter 7) would be considered 1000 times greater in seismic activity compared to a small earthquake.\n\nBut when we instead use logarithms, those multiplicative effects are now converted to additive effects. **Each one-unit increase in seismic activity on the Richter scale corresponds to a 10 times greater increase in seismic activity on the natural scale.**\n\nSo, how is this relevant in our daily data analysis endeavours?\n\n# Logarithms in Biostatistics\n\nOk, so I don't have the space, time or your attention to go into every possible use of logarithms in biostatistics. But want I want to do here is just give you some basic intuition about how important they can be in what we do, how not to be put off when you're required to entertain them, and how you may be using them without even realising it.\n\n## Simulate Exponential Data\n\nLet's first of all visualise my statement regarding the logarithms ability to convert multiplicative effects to additive effects. I'll create a 'geometric' number series of 10 numbers with **base** `2` - i.e. each subsequent number in the series is double the previous number. In other words, `2` is the multiplying factor in this series. The data looks like:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(kableExtra)\nlibrary(gtsummary)\nlibrary(emmeans)\nx <- c(0:10)\ny <- 2^(0:10)\ny2 <- c(paste0(\"1 = 2\\U2070\"),\n        paste0(\"2 = 2\\U00B9\"),\n        paste0(\"2x2 = 2\\U00B2\"),\n        paste0(\"2x2x2 = 2\\U00B3\"),\n        paste0(\"2x2x2x2 = 2\\U2074\"),\n        paste0(\"2x2x2x2x2 = 2\\U2075\"),\n        paste0(\"2x2x2x2x2x2 = 2\\U2076\"),\n        paste0(\"2x2x2x2x2x2x2 = 2\\U2077\"),\n        paste0(\"2x2x2x2x2x2x2x2 = 2\\U2078\"),\n        paste0(\"2x2x2x2x2x2x2x2x2 = 2\\U2079\"),\n        paste0(\"2x2x2x2x2x2x2x2x2x2 = 2\\U00B9\\U2070\"))\ndf <- data.frame(cbind(x = x, y = y, `y_in_exponential_form` = y2))\ndf$x <- as.numeric(df$x); df$y <- as.numeric(df$y)\ndf |> \n  kable(align = \"c\", digits = 2)\n```\n\n::: {.cell-output-display}\n\n\n| x  |  y   |   y_in_exponential_form   |\n|:--:|:----:|:-------------------------:|\n| 0  |  1   |          1 = 2⁰           |\n| 1  |  2   |          2 = 2¹           |\n| 2  |  4   |         2x2 = 2²          |\n| 3  |  8   |        2x2x2 = 2³         |\n| 4  |  16  |       2x2x2x2 = 2⁴        |\n| 5  |  32  |      2x2x2x2x2 = 2⁵       |\n| 6  |  64  |     2x2x2x2x2x2 = 2⁶      |\n| 7  | 128  |    2x2x2x2x2x2x2 = 2⁷     |\n| 8  | 256  |   2x2x2x2x2x2x2x2 = 2⁸    |\n| 9  | 512  |  2x2x2x2x2x2x2x2x2 = 2⁹   |\n| 10 | 1024 | 2x2x2x2x2x2x2x2x2x2 = 2¹⁰ |\n\n\n:::\n:::\n\n\nYou can see that the numbers grow large very quickly.\n\n## Arithmetic vs Geometric Mean\n\nIf someone asked you to provide a summary statistic for these data what would you give them? The mean, median or something else? The median is always a good choice when you're uncertain about whether your data might conform to parametric distribution assumptions. The median is just the middle value in the series and can be worked out in `R` as:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nmedian(df$y)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 32\n```\n\n\n:::\n:::\n\n\nWhat about the (arithmetic) mean?\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nmean(df$y)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 186.0909\n```\n\n\n:::\n:::\n\n\nThat seems fairly highly when we see that most values are less than this. But this is symptomatic of data that are related in a multiplicative way - values tend to be condensed towards one end of the scale and skewed towards the other. The fewer, larger values 'drag' the average towards that end of the scale. In these cases, the conventional **arithmetic** mean is not the best measure of central tendency and instead we should use the **geometric** mean.\n\nRemember that the arithmetic mean is calculated as such:\n\n$$\\frac{1+2+4+8+16+32+64+128+256+512+1024}{11} = 186.1$$ There are two ways to calculate the geometric mean by hand (but I will also show you how to do it in `R` as well):\n\nThe first way is to take the `nth` root of the product of all the terms:\n\n$$\\sqrt[11]{1*2*4*8*16*32*64*128*256*512*1024} = 32$$ and the second way is to take the exponent of the mean of the logged values:\n\n$$e\\ ^{\\left( \\frac{log(1)+log(2)+log(4)+log(8)+log(16)+log(32)+log(64)+log(128)+log(256)+log(512)+log(1024)}{11} \\right)} = 32$$\n\nIn `R`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# nth root method - manual\n(1*2*4*8*16*32*64*128*256*512*1024)^(1/11)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 32\n```\n\n\n:::\n\n```{.r .cell-code}\n# logs method - manual\nexp((log(1)+log(2)+log(4)+log(8)+log(16)+log(32)+log(64)+log(128)+log(256)+log(512)+log(1024))/11)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 32\n```\n\n\n:::\n\n```{.r .cell-code}\n# logs method - quick and easy\nexp(mean(log(df$y)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 32\n```\n\n\n:::\n:::\n\n\nIn a perfectly geometric series the geometric mean will align with the median and is a better measure of central tendency, so keep that in the back of your mind.\n\n## Plot Data on Original Scale\n\nLet's now plot this data using a normal linear scale:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(df, aes(x, y)) + \n  geom_line(linewidth = 1, colour = \"deepskyblue\") +\n  scale_x_continuous(limits = c(0, 10), breaks = seq(0, 10, by = 1)) +\n  scale_y_continuous(limits = c(1, 1050), breaks = c(1,100,200,300,400,500,600,700,800,900,1000)) +\n  theme_bw(base_size = 30)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=1152}\n:::\n:::\n\n\nIt is not hard to appreciate the exponential nature of the relationship between `X` and `Y` in this plot. As `X` increases, `Y` increases at a much faster rate, but it's hard to tell by how much.\n\n## Plot Data on Original Scale (Modified Y Axis)\n\nWhat does the plot look like if we use the axis tick marks to indicate the actual `Y` values (keeping the original scale):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(df, aes(x, y)) + \n  geom_line(linewidth = 1, colour = \"deepskyblue\") +\n  scale_x_continuous(limits = c(0, 10), breaks = seq(0, 10, by = 1)) +\n  scale_y_continuous(limits = c(1, 1050), breaks = c(1,2,4,8,16,32,64,128,256,512,1024)) +\n  geom_segment(aes(x = 0, y = 64, xend = 6, yend = 64), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  geom_segment(aes(x = 6, y = 1, xend = 6, yend = 64), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  geom_segment(aes(x = 0, y = 128, xend = 7, yend = 128), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  geom_segment(aes(x = 7, y = 1, xend = 7, yend = 128), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  geom_rect(aes(xmin = 0, xmax = 7, ymin = 64, ymax = 128), fill = \"red\", alpha = 0.02) +\n  geom_rect(aes(xmin = 6, xmax = 7, ymin = 1, ymax = 64), fill = \"red\", alpha = 0.02) +\n  geom_segment(aes(x = 0, y = 256, xend = 8, yend = 256), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  geom_segment(aes(x = 8, y = 1, xend = 8, yend = 256), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  geom_segment(aes(x = 0, y = 512, xend = 9, yend = 512), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  geom_segment(aes(x = 9, y = 1, xend = 9, yend = 512), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  geom_rect(aes(xmin = 0, xmax = 9, ymin = 256, ymax = 512), fill = \"red\", alpha = 0.02) +\n  geom_rect(aes(xmin = 8, xmax = 9, ymin = 1, ymax = 256), fill = \"red\", alpha = 0.02) +\n  theme_bw(base_size = 30)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=1152}\n:::\n:::\n\n\nInteresting. Obviously nothing has changed except the values on the `Y` axis no longer reflect evenly spaced units. In fact if you took a ruler to your screen you would see that the pixel distance between each pair of ascending tick marks is double the previous pair of tick marks. The larger numbers are nicely spread out on the axis, while the smaller numbers are all cramped together.\n\nWhat is certainly easier to appreciate in this plot compared to the previous one is the **doubling** of `Y` for each unit increase in `X`. We can see for instance that the one-unit increase in `X` between `6` and `7` corresponds to a doubling of `Y` from `64` to `128.` Similarly, the one-unit increase between `8` and `9` corresponds to a doubling of `Y` from `256` to `512`.\n\nSo, being good data analysts we always visualise our data before we get too far into analysing it. Although we know the data-generating mechanism for these data (because we simulated it based on what we wanted), we usually don't know the data-generating mechanism for most real-world data that we come across. So, if we were in fact naive to the origins of these data an entirely reasonable question we might ask ourselves would be \"do these come from an exponential (multiplicative) distribution?\"\n\nA natural next step would be to see if taking logs of the data linearises (i.e straightens) the association between `X` and `Y`. Remember that I mentioned earlier that logs convert numbers that are related on a multiplicative scale to numbers that are related on an additive scale. What this means in practice is that an exponential curve flattens out and becomes linear if the data are truly multiplicative in nature.\n\n## Plot Data on Log Scale\n\nThere are two ways one can plot data on a log scale using `ggplot()` in `R`. The first is to log-transform the data and plot it in the normal way; the second is to leave the data as is and use `ggplot()` in concert with the `scales` package to log-transform the axis scales. Let's consider the second option first.\n\nHere we specify `trans = \"log2\"` within the `scale_y_continuous()` function to transform the `Y` axis to a base(`2`) log scale. The result is:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(scales)\nggplot(df, aes(x, y)) + \n  geom_line(linewidth = 1, colour = \"deepskyblue\") +\n  scale_x_continuous(limits = c(0, 10), breaks = seq(0, 10, by = 1)) +\n  scale_y_continuous(trans = \"log2\", breaks = c(1,2,4,8,16,32,64,128,256,512,1024)) +\n  geom_segment(aes(x = 0, y = 64, xend = 6, yend = 64), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  geom_segment(aes(x = 6, y = 1, xend = 6, yend = 64), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  geom_segment(aes(x = 0, y = 128, xend = 7, yend = 128), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  geom_segment(aes(x = 7, y = 1, xend = 7, yend = 128), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  geom_rect(aes(xmin = 0, xmax = 7, ymin = 64, ymax = 128), fill = \"red\", alpha = 0.02) +\n  geom_rect(aes(xmin = 6, xmax = 7, ymin = 1, ymax = 64), fill = \"red\", alpha = 0.02) +\n  geom_segment(aes(x = 0, y = 256, xend = 8, yend = 256), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  geom_segment(aes(x = 8, y = 1, xend = 8, yend = 256), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  geom_segment(aes(x = 0, y = 512, xend = 9, yend = 512), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  geom_segment(aes(x = 9, y = 1, xend = 9, yend = 512), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  geom_rect(aes(xmin = 0, xmax = 9, ymin = 256, ymax = 512), fill = \"red\", alpha = 0.02) +\n  geom_rect(aes(xmin = 8, xmax = 9, ymin = 1, ymax = 256), fill = \"red\", alpha = 0.02) +\n  theme_bw(base_size = 30)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=1152}\n:::\n:::\n\n\nNow that the `Y` axis has been rescaled we can easily see that the association between `X` and `Y` is in fact linear on this scale. We can also see that where previously the spacing of the ascending tick marks on the `Y` axis doubled, these now remain the same. `Y` is still doubling for every unit increase in `X`, but the `Y` scale is now considered additive rather than multiplicative in nature (i.e. each doubling is the now the same pixel distance along the axis in the plot).\n\nI can hopefully consolidate this multiplicative -\\> additive transformation in your mind by now replacing the raw values on the `Y` axis with their log-transformed equivalents. If you ignore the base(`2`) on the ascending `Y` axis, each exponent is now simply `1` more than the previous value. In other words, on the base(`2`) log scale, the 'effects' are additive.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(df, aes(x, y)) + \n  geom_line(linewidth = 1, colour = \"deepskyblue\") +\n  scale_x_continuous(limits = c(0, 10), breaks = seq(0, 10, by = 1)) +\n  scale_y_continuous(trans = log2_trans(),\n    breaks = c(1,2,4,8,16,32,64,128,256,512,1024),\n    labels = trans_format(\"log2\", math_format(2^.x))) +\n  geom_segment(aes(x = 0, y = 64, xend = 6, yend = 64), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  geom_segment(aes(x = 6, y = 1, xend = 6, yend = 64), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  geom_segment(aes(x = 0, y = 128, xend = 7, yend = 128), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  geom_segment(aes(x = 7, y = 1, xend = 7, yend = 128), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  geom_rect(aes(xmin = 0, xmax = 7, ymin = 64, ymax = 128), fill = \"red\", alpha = 0.02) +\n  geom_rect(aes(xmin = 6, xmax = 7, ymin = 1, ymax = 64), fill = \"red\", alpha = 0.02) +\n  geom_segment(aes(x = 0, y = 256, xend = 8, yend = 256), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  geom_segment(aes(x = 8, y = 1, xend = 8, yend = 256), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  geom_segment(aes(x = 0, y = 512, xend = 9, yend = 512), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  geom_segment(aes(x = 9, y = 1, xend = 9, yend = 512), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  geom_rect(aes(xmin = 0, xmax = 9, ymin = 256, ymax = 512), fill = \"red\", alpha = 0.02) +\n  geom_rect(aes(xmin = 8, xmax = 9, ymin = 1, ymax = 256), fill = \"red\", alpha = 0.02) +\n  theme_bw(base_size = 30)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=1152}\n:::\n:::\n\n\nThe other approach to plotting data on a log scale is to actually log-transform the data, and this is not difficult. If you knew that the data series were multiplicative by a factor of `2` you would naturally transform using a base(`2`) log scale as you would end up with a nice, natural interpretation of the transformed data - each unit increase in `X` representing a doubling in `Y`. Often you won't know this, but you can still achieve the goal of linearising your data by using either natural (`e`) or base(`10`) logs.\n\nThe plots below show the association between `X` and log-transformed `Y` for all three of the common log transformations. Note that they all produce the same effect on the association between `X` and `Y` - just the scale differs. The numbers on each `Y` axis represent the powers that are raised to each base to calculate the value of `Y` in its original units. So, for example:\n\n$$2^{5} \\approx e^{3.46} \\approx 10^{1.51} \\approx 32$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Here I have performed the log-transformation of Y on-the-fly, within the ggplot call, but you can also do this by explicitly creating a new log-transformed variable in the dataset\np1 <- ggplot(df, aes(x, y = log2(y))) + \n  geom_line(linewidth = 1, colour = \"deepskyblue\") +\n  geom_segment(aes(x = 5, y = 0, xend = 5, yend = 5), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  geom_segment(aes(x = 0, y = 5, xend = 5, yend = 5), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  scale_x_continuous(limits = c(0, 10), breaks = seq(0, 10, by = 1)) +\n  scale_y_continuous(limits = c(0, 10), breaks = c(0,2,4,6,8,10)) +\n  annotate(geom = \"text\", x = 0.8, y = 5.26, label = \"5.00\", color=\"red\", size = 8) +\n  theme_bw(base_size = 20)\np2 <- ggplot(df, aes(x, y = log(y))) + \n  geom_line(linewidth = 1, colour = \"deepskyblue\") +\n  geom_segment(aes(x = 5, y = 0, xend = 5, yend = 3.46), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  geom_segment(aes(x = 0, y = 3.46, xend = 5, yend = 3.46), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  scale_x_continuous(limits = c(0, 10), breaks = seq(0, 10, by = 1)) +\n  annotate(geom = \"text\", x = 0.8, y = 3.65, label = \"3.46\", color=\"red\", size = 8) +\n  theme_bw(base_size = 20)\np3 <- ggplot(df, aes(x, y = log10(y))) + \n  geom_line(linewidth = 1, colour = \"deepskyblue\") +\n  geom_segment(aes(x = 5, y = 0, xend = 5, yend = 1.51), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  geom_segment(aes(x = 0, y = 1.51, xend = 5, yend = 1.51), linewidth = 0.5, color = \"red\", linetype = \"dashed\") +\n  scale_x_continuous(limits = c(0, 10), breaks = seq(0, 10, by = 1)) +\n  annotate(geom = \"text\", x = 0.8, y = 1.6, label = \"1.51\", color=\"red\", size = 8) +\n  theme_bw(base_size = 20)\ncowplot::plot_grid(p1, p2, p3, labels = c('Base(2) log', 'Natural log', 'Base(10) log'), hjust = c(-0.9,-0.7,-0.6), vjust = 4, ncol = 3, label_size = 20)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=1152}\n:::\n:::\n\n\nSo you might still be wondering where I am headed with all of this.\n\n## Think About Modelling Assumptions\n\nWell, there are several assumptions that the linear model leans on to ensure the parameter estimates it comes up with are valid and these include that the association between a continuous predictor and the outcome is roughly linear and the distribution of the model residuals is roughly normal. Both of these assumptions can fail when you try to model an obviously curved relationship as if it were linear. Certainly if domain-knowledge dictates that the origins of your data come from an exponential distribution (many biological cell process have this basis - e.g. cell division), you need to stop and think about how you will approach your analysis.\n\nIf you blindly ran a standard linear regression on these data, you would get:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_linear <- lm(y ~ x, data = df) \nmod_linear |> \n  tbl_regression()\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"yhkyogojsd\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#yhkyogojsd table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#yhkyogojsd thead, #yhkyogojsd tbody, #yhkyogojsd tfoot, #yhkyogojsd tr, #yhkyogojsd td, #yhkyogojsd th {\n  border-style: none;\n}\n\n#yhkyogojsd p {\n  margin: 0;\n  padding: 0;\n}\n\n#yhkyogojsd .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#yhkyogojsd .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#yhkyogojsd .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#yhkyogojsd .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#yhkyogojsd .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#yhkyogojsd .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#yhkyogojsd .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#yhkyogojsd .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#yhkyogojsd .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#yhkyogojsd .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#yhkyogojsd .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#yhkyogojsd .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#yhkyogojsd .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#yhkyogojsd .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#yhkyogojsd .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#yhkyogojsd .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#yhkyogojsd .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#yhkyogojsd .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#yhkyogojsd .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#yhkyogojsd .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#yhkyogojsd .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#yhkyogojsd .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#yhkyogojsd .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#yhkyogojsd .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#yhkyogojsd .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#yhkyogojsd .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#yhkyogojsd .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#yhkyogojsd .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#yhkyogojsd .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#yhkyogojsd .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#yhkyogojsd .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#yhkyogojsd .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#yhkyogojsd .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#yhkyogojsd .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#yhkyogojsd .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#yhkyogojsd .gt_left {\n  text-align: left;\n}\n\n#yhkyogojsd .gt_center {\n  text-align: center;\n}\n\n#yhkyogojsd .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#yhkyogojsd .gt_font_normal {\n  font-weight: normal;\n}\n\n#yhkyogojsd .gt_font_bold {\n  font-weight: bold;\n}\n\n#yhkyogojsd .gt_font_italic {\n  font-style: italic;\n}\n\n#yhkyogojsd .gt_super {\n  font-size: 65%;\n}\n\n#yhkyogojsd .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#yhkyogojsd .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#yhkyogojsd .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#yhkyogojsd .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#yhkyogojsd .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#yhkyogojsd .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#yhkyogojsd .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"&lt;strong&gt;Characteristic&lt;/strong&gt;\"><strong>Characteristic</strong></th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"&lt;strong&gt;Beta&lt;/strong&gt;\"><strong>Beta</strong></th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"&lt;strong&gt;95% CI&lt;/strong&gt;&lt;span class=&quot;gt_footnote_marks&quot; style=&quot;white-space:nowrap;font-style:italic;font-weight:normal;&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/span&gt;\"><strong>95% CI</strong><span class=\"gt_footnote_marks\" style=\"white-space:nowrap;font-style:italic;font-weight:normal;\"><sup>1</sup></span></th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"&lt;strong&gt;p-value&lt;/strong&gt;\"><strong>p-value</strong></th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">x</td>\n<td headers=\"estimate\" class=\"gt_row gt_center\">75</td>\n<td headers=\"ci\" class=\"gt_row gt_center\">29, 120</td>\n<td headers=\"p.value\" class=\"gt_row gt_center\">0.005</td></tr>\n  </tbody>\n  \n  <tfoot class=\"gt_footnotes\">\n    <tr>\n      <td class=\"gt_footnote\" colspan=\"4\"><span class=\"gt_footnote_marks\" style=\"white-space:nowrap;font-style:italic;font-weight:normal;\"><sup>1</sup></span> CI = Confidence Interval</td>\n    </tr>\n  </tfoot>\n</table>\n</div>\n```\n\n:::\n\n```{.r .cell-code}\nggplot(df, aes(x, y)) + \n  geom_line(linewidth = 1, colour = \"deepskyblue\") +\n  geom_smooth(method = \"lm\", se = F, colour = \"black\") +\n  scale_x_continuous(limits = c(0, 10), breaks = seq(0, 10, by = 1)) +\n  scale_y_continuous(limits = c(1, 1050), breaks = c(1,100,200,300,400,500,600,700,800,900,1000)) +\n  theme_bw(base_size = 30)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=1152}\n:::\n:::\n\n\nClearly this is not ideal. The model is trying to suggest that for each unit increase in `X`, `Y` increases at a constant rate of `75`. Let's see what the model predicts for the value of `Y` when `X = 5` (when we know the actual value is `32`).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemmeans(mod_linear, ~ x, at = (list(x = 5))) |> \n  kable(align = \"c\", digits = 2)\n```\n\n::: {.cell-output-display}\n\n\n| x | emmean |  SE   | df | lower.CL | upper.CL |\n|:-:|:------:|:-----:|:--:|:--------:|:--------:|\n| 5 | 186.09 | 64.04 | 9  |  41.22   |  330.97  |\n\n\n:::\n:::\n\n\nHmmm, further evidence that this is a bad model for these data. Instead, let's rerun the regression applying one small change - we will log-transform `Y` on-the-fly within the model call.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_trans <- lm(log(y) ~ x, data = df) \ntbl <- mod_trans |> \n  tbl_regression() # need work around for log transformed response for tbl_regression\ntbl |>\n  # remove character version of 95% CI\n  modify_column_hide(ci) |> \n  # exponentiate the regression estimates\n  modify_table_body(\n    \\(x) x |> mutate(across(c(estimate, conf.low, conf.high), exp))\n  ) |> \n  # merge numeric LB and UB together to display in table\n  modify_column_merge(pattern = \"{conf.low}, {conf.high}\", rows = !is.na(estimate)) |> \n  modify_header(conf.low = \"**95% CI**\") |> \n  as_kable()\n```\n\n::: {.cell-output-display}\n\n\n|**Characteristic** | **Beta** | **95% CI** | **p-value** |\n|:------------------|:--------:|:----------:|:-----------:|\n|x                  |   2.0    |  2.0, 2.0  |   <0.001    |\n\n\n:::\n:::\n\n\nYou will get a warning if you run this model (I have hidden it) as it's a perfect fit, because there is no randomness in the data. That doesn't really matter though for the sake of the illustration. The `Beta` value represents the exponentiated coefficient for the association between `X` and `Y` and can be considered a 'response ratio'. This is equivalent to the **ratio of each pair of successive values of `Y` for each unit increase in `X`**. The response ratio of `2` implies that the outcome doubles (or increases by `100%`) for each unit increase in the predictor and we know this to be true.\n\nWhat does this model predict the value of `Y` at `X = 5` should be?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemmeans(mod_trans, ~ x, at = (list(x = 5)), type = \"response\") |> \n  kable(align = \"c\", digits = 2)\n```\n\n::: {.cell-output-display}\n\n\n| x | response | SE | df | lower.CL | upper.CL |\n|:-:|:--------:|:--:|:--:|:--------:|:--------:|\n| 5 |    32    | 0  | 9  |    32    |    32    |\n\n\n:::\n:::\n\n\nAnd this is what we would expect a good-fitting (perfectly-fitting in this case) model to be able to do - predict values on new data in line with our empirical observations.\n\n# Summary\n\nOk, this post has become much longer than I was initially anticipating - there appears to be more to logs to talk about than I thought. The example just above illustrates the idea of log-tranforming your outcome variable to improve the model fit and assumptions, but logarithms appear in all sorts of statistical models that you might not even be aware of. For example, they are frequently applied as **link functions in generalised linear models** think the logit (log-odds) link function in logistic regression and the log-count link function in Poisson regression. In each case they are used to transform the outcome from its original scale - a probability for the former and a positive count for the latter - to a scale that is unbounded and continuous so that standard model estimation methods can be used. Part of this is linearising the associations between the predictor/s and the outcome.\n\nWhen you are dealing with logarithms in statistical models, you can rely on some general 'rules'. **Differences on (additive) log scales are generally equivalent to ratios on (multiplicative) original scales**. For example, if you are performing a logistic regression, you might be presented with a model coefficient on the log-odds scale. This represents the **difference** in the log-odds of the outcome for a one-unit increase in the predictor. But the log-odds scale is really only used to estimate the model parameters - we usually talk in terms of odds and odds ratios when we're discussing our results. So we exponentiate our log-odds coefficient to obtain an odds **ratio** instead.\n\nI will stop there. Hopefully I haven't confused you further in this discussion. Logs don't have to be difficult and you mostly don't have to deal directly with them - if it helps you can think of them as 'facilitators' - they help things run smoothly in the background. However, having a general sense that they assist in transforming multiplicative scales to additive scales can help you in your daily data analysis tasks.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}